{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1f967acab16e42d1bfd36702ce6b7d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e87cf38a33443ebaa9588f538957341",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5ff4f5d96ddf433885555ad8ed7de24b",
              "IPY_MODEL_90276e1203f34499946f56edb3629e4e",
              "IPY_MODEL_f460246ac9644b1191737b73c2fe4cc4"
            ]
          }
        },
        "9e87cf38a33443ebaa9588f538957341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ff4f5d96ddf433885555ad8ed7de24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7344ffee14b84f16a6889c7bdd2b7fc9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ccdc3fceb32b4f75ba356738f294de2f"
          }
        },
        "90276e1203f34499946f56edb3629e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_13c29dac95b94d1a86d6ad5d281ef9fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ff160096d104ad28c59ce8b82ffef33"
          }
        },
        "f460246ac9644b1191737b73c2fe4cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_250ea29fc626430a9d570d0ddd6b214d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:12&lt;00:00, 16107915.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_861562f58573467aa301020ba6695d5e"
          }
        },
        "7344ffee14b84f16a6889c7bdd2b7fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccdc3fceb32b4f75ba356738f294de2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13c29dac95b94d1a86d6ad5d281ef9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ff160096d104ad28c59ce8b82ffef33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "250ea29fc626430a9d570d0ddd6b214d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "861562f58573467aa301020ba6695d5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1z-Mcbmh6Nl",
        "outputId": "be81d180-20c3-467a-c310-9787801678c2"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "\n",
        "import getpass\n",
        "\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "\n",
        "vcode = getpass.getpass()\n",
        "\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.27-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.27-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.27-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Cannot retrieve auth tokens.\n",
            "Failure(\"Unexpected error response: {\\n  \\\"error\\\": \\\"invalid_grant\\\",\\n  \\\"error_description\\\": \\\"Bad Request\\\"\\n}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n21TtokfiZgK",
        "outputId": "e2eda9d3-32f9-4b0c-88dd-d93029f7ca83"
      },
      "source": [
        "!mkdir -p drive \n",
        "\n",
        "!google-drive-ocamlfuse drive "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: www-browser: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links2: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: elinks: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: lynx: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/bin/sh: 1: open: not found\n",
            "Error: Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rilBauk7ibC-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIdmQPmdicrR",
        "outputId": "accd43dd-8550-4e18-c364-df207d92f12c"
      },
      "source": [
        "!pwd\n",
        "!ls drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLsFMfMliesd",
        "outputId": "abb08af1-03f9-468c-f768-8efb48514a57"
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1f967acab16e42d1bfd36702ce6b7d74",
            "9e87cf38a33443ebaa9588f538957341",
            "5ff4f5d96ddf433885555ad8ed7de24b",
            "90276e1203f34499946f56edb3629e4e",
            "f460246ac9644b1191737b73c2fe4cc4",
            "7344ffee14b84f16a6889c7bdd2b7fc9",
            "ccdc3fceb32b4f75ba356738f294de2f",
            "13c29dac95b94d1a86d6ad5d281ef9fe",
            "7ff160096d104ad28c59ce8b82ffef33",
            "250ea29fc626430a9d570d0ddd6b214d",
            "861562f58573467aa301020ba6695d5e"
          ]
        },
        "id": "hHYAgXWeig0G",
        "outputId": "d10be2a3-b4d6-404b-9e6c-7295f42de7d7"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'                # GPU Number \n",
        "start_time = time.time()\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "root_dir = 'drive/app/cifar10/'\n",
        "default_directory = 'drive/app/torch/save_models'\n",
        "\n",
        "# Data Augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),               # Random Position Crop\n",
        "    transforms.RandomHorizontalFlip(),                  # right and left flip\n",
        "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
        "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
        "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
        "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
        "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
        "])\n",
        "\n",
        "# automatically download\n",
        "train_dataset = datasets.CIFAR10(root=root_dir,\n",
        "                                 train=True,\n",
        "                                 transform=transform_train,\n",
        "                                 download=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root=root_dir,\n",
        "                                train=False,\n",
        "                                transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,            # at Training Procedure, Data Shuffle = True\n",
        "                                           num_workers=4)           # CPU loader number\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,            # at Test Procedure, Data Shuffle = False\n",
        "                                          num_workers=4)            # CPU loader number\n",
        "\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = out + self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "optimizer = optim.Adam(model.parameters(), learning_rate,\n",
        "                                eps=1e-08,\n",
        "                                weight_decay=1e-4\n",
        "                                )\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if torch.cuda.device_count() > 0:\n",
        "    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model).cuda()\n",
        "    cudnn.benchmark = True\n",
        "else:\n",
        "    print(\"USE ONLY CPU!\")\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0 \n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
        "        else:\n",
        "            data, target = Variable(data), Variable(target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
        "                  .format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
        "        else:\n",
        "            data, target = Variable(data), Variable(target)\n",
        "\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
        "          .format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "\n",
        "def save_checkpoint(directory, state, filename='latest.tar.gz'):\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    model_filename = os.path.join(directory, filename)\n",
        "    torch.save(state, model_filename)\n",
        "    print(\"=> saving checkpoint\")\n",
        "\n",
        "def load_checkpoint(directory, filename='latest.tar.gz'):\n",
        "\n",
        "    model_filename = os.path.join(directory, filename)\n",
        "    if os.path.exists(model_filename):\n",
        "        print(\"=> loading checkpoint\")\n",
        "        state = torch.load(model_filename)\n",
        "        return state\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "start_epoch = 0\n",
        "\n",
        "checkpoint = load_checkpoint(default_directory)\n",
        "if not checkpoint:\n",
        "    pass\n",
        "else:\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "for epoch in range(start_epoch, 165):\n",
        "\n",
        "    if epoch < 80:\n",
        "        lr = learning_rate\n",
        "    elif epoch < 120:\n",
        "        lr = learning_rate * 0.1\n",
        "    else:\n",
        "        lr = learning_rate * 0.01\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    train(epoch)\n",
        "    save_checkpoint(default_directory, {\n",
        "        'epoch': epoch,\n",
        "        'model': model,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "    })\n",
        "    test()  \n",
        "\n",
        "now = time.gmtime(time.time() - start_time)\n",
        "print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to drive/app/cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f967acab16e42d1bfd36702ce6b7d74",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting drive/app/cifar10/cifar-10-python.tar.gz to drive/app/cifar10/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "# TEST : Loss: (0.3591) | Acc: (89.28%) (8928/10000)\n",
            "Epoch: 46 | Batch_idx: 0 |  Loss: (0.1008) | Acc: (96.88%) (124/128)\n",
            "Epoch: 46 | Batch_idx: 10 |  Loss: (0.1411) | Acc: (95.53%) (1345/1408)\n",
            "Epoch: 46 | Batch_idx: 20 |  Loss: (0.1493) | Acc: (94.98%) (2553/2688)\n",
            "Epoch: 46 | Batch_idx: 30 |  Loss: (0.1533) | Acc: (94.86%) (3764/3968)\n",
            "Epoch: 46 | Batch_idx: 40 |  Loss: (0.1564) | Acc: (94.66%) (4968/5248)\n",
            "Epoch: 46 | Batch_idx: 50 |  Loss: (0.1592) | Acc: (94.58%) (6174/6528)\n",
            "Epoch: 46 | Batch_idx: 60 |  Loss: (0.1581) | Acc: (94.66%) (7391/7808)\n",
            "Epoch: 46 | Batch_idx: 70 |  Loss: (0.1607) | Acc: (94.48%) (8586/9088)\n",
            "Epoch: 46 | Batch_idx: 80 |  Loss: (0.1583) | Acc: (94.55%) (9803/10368)\n",
            "Epoch: 46 | Batch_idx: 90 |  Loss: (0.1581) | Acc: (94.57%) (11015/11648)\n",
            "Epoch: 46 | Batch_idx: 100 |  Loss: (0.1584) | Acc: (94.55%) (12224/12928)\n",
            "Epoch: 46 | Batch_idx: 110 |  Loss: (0.1579) | Acc: (94.50%) (13427/14208)\n",
            "Epoch: 46 | Batch_idx: 120 |  Loss: (0.1586) | Acc: (94.54%) (14643/15488)\n",
            "Epoch: 46 | Batch_idx: 130 |  Loss: (0.1583) | Acc: (94.53%) (15850/16768)\n",
            "Epoch: 46 | Batch_idx: 140 |  Loss: (0.1593) | Acc: (94.48%) (17051/18048)\n",
            "Epoch: 46 | Batch_idx: 150 |  Loss: (0.1597) | Acc: (94.45%) (18255/19328)\n",
            "Epoch: 46 | Batch_idx: 160 |  Loss: (0.1597) | Acc: (94.45%) (19464/20608)\n",
            "Epoch: 46 | Batch_idx: 170 |  Loss: (0.1583) | Acc: (94.51%) (20686/21888)\n",
            "Epoch: 46 | Batch_idx: 180 |  Loss: (0.1592) | Acc: (94.46%) (21885/23168)\n",
            "Epoch: 46 | Batch_idx: 190 |  Loss: (0.1590) | Acc: (94.48%) (23098/24448)\n",
            "Epoch: 46 | Batch_idx: 200 |  Loss: (0.1587) | Acc: (94.44%) (24298/25728)\n",
            "Epoch: 46 | Batch_idx: 210 |  Loss: (0.1600) | Acc: (94.40%) (25495/27008)\n",
            "Epoch: 46 | Batch_idx: 220 |  Loss: (0.1602) | Acc: (94.38%) (26699/28288)\n",
            "Epoch: 46 | Batch_idx: 230 |  Loss: (0.1621) | Acc: (94.33%) (27891/29568)\n",
            "Epoch: 46 | Batch_idx: 240 |  Loss: (0.1619) | Acc: (94.35%) (29105/30848)\n",
            "Epoch: 46 | Batch_idx: 250 |  Loss: (0.1620) | Acc: (94.33%) (30305/32128)\n",
            "Epoch: 46 | Batch_idx: 260 |  Loss: (0.1615) | Acc: (94.33%) (31515/33408)\n",
            "Epoch: 46 | Batch_idx: 270 |  Loss: (0.1615) | Acc: (94.34%) (32726/34688)\n",
            "Epoch: 46 | Batch_idx: 280 |  Loss: (0.1619) | Acc: (94.34%) (33931/35968)\n",
            "Epoch: 46 | Batch_idx: 290 |  Loss: (0.1617) | Acc: (94.33%) (35137/37248)\n",
            "Epoch: 46 | Batch_idx: 300 |  Loss: (0.1627) | Acc: (94.29%) (36328/38528)\n",
            "Epoch: 46 | Batch_idx: 310 |  Loss: (0.1625) | Acc: (94.29%) (37536/39808)\n",
            "Epoch: 46 | Batch_idx: 320 |  Loss: (0.1622) | Acc: (94.31%) (38752/41088)\n",
            "Epoch: 46 | Batch_idx: 330 |  Loss: (0.1638) | Acc: (94.27%) (39941/42368)\n",
            "Epoch: 46 | Batch_idx: 340 |  Loss: (0.1646) | Acc: (94.22%) (41126/43648)\n",
            "Epoch: 46 | Batch_idx: 350 |  Loss: (0.1654) | Acc: (94.20%) (42320/44928)\n",
            "Epoch: 46 | Batch_idx: 360 |  Loss: (0.1665) | Acc: (94.16%) (43508/46208)\n",
            "Epoch: 46 | Batch_idx: 370 |  Loss: (0.1665) | Acc: (94.15%) (44712/47488)\n",
            "Epoch: 46 | Batch_idx: 380 |  Loss: (0.1673) | Acc: (94.11%) (45898/48768)\n",
            "Epoch: 46 | Batch_idx: 390 |  Loss: (0.1683) | Acc: (94.08%) (47041/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4129) | Acc: (88.14%) (8814/10000)\n",
            "Epoch: 47 | Batch_idx: 0 |  Loss: (0.1438) | Acc: (96.09%) (123/128)\n",
            "Epoch: 47 | Batch_idx: 10 |  Loss: (0.1494) | Acc: (94.46%) (1330/1408)\n",
            "Epoch: 47 | Batch_idx: 20 |  Loss: (0.1515) | Acc: (94.57%) (2542/2688)\n",
            "Epoch: 47 | Batch_idx: 30 |  Loss: (0.1522) | Acc: (94.53%) (3751/3968)\n",
            "Epoch: 47 | Batch_idx: 40 |  Loss: (0.1592) | Acc: (94.34%) (4951/5248)\n",
            "Epoch: 47 | Batch_idx: 50 |  Loss: (0.1580) | Acc: (94.42%) (6164/6528)\n",
            "Epoch: 47 | Batch_idx: 60 |  Loss: (0.1561) | Acc: (94.56%) (7383/7808)\n",
            "Epoch: 47 | Batch_idx: 70 |  Loss: (0.1554) | Acc: (94.65%) (8602/9088)\n",
            "Epoch: 47 | Batch_idx: 80 |  Loss: (0.1531) | Acc: (94.65%) (9813/10368)\n",
            "Epoch: 47 | Batch_idx: 90 |  Loss: (0.1530) | Acc: (94.68%) (11028/11648)\n",
            "Epoch: 47 | Batch_idx: 100 |  Loss: (0.1524) | Acc: (94.74%) (12248/12928)\n",
            "Epoch: 47 | Batch_idx: 110 |  Loss: (0.1502) | Acc: (94.83%) (13474/14208)\n",
            "Epoch: 47 | Batch_idx: 120 |  Loss: (0.1484) | Acc: (94.88%) (14695/15488)\n",
            "Epoch: 47 | Batch_idx: 130 |  Loss: (0.1503) | Acc: (94.84%) (15903/16768)\n",
            "Epoch: 47 | Batch_idx: 140 |  Loss: (0.1504) | Acc: (94.81%) (17112/18048)\n",
            "Epoch: 47 | Batch_idx: 150 |  Loss: (0.1502) | Acc: (94.77%) (18317/19328)\n",
            "Epoch: 47 | Batch_idx: 160 |  Loss: (0.1493) | Acc: (94.76%) (19529/20608)\n",
            "Epoch: 47 | Batch_idx: 170 |  Loss: (0.1498) | Acc: (94.76%) (20741/21888)\n",
            "Epoch: 47 | Batch_idx: 180 |  Loss: (0.1494) | Acc: (94.79%) (21961/23168)\n",
            "Epoch: 47 | Batch_idx: 190 |  Loss: (0.1492) | Acc: (94.77%) (23169/24448)\n",
            "Epoch: 47 | Batch_idx: 200 |  Loss: (0.1492) | Acc: (94.77%) (24383/25728)\n",
            "Epoch: 47 | Batch_idx: 210 |  Loss: (0.1483) | Acc: (94.78%) (25599/27008)\n",
            "Epoch: 47 | Batch_idx: 220 |  Loss: (0.1482) | Acc: (94.78%) (26811/28288)\n",
            "Epoch: 47 | Batch_idx: 230 |  Loss: (0.1485) | Acc: (94.78%) (28026/29568)\n",
            "Epoch: 47 | Batch_idx: 240 |  Loss: (0.1502) | Acc: (94.71%) (29217/30848)\n",
            "Epoch: 47 | Batch_idx: 250 |  Loss: (0.1511) | Acc: (94.68%) (30420/32128)\n",
            "Epoch: 47 | Batch_idx: 260 |  Loss: (0.1520) | Acc: (94.67%) (31626/33408)\n",
            "Epoch: 47 | Batch_idx: 270 |  Loss: (0.1535) | Acc: (94.61%) (32819/34688)\n",
            "Epoch: 47 | Batch_idx: 280 |  Loss: (0.1544) | Acc: (94.58%) (34019/35968)\n",
            "Epoch: 47 | Batch_idx: 290 |  Loss: (0.1549) | Acc: (94.56%) (35223/37248)\n",
            "Epoch: 47 | Batch_idx: 300 |  Loss: (0.1552) | Acc: (94.54%) (36426/38528)\n",
            "Epoch: 47 | Batch_idx: 310 |  Loss: (0.1557) | Acc: (94.52%) (37626/39808)\n",
            "Epoch: 47 | Batch_idx: 320 |  Loss: (0.1564) | Acc: (94.51%) (38831/41088)\n",
            "Epoch: 47 | Batch_idx: 330 |  Loss: (0.1570) | Acc: (94.48%) (40031/42368)\n",
            "Epoch: 47 | Batch_idx: 340 |  Loss: (0.1577) | Acc: (94.47%) (41235/43648)\n",
            "Epoch: 47 | Batch_idx: 350 |  Loss: (0.1590) | Acc: (94.44%) (42431/44928)\n",
            "Epoch: 47 | Batch_idx: 360 |  Loss: (0.1595) | Acc: (94.42%) (43631/46208)\n",
            "Epoch: 47 | Batch_idx: 370 |  Loss: (0.1599) | Acc: (94.41%) (44835/47488)\n",
            "Epoch: 47 | Batch_idx: 380 |  Loss: (0.1607) | Acc: (94.39%) (46032/48768)\n",
            "Epoch: 47 | Batch_idx: 390 |  Loss: (0.1609) | Acc: (94.38%) (47189/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3634) | Acc: (88.96%) (8896/10000)\n",
            "Epoch: 48 | Batch_idx: 0 |  Loss: (0.1658) | Acc: (93.75%) (120/128)\n",
            "Epoch: 48 | Batch_idx: 10 |  Loss: (0.1438) | Acc: (95.38%) (1343/1408)\n",
            "Epoch: 48 | Batch_idx: 20 |  Loss: (0.1374) | Acc: (95.50%) (2567/2688)\n",
            "Epoch: 48 | Batch_idx: 30 |  Loss: (0.1420) | Acc: (95.24%) (3779/3968)\n",
            "Epoch: 48 | Batch_idx: 40 |  Loss: (0.1476) | Acc: (94.86%) (4978/5248)\n",
            "Epoch: 48 | Batch_idx: 50 |  Loss: (0.1524) | Acc: (94.72%) (6183/6528)\n",
            "Epoch: 48 | Batch_idx: 60 |  Loss: (0.1532) | Acc: (94.65%) (7390/7808)\n",
            "Epoch: 48 | Batch_idx: 70 |  Loss: (0.1536) | Acc: (94.67%) (8604/9088)\n",
            "Epoch: 48 | Batch_idx: 80 |  Loss: (0.1527) | Acc: (94.65%) (9813/10368)\n",
            "Epoch: 48 | Batch_idx: 90 |  Loss: (0.1521) | Acc: (94.69%) (11029/11648)\n",
            "Epoch: 48 | Batch_idx: 100 |  Loss: (0.1508) | Acc: (94.71%) (12244/12928)\n",
            "Epoch: 48 | Batch_idx: 110 |  Loss: (0.1520) | Acc: (94.66%) (13449/14208)\n",
            "Epoch: 48 | Batch_idx: 120 |  Loss: (0.1499) | Acc: (94.73%) (14672/15488)\n",
            "Epoch: 48 | Batch_idx: 130 |  Loss: (0.1498) | Acc: (94.69%) (15878/16768)\n",
            "Epoch: 48 | Batch_idx: 140 |  Loss: (0.1503) | Acc: (94.69%) (17089/18048)\n",
            "Epoch: 48 | Batch_idx: 150 |  Loss: (0.1504) | Acc: (94.66%) (18295/19328)\n",
            "Epoch: 48 | Batch_idx: 160 |  Loss: (0.1516) | Acc: (94.67%) (19510/20608)\n",
            "Epoch: 48 | Batch_idx: 170 |  Loss: (0.1527) | Acc: (94.67%) (20721/21888)\n",
            "Epoch: 48 | Batch_idx: 180 |  Loss: (0.1531) | Acc: (94.66%) (21930/23168)\n",
            "Epoch: 48 | Batch_idx: 190 |  Loss: (0.1550) | Acc: (94.60%) (23128/24448)\n",
            "Epoch: 48 | Batch_idx: 200 |  Loss: (0.1541) | Acc: (94.64%) (24349/25728)\n",
            "Epoch: 48 | Batch_idx: 210 |  Loss: (0.1541) | Acc: (94.64%) (25560/27008)\n",
            "Epoch: 48 | Batch_idx: 220 |  Loss: (0.1542) | Acc: (94.62%) (26767/28288)\n",
            "Epoch: 48 | Batch_idx: 230 |  Loss: (0.1537) | Acc: (94.64%) (27984/29568)\n",
            "Epoch: 48 | Batch_idx: 240 |  Loss: (0.1557) | Acc: (94.59%) (29178/30848)\n",
            "Epoch: 48 | Batch_idx: 250 |  Loss: (0.1566) | Acc: (94.56%) (30379/32128)\n",
            "Epoch: 48 | Batch_idx: 260 |  Loss: (0.1557) | Acc: (94.61%) (31608/33408)\n",
            "Epoch: 48 | Batch_idx: 270 |  Loss: (0.1554) | Acc: (94.64%) (32827/34688)\n",
            "Epoch: 48 | Batch_idx: 280 |  Loss: (0.1551) | Acc: (94.63%) (34036/35968)\n",
            "Epoch: 48 | Batch_idx: 290 |  Loss: (0.1562) | Acc: (94.60%) (35236/37248)\n",
            "Epoch: 48 | Batch_idx: 300 |  Loss: (0.1567) | Acc: (94.59%) (36442/38528)\n",
            "Epoch: 48 | Batch_idx: 310 |  Loss: (0.1574) | Acc: (94.56%) (37641/39808)\n",
            "Epoch: 48 | Batch_idx: 320 |  Loss: (0.1578) | Acc: (94.54%) (38845/41088)\n",
            "Epoch: 48 | Batch_idx: 330 |  Loss: (0.1581) | Acc: (94.53%) (40050/42368)\n",
            "Epoch: 48 | Batch_idx: 340 |  Loss: (0.1585) | Acc: (94.49%) (41245/43648)\n",
            "Epoch: 48 | Batch_idx: 350 |  Loss: (0.1588) | Acc: (94.48%) (42448/44928)\n",
            "Epoch: 48 | Batch_idx: 360 |  Loss: (0.1584) | Acc: (94.49%) (43663/46208)\n",
            "Epoch: 48 | Batch_idx: 370 |  Loss: (0.1593) | Acc: (94.46%) (44857/47488)\n",
            "Epoch: 48 | Batch_idx: 380 |  Loss: (0.1599) | Acc: (94.43%) (46054/48768)\n",
            "Epoch: 48 | Batch_idx: 390 |  Loss: (0.1605) | Acc: (94.41%) (47204/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3934) | Acc: (88.08%) (8808/10000)\n",
            "Epoch: 49 | Batch_idx: 0 |  Loss: (0.0958) | Acc: (93.75%) (120/128)\n",
            "Epoch: 49 | Batch_idx: 10 |  Loss: (0.1372) | Acc: (94.96%) (1337/1408)\n",
            "Epoch: 49 | Batch_idx: 20 |  Loss: (0.1363) | Acc: (95.13%) (2557/2688)\n",
            "Epoch: 49 | Batch_idx: 30 |  Loss: (0.1346) | Acc: (95.41%) (3786/3968)\n",
            "Epoch: 49 | Batch_idx: 40 |  Loss: (0.1325) | Acc: (95.41%) (5007/5248)\n",
            "Epoch: 49 | Batch_idx: 50 |  Loss: (0.1357) | Acc: (95.36%) (6225/6528)\n",
            "Epoch: 49 | Batch_idx: 60 |  Loss: (0.1365) | Acc: (95.41%) (7450/7808)\n",
            "Epoch: 49 | Batch_idx: 70 |  Loss: (0.1415) | Acc: (95.21%) (8653/9088)\n",
            "Epoch: 49 | Batch_idx: 80 |  Loss: (0.1420) | Acc: (95.14%) (9864/10368)\n",
            "Epoch: 49 | Batch_idx: 90 |  Loss: (0.1412) | Acc: (95.11%) (11078/11648)\n",
            "Epoch: 49 | Batch_idx: 100 |  Loss: (0.1429) | Acc: (95.01%) (12283/12928)\n",
            "Epoch: 49 | Batch_idx: 110 |  Loss: (0.1465) | Acc: (94.86%) (13478/14208)\n",
            "Epoch: 49 | Batch_idx: 120 |  Loss: (0.1499) | Acc: (94.74%) (14674/15488)\n",
            "Epoch: 49 | Batch_idx: 130 |  Loss: (0.1501) | Acc: (94.72%) (15882/16768)\n",
            "Epoch: 49 | Batch_idx: 140 |  Loss: (0.1502) | Acc: (94.71%) (17093/18048)\n",
            "Epoch: 49 | Batch_idx: 150 |  Loss: (0.1506) | Acc: (94.72%) (18308/19328)\n",
            "Epoch: 49 | Batch_idx: 160 |  Loss: (0.1512) | Acc: (94.68%) (19512/20608)\n",
            "Epoch: 49 | Batch_idx: 170 |  Loss: (0.1526) | Acc: (94.66%) (20719/21888)\n",
            "Epoch: 49 | Batch_idx: 180 |  Loss: (0.1519) | Acc: (94.70%) (21939/23168)\n",
            "Epoch: 49 | Batch_idx: 190 |  Loss: (0.1521) | Acc: (94.70%) (23153/24448)\n",
            "Epoch: 49 | Batch_idx: 200 |  Loss: (0.1533) | Acc: (94.68%) (24359/25728)\n",
            "Epoch: 49 | Batch_idx: 210 |  Loss: (0.1543) | Acc: (94.65%) (25562/27008)\n",
            "Epoch: 49 | Batch_idx: 220 |  Loss: (0.1546) | Acc: (94.64%) (26772/28288)\n",
            "Epoch: 49 | Batch_idx: 230 |  Loss: (0.1553) | Acc: (94.60%) (27971/29568)\n",
            "Epoch: 49 | Batch_idx: 240 |  Loss: (0.1564) | Acc: (94.58%) (29177/30848)\n",
            "Epoch: 49 | Batch_idx: 250 |  Loss: (0.1564) | Acc: (94.57%) (30383/32128)\n",
            "Epoch: 49 | Batch_idx: 260 |  Loss: (0.1562) | Acc: (94.58%) (31597/33408)\n",
            "Epoch: 49 | Batch_idx: 270 |  Loss: (0.1564) | Acc: (94.56%) (32800/34688)\n",
            "Epoch: 49 | Batch_idx: 280 |  Loss: (0.1566) | Acc: (94.57%) (34015/35968)\n",
            "Epoch: 49 | Batch_idx: 290 |  Loss: (0.1565) | Acc: (94.58%) (35228/37248)\n",
            "Epoch: 49 | Batch_idx: 300 |  Loss: (0.1567) | Acc: (94.55%) (36429/38528)\n",
            "Epoch: 49 | Batch_idx: 310 |  Loss: (0.1573) | Acc: (94.52%) (37626/39808)\n",
            "Epoch: 49 | Batch_idx: 320 |  Loss: (0.1579) | Acc: (94.51%) (38832/41088)\n",
            "Epoch: 49 | Batch_idx: 330 |  Loss: (0.1576) | Acc: (94.53%) (40050/42368)\n",
            "Epoch: 49 | Batch_idx: 340 |  Loss: (0.1580) | Acc: (94.49%) (41245/43648)\n",
            "Epoch: 49 | Batch_idx: 350 |  Loss: (0.1582) | Acc: (94.47%) (42443/44928)\n",
            "Epoch: 49 | Batch_idx: 360 |  Loss: (0.1586) | Acc: (94.45%) (43645/46208)\n",
            "Epoch: 49 | Batch_idx: 370 |  Loss: (0.1591) | Acc: (94.43%) (44843/47488)\n",
            "Epoch: 49 | Batch_idx: 380 |  Loss: (0.1602) | Acc: (94.39%) (46030/48768)\n",
            "Epoch: 49 | Batch_idx: 390 |  Loss: (0.1603) | Acc: (94.40%) (47198/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3779) | Acc: (89.05%) (8905/10000)\n",
            "Epoch: 50 | Batch_idx: 0 |  Loss: (0.1899) | Acc: (94.53%) (121/128)\n",
            "Epoch: 50 | Batch_idx: 10 |  Loss: (0.1428) | Acc: (95.24%) (1341/1408)\n",
            "Epoch: 50 | Batch_idx: 20 |  Loss: (0.1526) | Acc: (94.87%) (2550/2688)\n",
            "Epoch: 50 | Batch_idx: 30 |  Loss: (0.1409) | Acc: (95.24%) (3779/3968)\n",
            "Epoch: 50 | Batch_idx: 40 |  Loss: (0.1428) | Acc: (95.08%) (4990/5248)\n",
            "Epoch: 50 | Batch_idx: 50 |  Loss: (0.1437) | Acc: (94.93%) (6197/6528)\n",
            "Epoch: 50 | Batch_idx: 60 |  Loss: (0.1401) | Acc: (95.08%) (7424/7808)\n",
            "Epoch: 50 | Batch_idx: 70 |  Loss: (0.1384) | Acc: (95.16%) (8648/9088)\n",
            "Epoch: 50 | Batch_idx: 80 |  Loss: (0.1394) | Acc: (95.16%) (9866/10368)\n",
            "Epoch: 50 | Batch_idx: 90 |  Loss: (0.1400) | Acc: (95.16%) (11084/11648)\n",
            "Epoch: 50 | Batch_idx: 100 |  Loss: (0.1397) | Acc: (95.17%) (12304/12928)\n",
            "Epoch: 50 | Batch_idx: 110 |  Loss: (0.1404) | Acc: (95.18%) (13523/14208)\n",
            "Epoch: 50 | Batch_idx: 120 |  Loss: (0.1409) | Acc: (95.16%) (14739/15488)\n",
            "Epoch: 50 | Batch_idx: 130 |  Loss: (0.1420) | Acc: (95.06%) (15940/16768)\n",
            "Epoch: 50 | Batch_idx: 140 |  Loss: (0.1445) | Acc: (94.96%) (17138/18048)\n",
            "Epoch: 50 | Batch_idx: 150 |  Loss: (0.1460) | Acc: (94.89%) (18341/19328)\n",
            "Epoch: 50 | Batch_idx: 160 |  Loss: (0.1475) | Acc: (94.85%) (19546/20608)\n",
            "Epoch: 50 | Batch_idx: 170 |  Loss: (0.1485) | Acc: (94.81%) (20752/21888)\n",
            "Epoch: 50 | Batch_idx: 180 |  Loss: (0.1485) | Acc: (94.82%) (21969/23168)\n",
            "Epoch: 50 | Batch_idx: 190 |  Loss: (0.1481) | Acc: (94.82%) (23182/24448)\n",
            "Epoch: 50 | Batch_idx: 200 |  Loss: (0.1481) | Acc: (94.83%) (24397/25728)\n",
            "Epoch: 50 | Batch_idx: 210 |  Loss: (0.1487) | Acc: (94.78%) (25598/27008)\n",
            "Epoch: 50 | Batch_idx: 220 |  Loss: (0.1495) | Acc: (94.74%) (26801/28288)\n",
            "Epoch: 50 | Batch_idx: 230 |  Loss: (0.1506) | Acc: (94.67%) (27993/29568)\n",
            "Epoch: 50 | Batch_idx: 240 |  Loss: (0.1513) | Acc: (94.67%) (29205/30848)\n",
            "Epoch: 50 | Batch_idx: 250 |  Loss: (0.1511) | Acc: (94.66%) (30412/32128)\n",
            "Epoch: 50 | Batch_idx: 260 |  Loss: (0.1519) | Acc: (94.61%) (31607/33408)\n",
            "Epoch: 50 | Batch_idx: 270 |  Loss: (0.1534) | Acc: (94.55%) (32799/34688)\n",
            "Epoch: 50 | Batch_idx: 280 |  Loss: (0.1531) | Acc: (94.58%) (34018/35968)\n",
            "Epoch: 50 | Batch_idx: 290 |  Loss: (0.1527) | Acc: (94.60%) (35236/37248)\n",
            "Epoch: 50 | Batch_idx: 300 |  Loss: (0.1538) | Acc: (94.55%) (36429/38528)\n",
            "Epoch: 50 | Batch_idx: 310 |  Loss: (0.1546) | Acc: (94.54%) (37635/39808)\n",
            "Epoch: 50 | Batch_idx: 320 |  Loss: (0.1549) | Acc: (94.54%) (38844/41088)\n",
            "Epoch: 50 | Batch_idx: 330 |  Loss: (0.1556) | Acc: (94.51%) (40042/42368)\n",
            "Epoch: 50 | Batch_idx: 340 |  Loss: (0.1566) | Acc: (94.48%) (41238/43648)\n",
            "Epoch: 50 | Batch_idx: 350 |  Loss: (0.1564) | Acc: (94.48%) (42447/44928)\n",
            "Epoch: 50 | Batch_idx: 360 |  Loss: (0.1570) | Acc: (94.46%) (43646/46208)\n",
            "Epoch: 50 | Batch_idx: 370 |  Loss: (0.1575) | Acc: (94.46%) (44856/47488)\n",
            "Epoch: 50 | Batch_idx: 380 |  Loss: (0.1580) | Acc: (94.45%) (46059/48768)\n",
            "Epoch: 50 | Batch_idx: 390 |  Loss: (0.1581) | Acc: (94.44%) (47222/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3532) | Acc: (89.54%) (8954/10000)\n",
            "Epoch: 51 | Batch_idx: 0 |  Loss: (0.1483) | Acc: (93.75%) (120/128)\n",
            "Epoch: 51 | Batch_idx: 10 |  Loss: (0.1352) | Acc: (95.60%) (1346/1408)\n",
            "Epoch: 51 | Batch_idx: 20 |  Loss: (0.1334) | Acc: (95.20%) (2559/2688)\n",
            "Epoch: 51 | Batch_idx: 30 |  Loss: (0.1286) | Acc: (95.46%) (3788/3968)\n",
            "Epoch: 51 | Batch_idx: 40 |  Loss: (0.1346) | Acc: (95.31%) (5002/5248)\n",
            "Epoch: 51 | Batch_idx: 50 |  Loss: (0.1350) | Acc: (95.33%) (6223/6528)\n",
            "Epoch: 51 | Batch_idx: 60 |  Loss: (0.1391) | Acc: (95.22%) (7435/7808)\n",
            "Epoch: 51 | Batch_idx: 70 |  Loss: (0.1431) | Acc: (95.16%) (8648/9088)\n",
            "Epoch: 51 | Batch_idx: 80 |  Loss: (0.1397) | Acc: (95.24%) (9875/10368)\n",
            "Epoch: 51 | Batch_idx: 90 |  Loss: (0.1391) | Acc: (95.24%) (11093/11648)\n",
            "Epoch: 51 | Batch_idx: 100 |  Loss: (0.1428) | Acc: (95.16%) (12302/12928)\n",
            "Epoch: 51 | Batch_idx: 110 |  Loss: (0.1439) | Acc: (95.10%) (13512/14208)\n",
            "Epoch: 51 | Batch_idx: 120 |  Loss: (0.1449) | Acc: (95.09%) (14727/15488)\n",
            "Epoch: 51 | Batch_idx: 130 |  Loss: (0.1442) | Acc: (95.06%) (15939/16768)\n",
            "Epoch: 51 | Batch_idx: 140 |  Loss: (0.1460) | Acc: (94.97%) (17141/18048)\n",
            "Epoch: 51 | Batch_idx: 150 |  Loss: (0.1455) | Acc: (95.02%) (18365/19328)\n",
            "Epoch: 51 | Batch_idx: 160 |  Loss: (0.1468) | Acc: (94.96%) (19570/20608)\n",
            "Epoch: 51 | Batch_idx: 170 |  Loss: (0.1472) | Acc: (94.95%) (20783/21888)\n",
            "Epoch: 51 | Batch_idx: 180 |  Loss: (0.1483) | Acc: (94.93%) (21993/23168)\n",
            "Epoch: 51 | Batch_idx: 190 |  Loss: (0.1483) | Acc: (94.90%) (23202/24448)\n",
            "Epoch: 51 | Batch_idx: 200 |  Loss: (0.1483) | Acc: (94.90%) (24417/25728)\n",
            "Epoch: 51 | Batch_idx: 210 |  Loss: (0.1507) | Acc: (94.83%) (25613/27008)\n",
            "Epoch: 51 | Batch_idx: 220 |  Loss: (0.1509) | Acc: (94.79%) (26813/28288)\n",
            "Epoch: 51 | Batch_idx: 230 |  Loss: (0.1511) | Acc: (94.80%) (28029/29568)\n",
            "Epoch: 51 | Batch_idx: 240 |  Loss: (0.1520) | Acc: (94.75%) (29227/30848)\n",
            "Epoch: 51 | Batch_idx: 250 |  Loss: (0.1527) | Acc: (94.73%) (30434/32128)\n",
            "Epoch: 51 | Batch_idx: 260 |  Loss: (0.1523) | Acc: (94.73%) (31648/33408)\n",
            "Epoch: 51 | Batch_idx: 270 |  Loss: (0.1520) | Acc: (94.74%) (32862/34688)\n",
            "Epoch: 51 | Batch_idx: 280 |  Loss: (0.1525) | Acc: (94.74%) (34077/35968)\n",
            "Epoch: 51 | Batch_idx: 290 |  Loss: (0.1526) | Acc: (94.74%) (35288/37248)\n",
            "Epoch: 51 | Batch_idx: 300 |  Loss: (0.1532) | Acc: (94.72%) (36493/38528)\n",
            "Epoch: 51 | Batch_idx: 310 |  Loss: (0.1538) | Acc: (94.68%) (37692/39808)\n",
            "Epoch: 51 | Batch_idx: 320 |  Loss: (0.1538) | Acc: (94.66%) (38895/41088)\n",
            "Epoch: 51 | Batch_idx: 330 |  Loss: (0.1543) | Acc: (94.65%) (40101/42368)\n",
            "Epoch: 51 | Batch_idx: 340 |  Loss: (0.1539) | Acc: (94.65%) (41315/43648)\n",
            "Epoch: 51 | Batch_idx: 350 |  Loss: (0.1536) | Acc: (94.66%) (42531/44928)\n",
            "Epoch: 51 | Batch_idx: 360 |  Loss: (0.1529) | Acc: (94.68%) (43751/46208)\n",
            "Epoch: 51 | Batch_idx: 370 |  Loss: (0.1538) | Acc: (94.64%) (44942/47488)\n",
            "Epoch: 51 | Batch_idx: 380 |  Loss: (0.1530) | Acc: (94.67%) (46167/48768)\n",
            "Epoch: 51 | Batch_idx: 390 |  Loss: (0.1528) | Acc: (94.67%) (47334/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3615) | Acc: (89.85%) (8985/10000)\n",
            "Epoch: 52 | Batch_idx: 0 |  Loss: (0.1437) | Acc: (96.09%) (123/128)\n",
            "Epoch: 52 | Batch_idx: 10 |  Loss: (0.1347) | Acc: (94.82%) (1335/1408)\n",
            "Epoch: 52 | Batch_idx: 20 |  Loss: (0.1258) | Acc: (95.42%) (2565/2688)\n",
            "Epoch: 52 | Batch_idx: 30 |  Loss: (0.1314) | Acc: (95.31%) (3782/3968)\n",
            "Epoch: 52 | Batch_idx: 40 |  Loss: (0.1363) | Acc: (95.18%) (4995/5248)\n",
            "Epoch: 52 | Batch_idx: 50 |  Loss: (0.1416) | Acc: (94.91%) (6196/6528)\n",
            "Epoch: 52 | Batch_idx: 60 |  Loss: (0.1431) | Acc: (94.92%) (7411/7808)\n",
            "Epoch: 52 | Batch_idx: 70 |  Loss: (0.1415) | Acc: (94.95%) (8629/9088)\n",
            "Epoch: 52 | Batch_idx: 80 |  Loss: (0.1436) | Acc: (94.95%) (9844/10368)\n",
            "Epoch: 52 | Batch_idx: 90 |  Loss: (0.1435) | Acc: (94.93%) (11058/11648)\n",
            "Epoch: 52 | Batch_idx: 100 |  Loss: (0.1448) | Acc: (94.90%) (12269/12928)\n",
            "Epoch: 52 | Batch_idx: 110 |  Loss: (0.1442) | Acc: (94.95%) (13490/14208)\n",
            "Epoch: 52 | Batch_idx: 120 |  Loss: (0.1444) | Acc: (94.91%) (14699/15488)\n",
            "Epoch: 52 | Batch_idx: 130 |  Loss: (0.1462) | Acc: (94.87%) (15907/16768)\n",
            "Epoch: 52 | Batch_idx: 140 |  Loss: (0.1452) | Acc: (94.94%) (17135/18048)\n",
            "Epoch: 52 | Batch_idx: 150 |  Loss: (0.1457) | Acc: (94.89%) (18341/19328)\n",
            "Epoch: 52 | Batch_idx: 160 |  Loss: (0.1462) | Acc: (94.85%) (19547/20608)\n",
            "Epoch: 52 | Batch_idx: 170 |  Loss: (0.1445) | Acc: (94.93%) (20778/21888)\n",
            "Epoch: 52 | Batch_idx: 180 |  Loss: (0.1450) | Acc: (94.89%) (21985/23168)\n",
            "Epoch: 52 | Batch_idx: 190 |  Loss: (0.1450) | Acc: (94.90%) (23200/24448)\n",
            "Epoch: 52 | Batch_idx: 200 |  Loss: (0.1447) | Acc: (94.88%) (24412/25728)\n",
            "Epoch: 52 | Batch_idx: 210 |  Loss: (0.1449) | Acc: (94.88%) (25624/27008)\n",
            "Epoch: 52 | Batch_idx: 220 |  Loss: (0.1458) | Acc: (94.82%) (26824/28288)\n",
            "Epoch: 52 | Batch_idx: 230 |  Loss: (0.1460) | Acc: (94.80%) (28029/29568)\n",
            "Epoch: 52 | Batch_idx: 240 |  Loss: (0.1465) | Acc: (94.81%) (29247/30848)\n",
            "Epoch: 52 | Batch_idx: 250 |  Loss: (0.1467) | Acc: (94.81%) (30462/32128)\n",
            "Epoch: 52 | Batch_idx: 260 |  Loss: (0.1475) | Acc: (94.81%) (31673/33408)\n",
            "Epoch: 52 | Batch_idx: 270 |  Loss: (0.1498) | Acc: (94.73%) (32861/34688)\n",
            "Epoch: 52 | Batch_idx: 280 |  Loss: (0.1515) | Acc: (94.67%) (34050/35968)\n",
            "Epoch: 52 | Batch_idx: 290 |  Loss: (0.1521) | Acc: (94.64%) (35253/37248)\n",
            "Epoch: 52 | Batch_idx: 300 |  Loss: (0.1531) | Acc: (94.62%) (36456/38528)\n",
            "Epoch: 52 | Batch_idx: 310 |  Loss: (0.1533) | Acc: (94.62%) (37666/39808)\n",
            "Epoch: 52 | Batch_idx: 320 |  Loss: (0.1538) | Acc: (94.59%) (38867/41088)\n",
            "Epoch: 52 | Batch_idx: 330 |  Loss: (0.1543) | Acc: (94.56%) (40063/42368)\n",
            "Epoch: 52 | Batch_idx: 340 |  Loss: (0.1547) | Acc: (94.54%) (41263/43648)\n",
            "Epoch: 52 | Batch_idx: 350 |  Loss: (0.1549) | Acc: (94.52%) (42467/44928)\n",
            "Epoch: 52 | Batch_idx: 360 |  Loss: (0.1547) | Acc: (94.53%) (43679/46208)\n",
            "Epoch: 52 | Batch_idx: 370 |  Loss: (0.1552) | Acc: (94.50%) (44874/47488)\n",
            "Epoch: 52 | Batch_idx: 380 |  Loss: (0.1558) | Acc: (94.48%) (46077/48768)\n",
            "Epoch: 52 | Batch_idx: 390 |  Loss: (0.1559) | Acc: (94.48%) (47238/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3826) | Acc: (88.81%) (8881/10000)\n",
            "Epoch: 53 | Batch_idx: 0 |  Loss: (0.1493) | Acc: (94.53%) (121/128)\n",
            "Epoch: 53 | Batch_idx: 10 |  Loss: (0.1282) | Acc: (95.81%) (1349/1408)\n",
            "Epoch: 53 | Batch_idx: 20 |  Loss: (0.1401) | Acc: (95.16%) (2558/2688)\n",
            "Epoch: 53 | Batch_idx: 30 |  Loss: (0.1423) | Acc: (94.96%) (3768/3968)\n",
            "Epoch: 53 | Batch_idx: 40 |  Loss: (0.1373) | Acc: (95.33%) (5003/5248)\n",
            "Epoch: 53 | Batch_idx: 50 |  Loss: (0.1385) | Acc: (95.22%) (6216/6528)\n",
            "Epoch: 53 | Batch_idx: 60 |  Loss: (0.1375) | Acc: (95.33%) (7443/7808)\n",
            "Epoch: 53 | Batch_idx: 70 |  Loss: (0.1374) | Acc: (95.30%) (8661/9088)\n",
            "Epoch: 53 | Batch_idx: 80 |  Loss: (0.1386) | Acc: (95.23%) (9873/10368)\n",
            "Epoch: 53 | Batch_idx: 90 |  Loss: (0.1386) | Acc: (95.22%) (11091/11648)\n",
            "Epoch: 53 | Batch_idx: 100 |  Loss: (0.1370) | Acc: (95.25%) (12314/12928)\n",
            "Epoch: 53 | Batch_idx: 110 |  Loss: (0.1398) | Acc: (95.11%) (13513/14208)\n",
            "Epoch: 53 | Batch_idx: 120 |  Loss: (0.1399) | Acc: (95.09%) (14727/15488)\n",
            "Epoch: 53 | Batch_idx: 130 |  Loss: (0.1408) | Acc: (95.06%) (15940/16768)\n",
            "Epoch: 53 | Batch_idx: 140 |  Loss: (0.1408) | Acc: (95.05%) (17154/18048)\n",
            "Epoch: 53 | Batch_idx: 150 |  Loss: (0.1412) | Acc: (95.05%) (18372/19328)\n",
            "Epoch: 53 | Batch_idx: 160 |  Loss: (0.1424) | Acc: (95.03%) (19583/20608)\n",
            "Epoch: 53 | Batch_idx: 170 |  Loss: (0.1427) | Acc: (95.01%) (20796/21888)\n",
            "Epoch: 53 | Batch_idx: 180 |  Loss: (0.1439) | Acc: (95.00%) (22009/23168)\n",
            "Epoch: 53 | Batch_idx: 190 |  Loss: (0.1446) | Acc: (94.95%) (23213/24448)\n",
            "Epoch: 53 | Batch_idx: 200 |  Loss: (0.1452) | Acc: (94.92%) (24420/25728)\n",
            "Epoch: 53 | Batch_idx: 210 |  Loss: (0.1467) | Acc: (94.88%) (25625/27008)\n",
            "Epoch: 53 | Batch_idx: 220 |  Loss: (0.1473) | Acc: (94.84%) (26828/28288)\n",
            "Epoch: 53 | Batch_idx: 230 |  Loss: (0.1478) | Acc: (94.80%) (28029/29568)\n",
            "Epoch: 53 | Batch_idx: 240 |  Loss: (0.1489) | Acc: (94.75%) (29230/30848)\n",
            "Epoch: 53 | Batch_idx: 250 |  Loss: (0.1484) | Acc: (94.74%) (30438/32128)\n",
            "Epoch: 53 | Batch_idx: 260 |  Loss: (0.1482) | Acc: (94.76%) (31658/33408)\n",
            "Epoch: 53 | Batch_idx: 270 |  Loss: (0.1483) | Acc: (94.76%) (32872/34688)\n",
            "Epoch: 53 | Batch_idx: 280 |  Loss: (0.1489) | Acc: (94.74%) (34076/35968)\n",
            "Epoch: 53 | Batch_idx: 290 |  Loss: (0.1486) | Acc: (94.78%) (35304/37248)\n",
            "Epoch: 53 | Batch_idx: 300 |  Loss: (0.1484) | Acc: (94.77%) (36513/38528)\n",
            "Epoch: 53 | Batch_idx: 310 |  Loss: (0.1489) | Acc: (94.74%) (37716/39808)\n",
            "Epoch: 53 | Batch_idx: 320 |  Loss: (0.1482) | Acc: (94.78%) (38942/41088)\n",
            "Epoch: 53 | Batch_idx: 330 |  Loss: (0.1484) | Acc: (94.75%) (40145/42368)\n",
            "Epoch: 53 | Batch_idx: 340 |  Loss: (0.1490) | Acc: (94.74%) (41351/43648)\n",
            "Epoch: 53 | Batch_idx: 350 |  Loss: (0.1491) | Acc: (94.73%) (42561/44928)\n",
            "Epoch: 53 | Batch_idx: 360 |  Loss: (0.1491) | Acc: (94.74%) (43778/46208)\n",
            "Epoch: 53 | Batch_idx: 370 |  Loss: (0.1496) | Acc: (94.72%) (44983/47488)\n",
            "Epoch: 53 | Batch_idx: 380 |  Loss: (0.1504) | Acc: (94.70%) (46185/48768)\n",
            "Epoch: 53 | Batch_idx: 390 |  Loss: (0.1510) | Acc: (94.68%) (47342/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3799) | Acc: (89.02%) (8902/10000)\n",
            "Epoch: 54 | Batch_idx: 0 |  Loss: (0.0657) | Acc: (97.66%) (125/128)\n",
            "Epoch: 54 | Batch_idx: 10 |  Loss: (0.1172) | Acc: (95.60%) (1346/1408)\n",
            "Epoch: 54 | Batch_idx: 20 |  Loss: (0.1270) | Acc: (95.50%) (2567/2688)\n",
            "Epoch: 54 | Batch_idx: 30 |  Loss: (0.1310) | Acc: (95.26%) (3780/3968)\n",
            "Epoch: 54 | Batch_idx: 40 |  Loss: (0.1310) | Acc: (95.35%) (5004/5248)\n",
            "Epoch: 54 | Batch_idx: 50 |  Loss: (0.1354) | Acc: (95.21%) (6215/6528)\n",
            "Epoch: 54 | Batch_idx: 60 |  Loss: (0.1317) | Acc: (95.48%) (7455/7808)\n",
            "Epoch: 54 | Batch_idx: 70 |  Loss: (0.1290) | Acc: (95.58%) (8686/9088)\n",
            "Epoch: 54 | Batch_idx: 80 |  Loss: (0.1292) | Acc: (95.52%) (9904/10368)\n",
            "Epoch: 54 | Batch_idx: 90 |  Loss: (0.1312) | Acc: (95.48%) (11122/11648)\n",
            "Epoch: 54 | Batch_idx: 100 |  Loss: (0.1329) | Acc: (95.39%) (12332/12928)\n",
            "Epoch: 54 | Batch_idx: 110 |  Loss: (0.1354) | Acc: (95.31%) (13541/14208)\n",
            "Epoch: 54 | Batch_idx: 120 |  Loss: (0.1373) | Acc: (95.24%) (14750/15488)\n",
            "Epoch: 54 | Batch_idx: 130 |  Loss: (0.1355) | Acc: (95.27%) (15975/16768)\n",
            "Epoch: 54 | Batch_idx: 140 |  Loss: (0.1362) | Acc: (95.26%) (17192/18048)\n",
            "Epoch: 54 | Batch_idx: 150 |  Loss: (0.1365) | Acc: (95.29%) (18418/19328)\n",
            "Epoch: 54 | Batch_idx: 160 |  Loss: (0.1376) | Acc: (95.23%) (19625/20608)\n",
            "Epoch: 54 | Batch_idx: 170 |  Loss: (0.1386) | Acc: (95.18%) (20833/21888)\n",
            "Epoch: 54 | Batch_idx: 180 |  Loss: (0.1396) | Acc: (95.16%) (22046/23168)\n",
            "Epoch: 54 | Batch_idx: 190 |  Loss: (0.1399) | Acc: (95.15%) (23262/24448)\n",
            "Epoch: 54 | Batch_idx: 200 |  Loss: (0.1408) | Acc: (95.11%) (24470/25728)\n",
            "Epoch: 54 | Batch_idx: 210 |  Loss: (0.1416) | Acc: (95.07%) (25677/27008)\n",
            "Epoch: 54 | Batch_idx: 220 |  Loss: (0.1414) | Acc: (95.07%) (26893/28288)\n",
            "Epoch: 54 | Batch_idx: 230 |  Loss: (0.1426) | Acc: (95.04%) (28100/29568)\n",
            "Epoch: 54 | Batch_idx: 240 |  Loss: (0.1422) | Acc: (95.04%) (29317/30848)\n",
            "Epoch: 54 | Batch_idx: 250 |  Loss: (0.1423) | Acc: (95.04%) (30533/32128)\n",
            "Epoch: 54 | Batch_idx: 260 |  Loss: (0.1422) | Acc: (95.05%) (31755/33408)\n",
            "Epoch: 54 | Batch_idx: 270 |  Loss: (0.1435) | Acc: (95.02%) (32960/34688)\n",
            "Epoch: 54 | Batch_idx: 280 |  Loss: (0.1439) | Acc: (94.99%) (34166/35968)\n",
            "Epoch: 54 | Batch_idx: 290 |  Loss: (0.1444) | Acc: (94.95%) (35366/37248)\n",
            "Epoch: 54 | Batch_idx: 300 |  Loss: (0.1443) | Acc: (94.94%) (36579/38528)\n",
            "Epoch: 54 | Batch_idx: 310 |  Loss: (0.1442) | Acc: (94.93%) (37788/39808)\n",
            "Epoch: 54 | Batch_idx: 320 |  Loss: (0.1444) | Acc: (94.91%) (38998/41088)\n",
            "Epoch: 54 | Batch_idx: 330 |  Loss: (0.1444) | Acc: (94.92%) (40214/42368)\n",
            "Epoch: 54 | Batch_idx: 340 |  Loss: (0.1455) | Acc: (94.87%) (41408/43648)\n",
            "Epoch: 54 | Batch_idx: 350 |  Loss: (0.1458) | Acc: (94.85%) (42616/44928)\n",
            "Epoch: 54 | Batch_idx: 360 |  Loss: (0.1466) | Acc: (94.83%) (43817/46208)\n",
            "Epoch: 54 | Batch_idx: 370 |  Loss: (0.1469) | Acc: (94.80%) (45020/47488)\n",
            "Epoch: 54 | Batch_idx: 380 |  Loss: (0.1480) | Acc: (94.77%) (46219/48768)\n",
            "Epoch: 54 | Batch_idx: 390 |  Loss: (0.1489) | Acc: (94.74%) (47372/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3822) | Acc: (88.87%) (8887/10000)\n",
            "Epoch: 55 | Batch_idx: 0 |  Loss: (0.1302) | Acc: (95.31%) (122/128)\n",
            "Epoch: 55 | Batch_idx: 10 |  Loss: (0.1375) | Acc: (94.82%) (1335/1408)\n",
            "Epoch: 55 | Batch_idx: 20 |  Loss: (0.1417) | Acc: (94.75%) (2547/2688)\n",
            "Epoch: 55 | Batch_idx: 30 |  Loss: (0.1430) | Acc: (94.86%) (3764/3968)\n",
            "Epoch: 55 | Batch_idx: 40 |  Loss: (0.1442) | Acc: (94.97%) (4984/5248)\n",
            "Epoch: 55 | Batch_idx: 50 |  Loss: (0.1389) | Acc: (95.19%) (6214/6528)\n",
            "Epoch: 55 | Batch_idx: 60 |  Loss: (0.1439) | Acc: (95.03%) (7420/7808)\n",
            "Epoch: 55 | Batch_idx: 70 |  Loss: (0.1430) | Acc: (95.09%) (8642/9088)\n",
            "Epoch: 55 | Batch_idx: 80 |  Loss: (0.1441) | Acc: (95.08%) (9858/10368)\n",
            "Epoch: 55 | Batch_idx: 90 |  Loss: (0.1435) | Acc: (95.08%) (11075/11648)\n",
            "Epoch: 55 | Batch_idx: 100 |  Loss: (0.1481) | Acc: (94.93%) (12273/12928)\n",
            "Epoch: 55 | Batch_idx: 110 |  Loss: (0.1486) | Acc: (94.90%) (13484/14208)\n",
            "Epoch: 55 | Batch_idx: 120 |  Loss: (0.1502) | Acc: (94.76%) (14676/15488)\n",
            "Epoch: 55 | Batch_idx: 130 |  Loss: (0.1493) | Acc: (94.73%) (15884/16768)\n",
            "Epoch: 55 | Batch_idx: 140 |  Loss: (0.1500) | Acc: (94.70%) (17091/18048)\n",
            "Epoch: 55 | Batch_idx: 150 |  Loss: (0.1495) | Acc: (94.73%) (18309/19328)\n",
            "Epoch: 55 | Batch_idx: 160 |  Loss: (0.1501) | Acc: (94.73%) (19521/20608)\n",
            "Epoch: 55 | Batch_idx: 170 |  Loss: (0.1493) | Acc: (94.74%) (20737/21888)\n",
            "Epoch: 55 | Batch_idx: 180 |  Loss: (0.1504) | Acc: (94.73%) (21946/23168)\n",
            "Epoch: 55 | Batch_idx: 190 |  Loss: (0.1524) | Acc: (94.66%) (23143/24448)\n",
            "Epoch: 55 | Batch_idx: 200 |  Loss: (0.1517) | Acc: (94.68%) (24359/25728)\n",
            "Epoch: 55 | Batch_idx: 210 |  Loss: (0.1536) | Acc: (94.63%) (25558/27008)\n",
            "Epoch: 55 | Batch_idx: 220 |  Loss: (0.1540) | Acc: (94.60%) (26760/28288)\n",
            "Epoch: 55 | Batch_idx: 230 |  Loss: (0.1545) | Acc: (94.57%) (27962/29568)\n",
            "Epoch: 55 | Batch_idx: 240 |  Loss: (0.1540) | Acc: (94.57%) (29174/30848)\n",
            "Epoch: 55 | Batch_idx: 250 |  Loss: (0.1534) | Acc: (94.59%) (30390/32128)\n",
            "Epoch: 55 | Batch_idx: 260 |  Loss: (0.1537) | Acc: (94.59%) (31600/33408)\n",
            "Epoch: 55 | Batch_idx: 270 |  Loss: (0.1537) | Acc: (94.58%) (32808/34688)\n",
            "Epoch: 55 | Batch_idx: 280 |  Loss: (0.1540) | Acc: (94.57%) (34014/35968)\n",
            "Epoch: 55 | Batch_idx: 290 |  Loss: (0.1539) | Acc: (94.56%) (35222/37248)\n",
            "Epoch: 55 | Batch_idx: 300 |  Loss: (0.1545) | Acc: (94.53%) (36421/38528)\n",
            "Epoch: 55 | Batch_idx: 310 |  Loss: (0.1546) | Acc: (94.53%) (37632/39808)\n",
            "Epoch: 55 | Batch_idx: 320 |  Loss: (0.1550) | Acc: (94.52%) (38836/41088)\n",
            "Epoch: 55 | Batch_idx: 330 |  Loss: (0.1554) | Acc: (94.49%) (40035/42368)\n",
            "Epoch: 55 | Batch_idx: 340 |  Loss: (0.1562) | Acc: (94.46%) (41228/43648)\n",
            "Epoch: 55 | Batch_idx: 350 |  Loss: (0.1566) | Acc: (94.44%) (42428/44928)\n",
            "Epoch: 55 | Batch_idx: 360 |  Loss: (0.1576) | Acc: (94.41%) (43625/46208)\n",
            "Epoch: 55 | Batch_idx: 370 |  Loss: (0.1577) | Acc: (94.41%) (44832/47488)\n",
            "Epoch: 55 | Batch_idx: 380 |  Loss: (0.1578) | Acc: (94.43%) (46050/48768)\n",
            "Epoch: 55 | Batch_idx: 390 |  Loss: (0.1578) | Acc: (94.44%) (47221/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4143) | Acc: (88.09%) (8809/10000)\n",
            "Epoch: 56 | Batch_idx: 0 |  Loss: (0.0992) | Acc: (97.66%) (125/128)\n",
            "Epoch: 56 | Batch_idx: 10 |  Loss: (0.1247) | Acc: (95.81%) (1349/1408)\n",
            "Epoch: 56 | Batch_idx: 20 |  Loss: (0.1356) | Acc: (95.16%) (2558/2688)\n",
            "Epoch: 56 | Batch_idx: 30 |  Loss: (0.1379) | Acc: (94.93%) (3767/3968)\n",
            "Epoch: 56 | Batch_idx: 40 |  Loss: (0.1358) | Acc: (95.06%) (4989/5248)\n",
            "Epoch: 56 | Batch_idx: 50 |  Loss: (0.1352) | Acc: (95.27%) (6219/6528)\n",
            "Epoch: 56 | Batch_idx: 60 |  Loss: (0.1383) | Acc: (95.12%) (7427/7808)\n",
            "Epoch: 56 | Batch_idx: 70 |  Loss: (0.1372) | Acc: (95.20%) (8652/9088)\n",
            "Epoch: 56 | Batch_idx: 80 |  Loss: (0.1367) | Acc: (95.24%) (9874/10368)\n",
            "Epoch: 56 | Batch_idx: 90 |  Loss: (0.1363) | Acc: (95.24%) (11094/11648)\n",
            "Epoch: 56 | Batch_idx: 100 |  Loss: (0.1372) | Acc: (95.22%) (12310/12928)\n",
            "Epoch: 56 | Batch_idx: 110 |  Loss: (0.1375) | Acc: (95.15%) (13519/14208)\n",
            "Epoch: 56 | Batch_idx: 120 |  Loss: (0.1364) | Acc: (95.18%) (14741/15488)\n",
            "Epoch: 56 | Batch_idx: 130 |  Loss: (0.1353) | Acc: (95.22%) (15967/16768)\n",
            "Epoch: 56 | Batch_idx: 140 |  Loss: (0.1353) | Acc: (95.20%) (17181/18048)\n",
            "Epoch: 56 | Batch_idx: 150 |  Loss: (0.1357) | Acc: (95.20%) (18401/19328)\n",
            "Epoch: 56 | Batch_idx: 160 |  Loss: (0.1361) | Acc: (95.21%) (19620/20608)\n",
            "Epoch: 56 | Batch_idx: 170 |  Loss: (0.1372) | Acc: (95.17%) (20831/21888)\n",
            "Epoch: 56 | Batch_idx: 180 |  Loss: (0.1385) | Acc: (95.11%) (22036/23168)\n",
            "Epoch: 56 | Batch_idx: 190 |  Loss: (0.1392) | Acc: (95.08%) (23246/24448)\n",
            "Epoch: 56 | Batch_idx: 200 |  Loss: (0.1394) | Acc: (95.08%) (24462/25728)\n",
            "Epoch: 56 | Batch_idx: 210 |  Loss: (0.1399) | Acc: (95.06%) (25674/27008)\n",
            "Epoch: 56 | Batch_idx: 220 |  Loss: (0.1395) | Acc: (95.09%) (26900/28288)\n",
            "Epoch: 56 | Batch_idx: 230 |  Loss: (0.1407) | Acc: (95.05%) (28105/29568)\n",
            "Epoch: 56 | Batch_idx: 240 |  Loss: (0.1416) | Acc: (94.99%) (29304/30848)\n",
            "Epoch: 56 | Batch_idx: 250 |  Loss: (0.1431) | Acc: (94.95%) (30505/32128)\n",
            "Epoch: 56 | Batch_idx: 260 |  Loss: (0.1431) | Acc: (94.95%) (31720/33408)\n",
            "Epoch: 56 | Batch_idx: 270 |  Loss: (0.1441) | Acc: (94.93%) (32930/34688)\n",
            "Epoch: 56 | Batch_idx: 280 |  Loss: (0.1448) | Acc: (94.91%) (34136/35968)\n",
            "Epoch: 56 | Batch_idx: 290 |  Loss: (0.1455) | Acc: (94.86%) (35333/37248)\n",
            "Epoch: 56 | Batch_idx: 300 |  Loss: (0.1463) | Acc: (94.83%) (36536/38528)\n",
            "Epoch: 56 | Batch_idx: 310 |  Loss: (0.1466) | Acc: (94.83%) (37750/39808)\n",
            "Epoch: 56 | Batch_idx: 320 |  Loss: (0.1463) | Acc: (94.83%) (38962/41088)\n",
            "Epoch: 56 | Batch_idx: 330 |  Loss: (0.1467) | Acc: (94.81%) (40171/42368)\n",
            "Epoch: 56 | Batch_idx: 340 |  Loss: (0.1467) | Acc: (94.82%) (41385/43648)\n",
            "Epoch: 56 | Batch_idx: 350 |  Loss: (0.1468) | Acc: (94.81%) (42596/44928)\n",
            "Epoch: 56 | Batch_idx: 360 |  Loss: (0.1473) | Acc: (94.80%) (43803/46208)\n",
            "Epoch: 56 | Batch_idx: 370 |  Loss: (0.1475) | Acc: (94.76%) (45001/47488)\n",
            "Epoch: 56 | Batch_idx: 380 |  Loss: (0.1474) | Acc: (94.77%) (46219/48768)\n",
            "Epoch: 56 | Batch_idx: 390 |  Loss: (0.1480) | Acc: (94.75%) (47376/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3649) | Acc: (89.17%) (8917/10000)\n",
            "Epoch: 57 | Batch_idx: 0 |  Loss: (0.0959) | Acc: (96.88%) (124/128)\n",
            "Epoch: 57 | Batch_idx: 10 |  Loss: (0.1644) | Acc: (94.60%) (1332/1408)\n",
            "Epoch: 57 | Batch_idx: 20 |  Loss: (0.1570) | Acc: (94.87%) (2550/2688)\n",
            "Epoch: 57 | Batch_idx: 30 |  Loss: (0.1470) | Acc: (95.14%) (3775/3968)\n",
            "Epoch: 57 | Batch_idx: 40 |  Loss: (0.1450) | Acc: (95.05%) (4988/5248)\n",
            "Epoch: 57 | Batch_idx: 50 |  Loss: (0.1479) | Acc: (94.90%) (6195/6528)\n",
            "Epoch: 57 | Batch_idx: 60 |  Loss: (0.1461) | Acc: (95.07%) (7423/7808)\n",
            "Epoch: 57 | Batch_idx: 70 |  Loss: (0.1441) | Acc: (95.16%) (8648/9088)\n",
            "Epoch: 57 | Batch_idx: 80 |  Loss: (0.1425) | Acc: (95.13%) (9863/10368)\n",
            "Epoch: 57 | Batch_idx: 90 |  Loss: (0.1394) | Acc: (95.29%) (11099/11648)\n",
            "Epoch: 57 | Batch_idx: 100 |  Loss: (0.1409) | Acc: (95.25%) (12314/12928)\n",
            "Epoch: 57 | Batch_idx: 110 |  Loss: (0.1414) | Acc: (95.16%) (13521/14208)\n",
            "Epoch: 57 | Batch_idx: 120 |  Loss: (0.1414) | Acc: (95.18%) (14742/15488)\n",
            "Epoch: 57 | Batch_idx: 130 |  Loss: (0.1412) | Acc: (95.21%) (15964/16768)\n",
            "Epoch: 57 | Batch_idx: 140 |  Loss: (0.1419) | Acc: (95.16%) (17174/18048)\n",
            "Epoch: 57 | Batch_idx: 150 |  Loss: (0.1417) | Acc: (95.16%) (18393/19328)\n",
            "Epoch: 57 | Batch_idx: 160 |  Loss: (0.1421) | Acc: (95.16%) (19611/20608)\n",
            "Epoch: 57 | Batch_idx: 170 |  Loss: (0.1422) | Acc: (95.13%) (20821/21888)\n",
            "Epoch: 57 | Batch_idx: 180 |  Loss: (0.1418) | Acc: (95.10%) (22033/23168)\n",
            "Epoch: 57 | Batch_idx: 190 |  Loss: (0.1412) | Acc: (95.12%) (23255/24448)\n",
            "Epoch: 57 | Batch_idx: 200 |  Loss: (0.1411) | Acc: (95.13%) (24476/25728)\n",
            "Epoch: 57 | Batch_idx: 210 |  Loss: (0.1427) | Acc: (95.09%) (25683/27008)\n",
            "Epoch: 57 | Batch_idx: 220 |  Loss: (0.1439) | Acc: (95.05%) (26888/28288)\n",
            "Epoch: 57 | Batch_idx: 230 |  Loss: (0.1438) | Acc: (95.05%) (28104/29568)\n",
            "Epoch: 57 | Batch_idx: 240 |  Loss: (0.1432) | Acc: (95.08%) (29331/30848)\n",
            "Epoch: 57 | Batch_idx: 250 |  Loss: (0.1436) | Acc: (95.05%) (30538/32128)\n",
            "Epoch: 57 | Batch_idx: 260 |  Loss: (0.1435) | Acc: (95.03%) (31748/33408)\n",
            "Epoch: 57 | Batch_idx: 270 |  Loss: (0.1438) | Acc: (95.02%) (32960/34688)\n",
            "Epoch: 57 | Batch_idx: 280 |  Loss: (0.1447) | Acc: (94.98%) (34164/35968)\n",
            "Epoch: 57 | Batch_idx: 290 |  Loss: (0.1451) | Acc: (94.95%) (35367/37248)\n",
            "Epoch: 57 | Batch_idx: 300 |  Loss: (0.1453) | Acc: (94.95%) (36584/38528)\n",
            "Epoch: 57 | Batch_idx: 310 |  Loss: (0.1450) | Acc: (94.96%) (37803/39808)\n",
            "Epoch: 57 | Batch_idx: 320 |  Loss: (0.1455) | Acc: (94.95%) (39014/41088)\n",
            "Epoch: 57 | Batch_idx: 330 |  Loss: (0.1456) | Acc: (94.95%) (40227/42368)\n",
            "Epoch: 57 | Batch_idx: 340 |  Loss: (0.1454) | Acc: (94.95%) (41444/43648)\n",
            "Epoch: 57 | Batch_idx: 350 |  Loss: (0.1460) | Acc: (94.92%) (42646/44928)\n",
            "Epoch: 57 | Batch_idx: 360 |  Loss: (0.1467) | Acc: (94.91%) (43855/46208)\n",
            "Epoch: 57 | Batch_idx: 370 |  Loss: (0.1469) | Acc: (94.90%) (45068/47488)\n",
            "Epoch: 57 | Batch_idx: 380 |  Loss: (0.1467) | Acc: (94.91%) (46284/48768)\n",
            "Epoch: 57 | Batch_idx: 390 |  Loss: (0.1480) | Acc: (94.87%) (47437/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3654) | Acc: (89.39%) (8939/10000)\n",
            "Epoch: 58 | Batch_idx: 0 |  Loss: (0.1193) | Acc: (96.88%) (124/128)\n",
            "Epoch: 58 | Batch_idx: 10 |  Loss: (0.1024) | Acc: (96.24%) (1355/1408)\n",
            "Epoch: 58 | Batch_idx: 20 |  Loss: (0.1299) | Acc: (95.46%) (2566/2688)\n",
            "Epoch: 58 | Batch_idx: 30 |  Loss: (0.1345) | Acc: (95.31%) (3782/3968)\n",
            "Epoch: 58 | Batch_idx: 40 |  Loss: (0.1380) | Acc: (95.24%) (4998/5248)\n",
            "Epoch: 58 | Batch_idx: 50 |  Loss: (0.1332) | Acc: (95.37%) (6226/6528)\n",
            "Epoch: 58 | Batch_idx: 60 |  Loss: (0.1351) | Acc: (95.29%) (7440/7808)\n",
            "Epoch: 58 | Batch_idx: 70 |  Loss: (0.1364) | Acc: (95.22%) (8654/9088)\n",
            "Epoch: 58 | Batch_idx: 80 |  Loss: (0.1375) | Acc: (95.18%) (9868/10368)\n",
            "Epoch: 58 | Batch_idx: 90 |  Loss: (0.1402) | Acc: (95.11%) (11078/11648)\n",
            "Epoch: 58 | Batch_idx: 100 |  Loss: (0.1405) | Acc: (95.01%) (12283/12928)\n",
            "Epoch: 58 | Batch_idx: 110 |  Loss: (0.1414) | Acc: (95.00%) (13497/14208)\n",
            "Epoch: 58 | Batch_idx: 120 |  Loss: (0.1430) | Acc: (94.94%) (14704/15488)\n",
            "Epoch: 58 | Batch_idx: 130 |  Loss: (0.1430) | Acc: (94.97%) (15925/16768)\n",
            "Epoch: 58 | Batch_idx: 140 |  Loss: (0.1427) | Acc: (94.95%) (17137/18048)\n",
            "Epoch: 58 | Batch_idx: 150 |  Loss: (0.1421) | Acc: (94.95%) (18352/19328)\n",
            "Epoch: 58 | Batch_idx: 160 |  Loss: (0.1434) | Acc: (94.91%) (19559/20608)\n",
            "Epoch: 58 | Batch_idx: 170 |  Loss: (0.1413) | Acc: (94.99%) (20792/21888)\n",
            "Epoch: 58 | Batch_idx: 180 |  Loss: (0.1404) | Acc: (95.01%) (22013/23168)\n",
            "Epoch: 58 | Batch_idx: 190 |  Loss: (0.1402) | Acc: (95.04%) (23235/24448)\n",
            "Epoch: 58 | Batch_idx: 200 |  Loss: (0.1401) | Acc: (95.06%) (24457/25728)\n",
            "Epoch: 58 | Batch_idx: 210 |  Loss: (0.1403) | Acc: (95.07%) (25677/27008)\n",
            "Epoch: 58 | Batch_idx: 220 |  Loss: (0.1411) | Acc: (95.03%) (26881/28288)\n",
            "Epoch: 58 | Batch_idx: 230 |  Loss: (0.1419) | Acc: (94.97%) (28082/29568)\n",
            "Epoch: 58 | Batch_idx: 240 |  Loss: (0.1419) | Acc: (94.98%) (29298/30848)\n",
            "Epoch: 58 | Batch_idx: 250 |  Loss: (0.1425) | Acc: (94.95%) (30505/32128)\n",
            "Epoch: 58 | Batch_idx: 260 |  Loss: (0.1442) | Acc: (94.89%) (31700/33408)\n",
            "Epoch: 58 | Batch_idx: 270 |  Loss: (0.1454) | Acc: (94.85%) (32903/34688)\n",
            "Epoch: 58 | Batch_idx: 280 |  Loss: (0.1455) | Acc: (94.86%) (34118/35968)\n",
            "Epoch: 58 | Batch_idx: 290 |  Loss: (0.1457) | Acc: (94.84%) (35325/37248)\n",
            "Epoch: 58 | Batch_idx: 300 |  Loss: (0.1467) | Acc: (94.79%) (36520/38528)\n",
            "Epoch: 58 | Batch_idx: 310 |  Loss: (0.1464) | Acc: (94.81%) (37740/39808)\n",
            "Epoch: 58 | Batch_idx: 320 |  Loss: (0.1464) | Acc: (94.79%) (38949/41088)\n",
            "Epoch: 58 | Batch_idx: 330 |  Loss: (0.1468) | Acc: (94.79%) (40160/42368)\n",
            "Epoch: 58 | Batch_idx: 340 |  Loss: (0.1470) | Acc: (94.80%) (41377/43648)\n",
            "Epoch: 58 | Batch_idx: 350 |  Loss: (0.1478) | Acc: (94.78%) (42584/44928)\n",
            "Epoch: 58 | Batch_idx: 360 |  Loss: (0.1478) | Acc: (94.80%) (43803/46208)\n",
            "Epoch: 58 | Batch_idx: 370 |  Loss: (0.1480) | Acc: (94.79%) (45015/47488)\n",
            "Epoch: 58 | Batch_idx: 380 |  Loss: (0.1482) | Acc: (94.78%) (46224/48768)\n",
            "Epoch: 58 | Batch_idx: 390 |  Loss: (0.1488) | Acc: (94.75%) (47375/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3608) | Acc: (89.20%) (8920/10000)\n",
            "Epoch: 59 | Batch_idx: 0 |  Loss: (0.0711) | Acc: (97.66%) (125/128)\n",
            "Epoch: 59 | Batch_idx: 10 |  Loss: (0.1210) | Acc: (96.02%) (1352/1408)\n",
            "Epoch: 59 | Batch_idx: 20 |  Loss: (0.1152) | Acc: (96.13%) (2584/2688)\n",
            "Epoch: 59 | Batch_idx: 30 |  Loss: (0.1127) | Acc: (96.12%) (3814/3968)\n",
            "Epoch: 59 | Batch_idx: 40 |  Loss: (0.1261) | Acc: (95.56%) (5015/5248)\n",
            "Epoch: 59 | Batch_idx: 50 |  Loss: (0.1270) | Acc: (95.57%) (6239/6528)\n",
            "Epoch: 59 | Batch_idx: 60 |  Loss: (0.1258) | Acc: (95.56%) (7461/7808)\n",
            "Epoch: 59 | Batch_idx: 70 |  Loss: (0.1261) | Acc: (95.57%) (8685/9088)\n",
            "Epoch: 59 | Batch_idx: 80 |  Loss: (0.1257) | Acc: (95.61%) (9913/10368)\n",
            "Epoch: 59 | Batch_idx: 90 |  Loss: (0.1254) | Acc: (95.59%) (11134/11648)\n",
            "Epoch: 59 | Batch_idx: 100 |  Loss: (0.1248) | Acc: (95.61%) (12361/12928)\n",
            "Epoch: 59 | Batch_idx: 110 |  Loss: (0.1242) | Acc: (95.62%) (13586/14208)\n",
            "Epoch: 59 | Batch_idx: 120 |  Loss: (0.1231) | Acc: (95.68%) (14819/15488)\n",
            "Epoch: 59 | Batch_idx: 130 |  Loss: (0.1247) | Acc: (95.67%) (16042/16768)\n",
            "Epoch: 59 | Batch_idx: 140 |  Loss: (0.1261) | Acc: (95.63%) (17260/18048)\n",
            "Epoch: 59 | Batch_idx: 150 |  Loss: (0.1262) | Acc: (95.65%) (18488/19328)\n",
            "Epoch: 59 | Batch_idx: 160 |  Loss: (0.1261) | Acc: (95.67%) (19716/20608)\n",
            "Epoch: 59 | Batch_idx: 170 |  Loss: (0.1276) | Acc: (95.63%) (20932/21888)\n",
            "Epoch: 59 | Batch_idx: 180 |  Loss: (0.1280) | Acc: (95.62%) (22154/23168)\n",
            "Epoch: 59 | Batch_idx: 190 |  Loss: (0.1280) | Acc: (95.64%) (23381/24448)\n",
            "Epoch: 59 | Batch_idx: 200 |  Loss: (0.1287) | Acc: (95.65%) (24609/25728)\n",
            "Epoch: 59 | Batch_idx: 210 |  Loss: (0.1300) | Acc: (95.61%) (25821/27008)\n",
            "Epoch: 59 | Batch_idx: 220 |  Loss: (0.1304) | Acc: (95.58%) (27037/28288)\n",
            "Epoch: 59 | Batch_idx: 230 |  Loss: (0.1304) | Acc: (95.56%) (28256/29568)\n",
            "Epoch: 59 | Batch_idx: 240 |  Loss: (0.1305) | Acc: (95.58%) (29483/30848)\n",
            "Epoch: 59 | Batch_idx: 250 |  Loss: (0.1308) | Acc: (95.56%) (30701/32128)\n",
            "Epoch: 59 | Batch_idx: 260 |  Loss: (0.1317) | Acc: (95.50%) (31904/33408)\n",
            "Epoch: 59 | Batch_idx: 270 |  Loss: (0.1326) | Acc: (95.46%) (33113/34688)\n",
            "Epoch: 59 | Batch_idx: 280 |  Loss: (0.1326) | Acc: (95.44%) (34328/35968)\n",
            "Epoch: 59 | Batch_idx: 290 |  Loss: (0.1335) | Acc: (95.40%) (35533/37248)\n",
            "Epoch: 59 | Batch_idx: 300 |  Loss: (0.1350) | Acc: (95.33%) (36729/38528)\n",
            "Epoch: 59 | Batch_idx: 310 |  Loss: (0.1347) | Acc: (95.34%) (37954/39808)\n",
            "Epoch: 59 | Batch_idx: 320 |  Loss: (0.1356) | Acc: (95.33%) (39169/41088)\n",
            "Epoch: 59 | Batch_idx: 330 |  Loss: (0.1361) | Acc: (95.30%) (40376/42368)\n",
            "Epoch: 59 | Batch_idx: 340 |  Loss: (0.1369) | Acc: (95.28%) (41587/43648)\n",
            "Epoch: 59 | Batch_idx: 350 |  Loss: (0.1376) | Acc: (95.24%) (42790/44928)\n",
            "Epoch: 59 | Batch_idx: 360 |  Loss: (0.1386) | Acc: (95.20%) (43992/46208)\n",
            "Epoch: 59 | Batch_idx: 370 |  Loss: (0.1387) | Acc: (95.20%) (45207/47488)\n",
            "Epoch: 59 | Batch_idx: 380 |  Loss: (0.1393) | Acc: (95.17%) (46411/48768)\n",
            "Epoch: 59 | Batch_idx: 390 |  Loss: (0.1405) | Acc: (95.13%) (47566/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3771) | Acc: (89.47%) (8947/10000)\n",
            "Epoch: 60 | Batch_idx: 0 |  Loss: (0.1223) | Acc: (95.31%) (122/128)\n",
            "Epoch: 60 | Batch_idx: 10 |  Loss: (0.1324) | Acc: (95.38%) (1343/1408)\n",
            "Epoch: 60 | Batch_idx: 20 |  Loss: (0.1322) | Acc: (95.20%) (2559/2688)\n",
            "Epoch: 60 | Batch_idx: 30 |  Loss: (0.1323) | Acc: (95.34%) (3783/3968)\n",
            "Epoch: 60 | Batch_idx: 40 |  Loss: (0.1353) | Acc: (95.20%) (4996/5248)\n",
            "Epoch: 60 | Batch_idx: 50 |  Loss: (0.1327) | Acc: (95.31%) (6222/6528)\n",
            "Epoch: 60 | Batch_idx: 60 |  Loss: (0.1316) | Acc: (95.33%) (7443/7808)\n",
            "Epoch: 60 | Batch_idx: 70 |  Loss: (0.1312) | Acc: (95.33%) (8664/9088)\n",
            "Epoch: 60 | Batch_idx: 80 |  Loss: (0.1358) | Acc: (95.15%) (9865/10368)\n",
            "Epoch: 60 | Batch_idx: 90 |  Loss: (0.1367) | Acc: (95.12%) (11079/11648)\n",
            "Epoch: 60 | Batch_idx: 100 |  Loss: (0.1360) | Acc: (95.18%) (12305/12928)\n",
            "Epoch: 60 | Batch_idx: 110 |  Loss: (0.1361) | Acc: (95.17%) (13522/14208)\n",
            "Epoch: 60 | Batch_idx: 120 |  Loss: (0.1367) | Acc: (95.18%) (14741/15488)\n",
            "Epoch: 60 | Batch_idx: 130 |  Loss: (0.1370) | Acc: (95.16%) (15957/16768)\n",
            "Epoch: 60 | Batch_idx: 140 |  Loss: (0.1381) | Acc: (95.16%) (17175/18048)\n",
            "Epoch: 60 | Batch_idx: 150 |  Loss: (0.1376) | Acc: (95.16%) (18392/19328)\n",
            "Epoch: 60 | Batch_idx: 160 |  Loss: (0.1377) | Acc: (95.16%) (19611/20608)\n",
            "Epoch: 60 | Batch_idx: 170 |  Loss: (0.1381) | Acc: (95.13%) (20821/21888)\n",
            "Epoch: 60 | Batch_idx: 180 |  Loss: (0.1399) | Acc: (95.07%) (22025/23168)\n",
            "Epoch: 60 | Batch_idx: 190 |  Loss: (0.1406) | Acc: (95.05%) (23238/24448)\n",
            "Epoch: 60 | Batch_idx: 200 |  Loss: (0.1415) | Acc: (95.02%) (24447/25728)\n",
            "Epoch: 60 | Batch_idx: 210 |  Loss: (0.1426) | Acc: (94.99%) (25654/27008)\n",
            "Epoch: 60 | Batch_idx: 220 |  Loss: (0.1416) | Acc: (95.02%) (26880/28288)\n",
            "Epoch: 60 | Batch_idx: 230 |  Loss: (0.1431) | Acc: (94.98%) (28083/29568)\n",
            "Epoch: 60 | Batch_idx: 240 |  Loss: (0.1433) | Acc: (94.98%) (29299/30848)\n",
            "Epoch: 60 | Batch_idx: 250 |  Loss: (0.1447) | Acc: (94.94%) (30502/32128)\n",
            "Epoch: 60 | Batch_idx: 260 |  Loss: (0.1446) | Acc: (94.94%) (31719/33408)\n",
            "Epoch: 60 | Batch_idx: 270 |  Loss: (0.1454) | Acc: (94.91%) (32922/34688)\n",
            "Epoch: 60 | Batch_idx: 280 |  Loss: (0.1451) | Acc: (94.92%) (34142/35968)\n",
            "Epoch: 60 | Batch_idx: 290 |  Loss: (0.1450) | Acc: (94.94%) (35363/37248)\n",
            "Epoch: 60 | Batch_idx: 300 |  Loss: (0.1454) | Acc: (94.92%) (36572/38528)\n",
            "Epoch: 60 | Batch_idx: 310 |  Loss: (0.1453) | Acc: (94.92%) (37785/39808)\n",
            "Epoch: 60 | Batch_idx: 320 |  Loss: (0.1456) | Acc: (94.91%) (38996/41088)\n",
            "Epoch: 60 | Batch_idx: 330 |  Loss: (0.1462) | Acc: (94.88%) (40197/42368)\n",
            "Epoch: 60 | Batch_idx: 340 |  Loss: (0.1459) | Acc: (94.87%) (41411/43648)\n",
            "Epoch: 60 | Batch_idx: 350 |  Loss: (0.1462) | Acc: (94.87%) (42623/44928)\n",
            "Epoch: 60 | Batch_idx: 360 |  Loss: (0.1478) | Acc: (94.80%) (43804/46208)\n",
            "Epoch: 60 | Batch_idx: 370 |  Loss: (0.1483) | Acc: (94.79%) (45013/47488)\n",
            "Epoch: 60 | Batch_idx: 380 |  Loss: (0.1492) | Acc: (94.74%) (46205/48768)\n",
            "Epoch: 60 | Batch_idx: 390 |  Loss: (0.1490) | Acc: (94.76%) (47379/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3583) | Acc: (89.11%) (8911/10000)\n",
            "Epoch: 61 | Batch_idx: 0 |  Loss: (0.1394) | Acc: (94.53%) (121/128)\n",
            "Epoch: 61 | Batch_idx: 10 |  Loss: (0.1352) | Acc: (94.82%) (1335/1408)\n",
            "Epoch: 61 | Batch_idx: 20 |  Loss: (0.1259) | Acc: (95.09%) (2556/2688)\n",
            "Epoch: 61 | Batch_idx: 30 |  Loss: (0.1267) | Acc: (95.14%) (3775/3968)\n",
            "Epoch: 61 | Batch_idx: 40 |  Loss: (0.1286) | Acc: (95.29%) (5001/5248)\n",
            "Epoch: 61 | Batch_idx: 50 |  Loss: (0.1253) | Acc: (95.47%) (6232/6528)\n",
            "Epoch: 61 | Batch_idx: 60 |  Loss: (0.1224) | Acc: (95.62%) (7466/7808)\n",
            "Epoch: 61 | Batch_idx: 70 |  Loss: (0.1231) | Acc: (95.62%) (8690/9088)\n",
            "Epoch: 61 | Batch_idx: 80 |  Loss: (0.1224) | Acc: (95.62%) (9914/10368)\n",
            "Epoch: 61 | Batch_idx: 90 |  Loss: (0.1262) | Acc: (95.50%) (11124/11648)\n",
            "Epoch: 61 | Batch_idx: 100 |  Loss: (0.1277) | Acc: (95.44%) (12339/12928)\n",
            "Epoch: 61 | Batch_idx: 110 |  Loss: (0.1271) | Acc: (95.50%) (13568/14208)\n",
            "Epoch: 61 | Batch_idx: 120 |  Loss: (0.1288) | Acc: (95.45%) (14784/15488)\n",
            "Epoch: 61 | Batch_idx: 130 |  Loss: (0.1306) | Acc: (95.38%) (15994/16768)\n",
            "Epoch: 61 | Batch_idx: 140 |  Loss: (0.1323) | Acc: (95.31%) (17202/18048)\n",
            "Epoch: 61 | Batch_idx: 150 |  Loss: (0.1327) | Acc: (95.25%) (18409/19328)\n",
            "Epoch: 61 | Batch_idx: 160 |  Loss: (0.1319) | Acc: (95.27%) (19633/20608)\n",
            "Epoch: 61 | Batch_idx: 170 |  Loss: (0.1334) | Acc: (95.23%) (20843/21888)\n",
            "Epoch: 61 | Batch_idx: 180 |  Loss: (0.1337) | Acc: (95.23%) (22063/23168)\n",
            "Epoch: 61 | Batch_idx: 190 |  Loss: (0.1348) | Acc: (95.21%) (23276/24448)\n",
            "Epoch: 61 | Batch_idx: 200 |  Loss: (0.1348) | Acc: (95.20%) (24494/25728)\n",
            "Epoch: 61 | Batch_idx: 210 |  Loss: (0.1342) | Acc: (95.22%) (25718/27008)\n",
            "Epoch: 61 | Batch_idx: 220 |  Loss: (0.1351) | Acc: (95.18%) (26925/28288)\n",
            "Epoch: 61 | Batch_idx: 230 |  Loss: (0.1347) | Acc: (95.19%) (28147/29568)\n",
            "Epoch: 61 | Batch_idx: 240 |  Loss: (0.1353) | Acc: (95.19%) (29363/30848)\n",
            "Epoch: 61 | Batch_idx: 250 |  Loss: (0.1355) | Acc: (95.19%) (30582/32128)\n",
            "Epoch: 61 | Batch_idx: 260 |  Loss: (0.1351) | Acc: (95.22%) (31812/33408)\n",
            "Epoch: 61 | Batch_idx: 270 |  Loss: (0.1356) | Acc: (95.19%) (33020/34688)\n",
            "Epoch: 61 | Batch_idx: 280 |  Loss: (0.1358) | Acc: (95.20%) (34241/35968)\n",
            "Epoch: 61 | Batch_idx: 290 |  Loss: (0.1364) | Acc: (95.18%) (35451/37248)\n",
            "Epoch: 61 | Batch_idx: 300 |  Loss: (0.1374) | Acc: (95.15%) (36660/38528)\n",
            "Epoch: 61 | Batch_idx: 310 |  Loss: (0.1381) | Acc: (95.13%) (37869/39808)\n",
            "Epoch: 61 | Batch_idx: 320 |  Loss: (0.1379) | Acc: (95.15%) (39097/41088)\n",
            "Epoch: 61 | Batch_idx: 330 |  Loss: (0.1376) | Acc: (95.18%) (40324/42368)\n",
            "Epoch: 61 | Batch_idx: 340 |  Loss: (0.1382) | Acc: (95.16%) (41534/43648)\n",
            "Epoch: 61 | Batch_idx: 350 |  Loss: (0.1377) | Acc: (95.18%) (42763/44928)\n",
            "Epoch: 61 | Batch_idx: 360 |  Loss: (0.1380) | Acc: (95.18%) (43980/46208)\n",
            "Epoch: 61 | Batch_idx: 370 |  Loss: (0.1384) | Acc: (95.17%) (45192/47488)\n",
            "Epoch: 61 | Batch_idx: 380 |  Loss: (0.1386) | Acc: (95.15%) (46402/48768)\n",
            "Epoch: 61 | Batch_idx: 390 |  Loss: (0.1389) | Acc: (95.16%) (47578/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4118) | Acc: (88.40%) (8840/10000)\n",
            "Epoch: 62 | Batch_idx: 0 |  Loss: (0.1732) | Acc: (96.09%) (123/128)\n",
            "Epoch: 62 | Batch_idx: 10 |  Loss: (0.1516) | Acc: (95.24%) (1341/1408)\n",
            "Epoch: 62 | Batch_idx: 20 |  Loss: (0.1519) | Acc: (95.01%) (2554/2688)\n",
            "Epoch: 62 | Batch_idx: 30 |  Loss: (0.1378) | Acc: (95.26%) (3780/3968)\n",
            "Epoch: 62 | Batch_idx: 40 |  Loss: (0.1381) | Acc: (95.22%) (4997/5248)\n",
            "Epoch: 62 | Batch_idx: 50 |  Loss: (0.1365) | Acc: (95.30%) (6221/6528)\n",
            "Epoch: 62 | Batch_idx: 60 |  Loss: (0.1361) | Acc: (95.33%) (7443/7808)\n",
            "Epoch: 62 | Batch_idx: 70 |  Loss: (0.1330) | Acc: (95.41%) (8671/9088)\n",
            "Epoch: 62 | Batch_idx: 80 |  Loss: (0.1329) | Acc: (95.37%) (9888/10368)\n",
            "Epoch: 62 | Batch_idx: 90 |  Loss: (0.1340) | Acc: (95.30%) (11101/11648)\n",
            "Epoch: 62 | Batch_idx: 100 |  Loss: (0.1344) | Acc: (95.30%) (12321/12928)\n",
            "Epoch: 62 | Batch_idx: 110 |  Loss: (0.1354) | Acc: (95.26%) (13535/14208)\n",
            "Epoch: 62 | Batch_idx: 120 |  Loss: (0.1343) | Acc: (95.28%) (14757/15488)\n",
            "Epoch: 62 | Batch_idx: 130 |  Loss: (0.1324) | Acc: (95.38%) (15994/16768)\n",
            "Epoch: 62 | Batch_idx: 140 |  Loss: (0.1313) | Acc: (95.42%) (17221/18048)\n",
            "Epoch: 62 | Batch_idx: 150 |  Loss: (0.1327) | Acc: (95.38%) (18435/19328)\n",
            "Epoch: 62 | Batch_idx: 160 |  Loss: (0.1324) | Acc: (95.39%) (19658/20608)\n",
            "Epoch: 62 | Batch_idx: 170 |  Loss: (0.1344) | Acc: (95.29%) (20858/21888)\n",
            "Epoch: 62 | Batch_idx: 180 |  Loss: (0.1325) | Acc: (95.36%) (22094/23168)\n",
            "Epoch: 62 | Batch_idx: 190 |  Loss: (0.1318) | Acc: (95.41%) (23326/24448)\n",
            "Epoch: 62 | Batch_idx: 200 |  Loss: (0.1322) | Acc: (95.39%) (24542/25728)\n",
            "Epoch: 62 | Batch_idx: 210 |  Loss: (0.1325) | Acc: (95.36%) (25756/27008)\n",
            "Epoch: 62 | Batch_idx: 220 |  Loss: (0.1328) | Acc: (95.38%) (26980/28288)\n",
            "Epoch: 62 | Batch_idx: 230 |  Loss: (0.1332) | Acc: (95.36%) (28196/29568)\n",
            "Epoch: 62 | Batch_idx: 240 |  Loss: (0.1334) | Acc: (95.35%) (29414/30848)\n",
            "Epoch: 62 | Batch_idx: 250 |  Loss: (0.1336) | Acc: (95.33%) (30629/32128)\n",
            "Epoch: 62 | Batch_idx: 260 |  Loss: (0.1347) | Acc: (95.29%) (31835/33408)\n",
            "Epoch: 62 | Batch_idx: 270 |  Loss: (0.1358) | Acc: (95.24%) (33038/34688)\n",
            "Epoch: 62 | Batch_idx: 280 |  Loss: (0.1360) | Acc: (95.24%) (34255/35968)\n",
            "Epoch: 62 | Batch_idx: 290 |  Loss: (0.1376) | Acc: (95.19%) (35457/37248)\n",
            "Epoch: 62 | Batch_idx: 300 |  Loss: (0.1383) | Acc: (95.17%) (36667/38528)\n",
            "Epoch: 62 | Batch_idx: 310 |  Loss: (0.1385) | Acc: (95.17%) (37887/39808)\n",
            "Epoch: 62 | Batch_idx: 320 |  Loss: (0.1388) | Acc: (95.15%) (39094/41088)\n",
            "Epoch: 62 | Batch_idx: 330 |  Loss: (0.1393) | Acc: (95.14%) (40307/42368)\n",
            "Epoch: 62 | Batch_idx: 340 |  Loss: (0.1392) | Acc: (95.15%) (41529/43648)\n",
            "Epoch: 62 | Batch_idx: 350 |  Loss: (0.1393) | Acc: (95.15%) (42747/44928)\n",
            "Epoch: 62 | Batch_idx: 360 |  Loss: (0.1395) | Acc: (95.14%) (43960/46208)\n",
            "Epoch: 62 | Batch_idx: 370 |  Loss: (0.1401) | Acc: (95.10%) (45161/47488)\n",
            "Epoch: 62 | Batch_idx: 380 |  Loss: (0.1401) | Acc: (95.11%) (46383/48768)\n",
            "Epoch: 62 | Batch_idx: 390 |  Loss: (0.1408) | Acc: (95.07%) (47536/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3630) | Acc: (89.51%) (8951/10000)\n",
            "Epoch: 63 | Batch_idx: 0 |  Loss: (0.0808) | Acc: (97.66%) (125/128)\n",
            "Epoch: 63 | Batch_idx: 10 |  Loss: (0.1314) | Acc: (95.10%) (1339/1408)\n",
            "Epoch: 63 | Batch_idx: 20 |  Loss: (0.1297) | Acc: (95.39%) (2564/2688)\n",
            "Epoch: 63 | Batch_idx: 30 |  Loss: (0.1305) | Acc: (95.31%) (3782/3968)\n",
            "Epoch: 63 | Batch_idx: 40 |  Loss: (0.1309) | Acc: (95.46%) (5010/5248)\n",
            "Epoch: 63 | Batch_idx: 50 |  Loss: (0.1350) | Acc: (95.34%) (6224/6528)\n",
            "Epoch: 63 | Batch_idx: 60 |  Loss: (0.1341) | Acc: (95.40%) (7449/7808)\n",
            "Epoch: 63 | Batch_idx: 70 |  Loss: (0.1356) | Acc: (95.28%) (8659/9088)\n",
            "Epoch: 63 | Batch_idx: 80 |  Loss: (0.1341) | Acc: (95.33%) (9884/10368)\n",
            "Epoch: 63 | Batch_idx: 90 |  Loss: (0.1326) | Acc: (95.41%) (11113/11648)\n",
            "Epoch: 63 | Batch_idx: 100 |  Loss: (0.1334) | Acc: (95.40%) (12333/12928)\n",
            "Epoch: 63 | Batch_idx: 110 |  Loss: (0.1321) | Acc: (95.47%) (13564/14208)\n",
            "Epoch: 63 | Batch_idx: 120 |  Loss: (0.1328) | Acc: (95.39%) (14774/15488)\n",
            "Epoch: 63 | Batch_idx: 130 |  Loss: (0.1338) | Acc: (95.36%) (15990/16768)\n",
            "Epoch: 63 | Batch_idx: 140 |  Loss: (0.1343) | Acc: (95.33%) (17205/18048)\n",
            "Epoch: 63 | Batch_idx: 150 |  Loss: (0.1342) | Acc: (95.35%) (18430/19328)\n",
            "Epoch: 63 | Batch_idx: 160 |  Loss: (0.1340) | Acc: (95.32%) (19643/20608)\n",
            "Epoch: 63 | Batch_idx: 170 |  Loss: (0.1334) | Acc: (95.36%) (20872/21888)\n",
            "Epoch: 63 | Batch_idx: 180 |  Loss: (0.1345) | Acc: (95.31%) (22082/23168)\n",
            "Epoch: 63 | Batch_idx: 190 |  Loss: (0.1343) | Acc: (95.29%) (23297/24448)\n",
            "Epoch: 63 | Batch_idx: 200 |  Loss: (0.1348) | Acc: (95.31%) (24521/25728)\n",
            "Epoch: 63 | Batch_idx: 210 |  Loss: (0.1344) | Acc: (95.32%) (25745/27008)\n",
            "Epoch: 63 | Batch_idx: 220 |  Loss: (0.1341) | Acc: (95.34%) (26969/28288)\n",
            "Epoch: 63 | Batch_idx: 230 |  Loss: (0.1342) | Acc: (95.35%) (28193/29568)\n",
            "Epoch: 63 | Batch_idx: 240 |  Loss: (0.1355) | Acc: (95.33%) (29407/30848)\n",
            "Epoch: 63 | Batch_idx: 250 |  Loss: (0.1361) | Acc: (95.29%) (30614/32128)\n",
            "Epoch: 63 | Batch_idx: 260 |  Loss: (0.1366) | Acc: (95.26%) (31826/33408)\n",
            "Epoch: 63 | Batch_idx: 270 |  Loss: (0.1372) | Acc: (95.25%) (33040/34688)\n",
            "Epoch: 63 | Batch_idx: 280 |  Loss: (0.1388) | Acc: (95.22%) (34249/35968)\n",
            "Epoch: 63 | Batch_idx: 290 |  Loss: (0.1392) | Acc: (95.20%) (35459/37248)\n",
            "Epoch: 63 | Batch_idx: 300 |  Loss: (0.1393) | Acc: (95.19%) (36673/38528)\n",
            "Epoch: 63 | Batch_idx: 310 |  Loss: (0.1401) | Acc: (95.15%) (37878/39808)\n",
            "Epoch: 63 | Batch_idx: 320 |  Loss: (0.1401) | Acc: (95.16%) (39101/41088)\n",
            "Epoch: 63 | Batch_idx: 330 |  Loss: (0.1408) | Acc: (95.14%) (40310/42368)\n",
            "Epoch: 63 | Batch_idx: 340 |  Loss: (0.1412) | Acc: (95.12%) (41516/43648)\n",
            "Epoch: 63 | Batch_idx: 350 |  Loss: (0.1419) | Acc: (95.10%) (42726/44928)\n",
            "Epoch: 63 | Batch_idx: 360 |  Loss: (0.1421) | Acc: (95.08%) (43933/46208)\n",
            "Epoch: 63 | Batch_idx: 370 |  Loss: (0.1424) | Acc: (95.08%) (45151/47488)\n",
            "Epoch: 63 | Batch_idx: 380 |  Loss: (0.1426) | Acc: (95.07%) (46364/48768)\n",
            "Epoch: 63 | Batch_idx: 390 |  Loss: (0.1430) | Acc: (95.04%) (47522/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3532) | Acc: (89.77%) (8977/10000)\n",
            "Epoch: 64 | Batch_idx: 0 |  Loss: (0.1120) | Acc: (95.31%) (122/128)\n",
            "Epoch: 64 | Batch_idx: 10 |  Loss: (0.1356) | Acc: (95.03%) (1338/1408)\n",
            "Epoch: 64 | Batch_idx: 20 |  Loss: (0.1359) | Acc: (95.16%) (2558/2688)\n",
            "Epoch: 64 | Batch_idx: 30 |  Loss: (0.1322) | Acc: (95.36%) (3784/3968)\n",
            "Epoch: 64 | Batch_idx: 40 |  Loss: (0.1313) | Acc: (95.37%) (5005/5248)\n",
            "Epoch: 64 | Batch_idx: 50 |  Loss: (0.1356) | Acc: (95.31%) (6222/6528)\n",
            "Epoch: 64 | Batch_idx: 60 |  Loss: (0.1291) | Acc: (95.48%) (7455/7808)\n",
            "Epoch: 64 | Batch_idx: 70 |  Loss: (0.1293) | Acc: (95.44%) (8674/9088)\n",
            "Epoch: 64 | Batch_idx: 80 |  Loss: (0.1271) | Acc: (95.55%) (9907/10368)\n",
            "Epoch: 64 | Batch_idx: 90 |  Loss: (0.1274) | Acc: (95.51%) (11125/11648)\n",
            "Epoch: 64 | Batch_idx: 100 |  Loss: (0.1268) | Acc: (95.54%) (12352/12928)\n",
            "Epoch: 64 | Batch_idx: 110 |  Loss: (0.1276) | Acc: (95.53%) (13573/14208)\n",
            "Epoch: 64 | Batch_idx: 120 |  Loss: (0.1264) | Acc: (95.55%) (14799/15488)\n",
            "Epoch: 64 | Batch_idx: 130 |  Loss: (0.1251) | Acc: (95.60%) (16031/16768)\n",
            "Epoch: 64 | Batch_idx: 140 |  Loss: (0.1249) | Acc: (95.60%) (17254/18048)\n",
            "Epoch: 64 | Batch_idx: 150 |  Loss: (0.1239) | Acc: (95.62%) (18482/19328)\n",
            "Epoch: 64 | Batch_idx: 160 |  Loss: (0.1234) | Acc: (95.69%) (19719/20608)\n",
            "Epoch: 64 | Batch_idx: 170 |  Loss: (0.1256) | Acc: (95.59%) (20922/21888)\n",
            "Epoch: 64 | Batch_idx: 180 |  Loss: (0.1251) | Acc: (95.62%) (22154/23168)\n",
            "Epoch: 64 | Batch_idx: 190 |  Loss: (0.1258) | Acc: (95.59%) (23371/24448)\n",
            "Epoch: 64 | Batch_idx: 200 |  Loss: (0.1268) | Acc: (95.56%) (24586/25728)\n",
            "Epoch: 64 | Batch_idx: 210 |  Loss: (0.1281) | Acc: (95.51%) (25794/27008)\n",
            "Epoch: 64 | Batch_idx: 220 |  Loss: (0.1291) | Acc: (95.49%) (27011/28288)\n",
            "Epoch: 64 | Batch_idx: 230 |  Loss: (0.1300) | Acc: (95.46%) (28226/29568)\n",
            "Epoch: 64 | Batch_idx: 240 |  Loss: (0.1298) | Acc: (95.46%) (29446/30848)\n",
            "Epoch: 64 | Batch_idx: 250 |  Loss: (0.1299) | Acc: (95.44%) (30664/32128)\n",
            "Epoch: 64 | Batch_idx: 260 |  Loss: (0.1307) | Acc: (95.44%) (31885/33408)\n",
            "Epoch: 64 | Batch_idx: 270 |  Loss: (0.1307) | Acc: (95.45%) (33109/34688)\n",
            "Epoch: 64 | Batch_idx: 280 |  Loss: (0.1316) | Acc: (95.42%) (34319/35968)\n",
            "Epoch: 64 | Batch_idx: 290 |  Loss: (0.1322) | Acc: (95.39%) (35532/37248)\n",
            "Epoch: 64 | Batch_idx: 300 |  Loss: (0.1336) | Acc: (95.34%) (36731/38528)\n",
            "Epoch: 64 | Batch_idx: 310 |  Loss: (0.1349) | Acc: (95.29%) (37934/39808)\n",
            "Epoch: 64 | Batch_idx: 320 |  Loss: (0.1363) | Acc: (95.26%) (39140/41088)\n",
            "Epoch: 64 | Batch_idx: 330 |  Loss: (0.1373) | Acc: (95.21%) (40337/42368)\n",
            "Epoch: 64 | Batch_idx: 340 |  Loss: (0.1375) | Acc: (95.20%) (41553/43648)\n",
            "Epoch: 64 | Batch_idx: 350 |  Loss: (0.1378) | Acc: (95.20%) (42772/44928)\n",
            "Epoch: 64 | Batch_idx: 360 |  Loss: (0.1378) | Acc: (95.21%) (43994/46208)\n",
            "Epoch: 64 | Batch_idx: 370 |  Loss: (0.1383) | Acc: (95.19%) (45205/47488)\n",
            "Epoch: 64 | Batch_idx: 380 |  Loss: (0.1386) | Acc: (95.19%) (46421/48768)\n",
            "Epoch: 64 | Batch_idx: 390 |  Loss: (0.1384) | Acc: (95.21%) (47607/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3775) | Acc: (89.76%) (8976/10000)\n",
            "Epoch: 65 | Batch_idx: 0 |  Loss: (0.1429) | Acc: (94.53%) (121/128)\n",
            "Epoch: 65 | Batch_idx: 10 |  Loss: (0.1333) | Acc: (95.17%) (1340/1408)\n",
            "Epoch: 65 | Batch_idx: 20 |  Loss: (0.1243) | Acc: (95.76%) (2574/2688)\n",
            "Epoch: 65 | Batch_idx: 30 |  Loss: (0.1159) | Acc: (95.97%) (3808/3968)\n",
            "Epoch: 65 | Batch_idx: 40 |  Loss: (0.1203) | Acc: (95.83%) (5029/5248)\n",
            "Epoch: 65 | Batch_idx: 50 |  Loss: (0.1203) | Acc: (95.86%) (6258/6528)\n",
            "Epoch: 65 | Batch_idx: 60 |  Loss: (0.1214) | Acc: (95.88%) (7486/7808)\n",
            "Epoch: 65 | Batch_idx: 70 |  Loss: (0.1215) | Acc: (95.87%) (8713/9088)\n",
            "Epoch: 65 | Batch_idx: 80 |  Loss: (0.1212) | Acc: (95.92%) (9945/10368)\n",
            "Epoch: 65 | Batch_idx: 90 |  Loss: (0.1223) | Acc: (95.84%) (11163/11648)\n",
            "Epoch: 65 | Batch_idx: 100 |  Loss: (0.1227) | Acc: (95.78%) (12383/12928)\n",
            "Epoch: 65 | Batch_idx: 110 |  Loss: (0.1234) | Acc: (95.71%) (13599/14208)\n",
            "Epoch: 65 | Batch_idx: 120 |  Loss: (0.1251) | Acc: (95.67%) (14817/15488)\n",
            "Epoch: 65 | Batch_idx: 130 |  Loss: (0.1257) | Acc: (95.65%) (16039/16768)\n",
            "Epoch: 65 | Batch_idx: 140 |  Loss: (0.1268) | Acc: (95.58%) (17250/18048)\n",
            "Epoch: 65 | Batch_idx: 150 |  Loss: (0.1300) | Acc: (95.45%) (18448/19328)\n",
            "Epoch: 65 | Batch_idx: 160 |  Loss: (0.1312) | Acc: (95.43%) (19666/20608)\n",
            "Epoch: 65 | Batch_idx: 170 |  Loss: (0.1338) | Acc: (95.32%) (20864/21888)\n",
            "Epoch: 65 | Batch_idx: 180 |  Loss: (0.1356) | Acc: (95.28%) (22074/23168)\n",
            "Epoch: 65 | Batch_idx: 190 |  Loss: (0.1360) | Acc: (95.23%) (23283/24448)\n",
            "Epoch: 65 | Batch_idx: 200 |  Loss: (0.1356) | Acc: (95.27%) (24511/25728)\n",
            "Epoch: 65 | Batch_idx: 210 |  Loss: (0.1362) | Acc: (95.25%) (25726/27008)\n",
            "Epoch: 65 | Batch_idx: 220 |  Loss: (0.1369) | Acc: (95.25%) (26945/28288)\n",
            "Epoch: 65 | Batch_idx: 230 |  Loss: (0.1365) | Acc: (95.25%) (28164/29568)\n",
            "Epoch: 65 | Batch_idx: 240 |  Loss: (0.1371) | Acc: (95.22%) (29372/30848)\n",
            "Epoch: 65 | Batch_idx: 250 |  Loss: (0.1368) | Acc: (95.23%) (30597/32128)\n",
            "Epoch: 65 | Batch_idx: 260 |  Loss: (0.1364) | Acc: (95.23%) (31816/33408)\n",
            "Epoch: 65 | Batch_idx: 270 |  Loss: (0.1370) | Acc: (95.23%) (33032/34688)\n",
            "Epoch: 65 | Batch_idx: 280 |  Loss: (0.1368) | Acc: (95.23%) (34251/35968)\n",
            "Epoch: 65 | Batch_idx: 290 |  Loss: (0.1367) | Acc: (95.23%) (35470/37248)\n",
            "Epoch: 65 | Batch_idx: 300 |  Loss: (0.1369) | Acc: (95.24%) (36693/38528)\n",
            "Epoch: 65 | Batch_idx: 310 |  Loss: (0.1376) | Acc: (95.20%) (37898/39808)\n",
            "Epoch: 65 | Batch_idx: 320 |  Loss: (0.1383) | Acc: (95.18%) (39107/41088)\n",
            "Epoch: 65 | Batch_idx: 330 |  Loss: (0.1383) | Acc: (95.17%) (40322/42368)\n",
            "Epoch: 65 | Batch_idx: 340 |  Loss: (0.1380) | Acc: (95.19%) (41547/43648)\n",
            "Epoch: 65 | Batch_idx: 350 |  Loss: (0.1384) | Acc: (95.18%) (42763/44928)\n",
            "Epoch: 65 | Batch_idx: 360 |  Loss: (0.1394) | Acc: (95.14%) (43961/46208)\n",
            "Epoch: 65 | Batch_idx: 370 |  Loss: (0.1392) | Acc: (95.13%) (45177/47488)\n",
            "Epoch: 65 | Batch_idx: 380 |  Loss: (0.1392) | Acc: (95.14%) (46400/48768)\n",
            "Epoch: 65 | Batch_idx: 390 |  Loss: (0.1401) | Acc: (95.11%) (47554/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4195) | Acc: (88.81%) (8881/10000)\n",
            "Epoch: 66 | Batch_idx: 0 |  Loss: (0.0794) | Acc: (97.66%) (125/128)\n",
            "Epoch: 66 | Batch_idx: 10 |  Loss: (0.1314) | Acc: (95.95%) (1351/1408)\n",
            "Epoch: 66 | Batch_idx: 20 |  Loss: (0.1191) | Acc: (96.09%) (2583/2688)\n",
            "Epoch: 66 | Batch_idx: 30 |  Loss: (0.1287) | Acc: (95.77%) (3800/3968)\n",
            "Epoch: 66 | Batch_idx: 40 |  Loss: (0.1209) | Acc: (96.00%) (5038/5248)\n",
            "Epoch: 66 | Batch_idx: 50 |  Loss: (0.1224) | Acc: (95.97%) (6265/6528)\n",
            "Epoch: 66 | Batch_idx: 60 |  Loss: (0.1228) | Acc: (95.95%) (7492/7808)\n",
            "Epoch: 66 | Batch_idx: 70 |  Loss: (0.1232) | Acc: (95.87%) (8713/9088)\n",
            "Epoch: 66 | Batch_idx: 80 |  Loss: (0.1254) | Acc: (95.79%) (9931/10368)\n",
            "Epoch: 66 | Batch_idx: 90 |  Loss: (0.1250) | Acc: (95.78%) (11157/11648)\n",
            "Epoch: 66 | Batch_idx: 100 |  Loss: (0.1262) | Acc: (95.74%) (12377/12928)\n",
            "Epoch: 66 | Batch_idx: 110 |  Loss: (0.1261) | Acc: (95.75%) (13604/14208)\n",
            "Epoch: 66 | Batch_idx: 120 |  Loss: (0.1287) | Acc: (95.59%) (14805/15488)\n",
            "Epoch: 66 | Batch_idx: 130 |  Loss: (0.1290) | Acc: (95.57%) (16025/16768)\n",
            "Epoch: 66 | Batch_idx: 140 |  Loss: (0.1278) | Acc: (95.60%) (17253/18048)\n",
            "Epoch: 66 | Batch_idx: 150 |  Loss: (0.1275) | Acc: (95.56%) (18470/19328)\n",
            "Epoch: 66 | Batch_idx: 160 |  Loss: (0.1277) | Acc: (95.56%) (19693/20608)\n",
            "Epoch: 66 | Batch_idx: 170 |  Loss: (0.1269) | Acc: (95.62%) (20929/21888)\n",
            "Epoch: 66 | Batch_idx: 180 |  Loss: (0.1264) | Acc: (95.61%) (22151/23168)\n",
            "Epoch: 66 | Batch_idx: 190 |  Loss: (0.1273) | Acc: (95.60%) (23373/24448)\n",
            "Epoch: 66 | Batch_idx: 200 |  Loss: (0.1278) | Acc: (95.58%) (24592/25728)\n",
            "Epoch: 66 | Batch_idx: 210 |  Loss: (0.1287) | Acc: (95.58%) (25814/27008)\n",
            "Epoch: 66 | Batch_idx: 220 |  Loss: (0.1293) | Acc: (95.56%) (27033/28288)\n",
            "Epoch: 66 | Batch_idx: 230 |  Loss: (0.1307) | Acc: (95.52%) (28243/29568)\n",
            "Epoch: 66 | Batch_idx: 240 |  Loss: (0.1315) | Acc: (95.46%) (29448/30848)\n",
            "Epoch: 66 | Batch_idx: 250 |  Loss: (0.1328) | Acc: (95.43%) (30660/32128)\n",
            "Epoch: 66 | Batch_idx: 260 |  Loss: (0.1338) | Acc: (95.38%) (31866/33408)\n",
            "Epoch: 66 | Batch_idx: 270 |  Loss: (0.1341) | Acc: (95.38%) (33087/34688)\n",
            "Epoch: 66 | Batch_idx: 280 |  Loss: (0.1344) | Acc: (95.38%) (34308/35968)\n",
            "Epoch: 66 | Batch_idx: 290 |  Loss: (0.1350) | Acc: (95.34%) (35513/37248)\n",
            "Epoch: 66 | Batch_idx: 300 |  Loss: (0.1357) | Acc: (95.32%) (36724/38528)\n",
            "Epoch: 66 | Batch_idx: 310 |  Loss: (0.1359) | Acc: (95.32%) (37943/39808)\n",
            "Epoch: 66 | Batch_idx: 320 |  Loss: (0.1361) | Acc: (95.30%) (39157/41088)\n",
            "Epoch: 66 | Batch_idx: 330 |  Loss: (0.1363) | Acc: (95.30%) (40376/42368)\n",
            "Epoch: 66 | Batch_idx: 340 |  Loss: (0.1356) | Acc: (95.31%) (41601/43648)\n",
            "Epoch: 66 | Batch_idx: 350 |  Loss: (0.1365) | Acc: (95.27%) (42803/44928)\n",
            "Epoch: 66 | Batch_idx: 360 |  Loss: (0.1368) | Acc: (95.26%) (44019/46208)\n",
            "Epoch: 66 | Batch_idx: 370 |  Loss: (0.1369) | Acc: (95.26%) (45237/47488)\n",
            "Epoch: 66 | Batch_idx: 380 |  Loss: (0.1377) | Acc: (95.24%) (46448/48768)\n",
            "Epoch: 66 | Batch_idx: 390 |  Loss: (0.1381) | Acc: (95.22%) (47612/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3653) | Acc: (89.49%) (8949/10000)\n",
            "Epoch: 67 | Batch_idx: 0 |  Loss: (0.0333) | Acc: (99.22%) (127/128)\n",
            "Epoch: 67 | Batch_idx: 10 |  Loss: (0.1075) | Acc: (96.09%) (1353/1408)\n",
            "Epoch: 67 | Batch_idx: 20 |  Loss: (0.1265) | Acc: (95.61%) (2570/2688)\n",
            "Epoch: 67 | Batch_idx: 30 |  Loss: (0.1191) | Acc: (95.74%) (3799/3968)\n",
            "Epoch: 67 | Batch_idx: 40 |  Loss: (0.1190) | Acc: (95.67%) (5021/5248)\n",
            "Epoch: 67 | Batch_idx: 50 |  Loss: (0.1165) | Acc: (95.79%) (6253/6528)\n",
            "Epoch: 67 | Batch_idx: 60 |  Loss: (0.1177) | Acc: (95.74%) (7475/7808)\n",
            "Epoch: 67 | Batch_idx: 70 |  Loss: (0.1163) | Acc: (95.81%) (8707/9088)\n",
            "Epoch: 67 | Batch_idx: 80 |  Loss: (0.1155) | Acc: (95.83%) (9936/10368)\n",
            "Epoch: 67 | Batch_idx: 90 |  Loss: (0.1186) | Acc: (95.72%) (11149/11648)\n",
            "Epoch: 67 | Batch_idx: 100 |  Loss: (0.1203) | Acc: (95.75%) (12378/12928)\n",
            "Epoch: 67 | Batch_idx: 110 |  Loss: (0.1205) | Acc: (95.78%) (13608/14208)\n",
            "Epoch: 67 | Batch_idx: 120 |  Loss: (0.1227) | Acc: (95.69%) (14820/15488)\n",
            "Epoch: 67 | Batch_idx: 130 |  Loss: (0.1260) | Acc: (95.60%) (16030/16768)\n",
            "Epoch: 67 | Batch_idx: 140 |  Loss: (0.1275) | Acc: (95.51%) (17238/18048)\n",
            "Epoch: 67 | Batch_idx: 150 |  Loss: (0.1272) | Acc: (95.53%) (18464/19328)\n",
            "Epoch: 67 | Batch_idx: 160 |  Loss: (0.1274) | Acc: (95.52%) (19685/20608)\n",
            "Epoch: 67 | Batch_idx: 170 |  Loss: (0.1266) | Acc: (95.55%) (20915/21888)\n",
            "Epoch: 67 | Batch_idx: 180 |  Loss: (0.1269) | Acc: (95.55%) (22136/23168)\n",
            "Epoch: 67 | Batch_idx: 190 |  Loss: (0.1272) | Acc: (95.54%) (23357/24448)\n",
            "Epoch: 67 | Batch_idx: 200 |  Loss: (0.1267) | Acc: (95.57%) (24587/25728)\n",
            "Epoch: 67 | Batch_idx: 210 |  Loss: (0.1276) | Acc: (95.50%) (25793/27008)\n",
            "Epoch: 67 | Batch_idx: 220 |  Loss: (0.1277) | Acc: (95.50%) (27015/28288)\n",
            "Epoch: 67 | Batch_idx: 230 |  Loss: (0.1274) | Acc: (95.51%) (28241/29568)\n",
            "Epoch: 67 | Batch_idx: 240 |  Loss: (0.1277) | Acc: (95.51%) (29463/30848)\n",
            "Epoch: 67 | Batch_idx: 250 |  Loss: (0.1281) | Acc: (95.51%) (30686/32128)\n",
            "Epoch: 67 | Batch_idx: 260 |  Loss: (0.1294) | Acc: (95.45%) (31887/33408)\n",
            "Epoch: 67 | Batch_idx: 270 |  Loss: (0.1299) | Acc: (95.43%) (33103/34688)\n",
            "Epoch: 67 | Batch_idx: 280 |  Loss: (0.1307) | Acc: (95.40%) (34314/35968)\n",
            "Epoch: 67 | Batch_idx: 290 |  Loss: (0.1302) | Acc: (95.43%) (35544/37248)\n",
            "Epoch: 67 | Batch_idx: 300 |  Loss: (0.1305) | Acc: (95.41%) (36760/38528)\n",
            "Epoch: 67 | Batch_idx: 310 |  Loss: (0.1305) | Acc: (95.40%) (37976/39808)\n",
            "Epoch: 67 | Batch_idx: 320 |  Loss: (0.1314) | Acc: (95.36%) (39182/41088)\n",
            "Epoch: 67 | Batch_idx: 330 |  Loss: (0.1323) | Acc: (95.32%) (40386/42368)\n",
            "Epoch: 67 | Batch_idx: 340 |  Loss: (0.1329) | Acc: (95.31%) (41603/43648)\n",
            "Epoch: 67 | Batch_idx: 350 |  Loss: (0.1331) | Acc: (95.31%) (42823/44928)\n",
            "Epoch: 67 | Batch_idx: 360 |  Loss: (0.1333) | Acc: (95.32%) (44046/46208)\n",
            "Epoch: 67 | Batch_idx: 370 |  Loss: (0.1341) | Acc: (95.30%) (45254/47488)\n",
            "Epoch: 67 | Batch_idx: 380 |  Loss: (0.1346) | Acc: (95.30%) (46474/48768)\n",
            "Epoch: 67 | Batch_idx: 390 |  Loss: (0.1351) | Acc: (95.28%) (47642/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3879) | Acc: (89.02%) (8902/10000)\n",
            "Epoch: 68 | Batch_idx: 0 |  Loss: (0.1511) | Acc: (96.09%) (123/128)\n",
            "Epoch: 68 | Batch_idx: 10 |  Loss: (0.1132) | Acc: (95.67%) (1347/1408)\n",
            "Epoch: 68 | Batch_idx: 20 |  Loss: (0.1145) | Acc: (95.94%) (2579/2688)\n",
            "Epoch: 68 | Batch_idx: 30 |  Loss: (0.1138) | Acc: (96.02%) (3810/3968)\n",
            "Epoch: 68 | Batch_idx: 40 |  Loss: (0.1219) | Acc: (95.67%) (5021/5248)\n",
            "Epoch: 68 | Batch_idx: 50 |  Loss: (0.1232) | Acc: (95.56%) (6238/6528)\n",
            "Epoch: 68 | Batch_idx: 60 |  Loss: (0.1212) | Acc: (95.71%) (7473/7808)\n",
            "Epoch: 68 | Batch_idx: 70 |  Loss: (0.1206) | Acc: (95.75%) (8702/9088)\n",
            "Epoch: 68 | Batch_idx: 80 |  Loss: (0.1209) | Acc: (95.74%) (9926/10368)\n",
            "Epoch: 68 | Batch_idx: 90 |  Loss: (0.1214) | Acc: (95.78%) (11157/11648)\n",
            "Epoch: 68 | Batch_idx: 100 |  Loss: (0.1222) | Acc: (95.74%) (12377/12928)\n",
            "Epoch: 68 | Batch_idx: 110 |  Loss: (0.1226) | Acc: (95.76%) (13606/14208)\n",
            "Epoch: 68 | Batch_idx: 120 |  Loss: (0.1215) | Acc: (95.84%) (14843/15488)\n",
            "Epoch: 68 | Batch_idx: 130 |  Loss: (0.1208) | Acc: (95.88%) (16077/16768)\n",
            "Epoch: 68 | Batch_idx: 140 |  Loss: (0.1214) | Acc: (95.81%) (17292/18048)\n",
            "Epoch: 68 | Batch_idx: 150 |  Loss: (0.1205) | Acc: (95.82%) (18521/19328)\n",
            "Epoch: 68 | Batch_idx: 160 |  Loss: (0.1215) | Acc: (95.82%) (19746/20608)\n",
            "Epoch: 68 | Batch_idx: 170 |  Loss: (0.1222) | Acc: (95.80%) (20968/21888)\n",
            "Epoch: 68 | Batch_idx: 180 |  Loss: (0.1225) | Acc: (95.77%) (22187/23168)\n",
            "Epoch: 68 | Batch_idx: 190 |  Loss: (0.1226) | Acc: (95.74%) (23407/24448)\n",
            "Epoch: 68 | Batch_idx: 200 |  Loss: (0.1237) | Acc: (95.71%) (24623/25728)\n",
            "Epoch: 68 | Batch_idx: 210 |  Loss: (0.1240) | Acc: (95.69%) (25843/27008)\n",
            "Epoch: 68 | Batch_idx: 220 |  Loss: (0.1243) | Acc: (95.67%) (27064/28288)\n",
            "Epoch: 68 | Batch_idx: 230 |  Loss: (0.1246) | Acc: (95.63%) (28276/29568)\n",
            "Epoch: 68 | Batch_idx: 240 |  Loss: (0.1252) | Acc: (95.60%) (29490/30848)\n",
            "Epoch: 68 | Batch_idx: 250 |  Loss: (0.1270) | Acc: (95.52%) (30688/32128)\n",
            "Epoch: 68 | Batch_idx: 260 |  Loss: (0.1273) | Acc: (95.49%) (31901/33408)\n",
            "Epoch: 68 | Batch_idx: 270 |  Loss: (0.1273) | Acc: (95.47%) (33115/34688)\n",
            "Epoch: 68 | Batch_idx: 280 |  Loss: (0.1284) | Acc: (95.44%) (34327/35968)\n",
            "Epoch: 68 | Batch_idx: 290 |  Loss: (0.1295) | Acc: (95.40%) (35534/37248)\n",
            "Epoch: 68 | Batch_idx: 300 |  Loss: (0.1298) | Acc: (95.38%) (36748/38528)\n",
            "Epoch: 68 | Batch_idx: 310 |  Loss: (0.1310) | Acc: (95.34%) (37953/39808)\n",
            "Epoch: 68 | Batch_idx: 320 |  Loss: (0.1313) | Acc: (95.34%) (39172/41088)\n",
            "Epoch: 68 | Batch_idx: 330 |  Loss: (0.1322) | Acc: (95.29%) (40371/42368)\n",
            "Epoch: 68 | Batch_idx: 340 |  Loss: (0.1317) | Acc: (95.30%) (41598/43648)\n",
            "Epoch: 68 | Batch_idx: 350 |  Loss: (0.1323) | Acc: (95.30%) (42816/44928)\n",
            "Epoch: 68 | Batch_idx: 360 |  Loss: (0.1321) | Acc: (95.29%) (44032/46208)\n",
            "Epoch: 68 | Batch_idx: 370 |  Loss: (0.1326) | Acc: (95.27%) (45243/47488)\n",
            "Epoch: 68 | Batch_idx: 380 |  Loss: (0.1335) | Acc: (95.24%) (46446/48768)\n",
            "Epoch: 68 | Batch_idx: 390 |  Loss: (0.1338) | Acc: (95.23%) (47613/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3796) | Acc: (88.97%) (8897/10000)\n",
            "Epoch: 69 | Batch_idx: 0 |  Loss: (0.0818) | Acc: (96.88%) (124/128)\n",
            "Epoch: 69 | Batch_idx: 10 |  Loss: (0.1086) | Acc: (96.45%) (1358/1408)\n",
            "Epoch: 69 | Batch_idx: 20 |  Loss: (0.1180) | Acc: (95.98%) (2580/2688)\n",
            "Epoch: 69 | Batch_idx: 30 |  Loss: (0.1261) | Acc: (95.84%) (3803/3968)\n",
            "Epoch: 69 | Batch_idx: 40 |  Loss: (0.1224) | Acc: (95.94%) (5035/5248)\n",
            "Epoch: 69 | Batch_idx: 50 |  Loss: (0.1246) | Acc: (95.76%) (6251/6528)\n",
            "Epoch: 69 | Batch_idx: 60 |  Loss: (0.1238) | Acc: (95.65%) (7468/7808)\n",
            "Epoch: 69 | Batch_idx: 70 |  Loss: (0.1265) | Acc: (95.62%) (8690/9088)\n",
            "Epoch: 69 | Batch_idx: 80 |  Loss: (0.1245) | Acc: (95.75%) (9927/10368)\n",
            "Epoch: 69 | Batch_idx: 90 |  Loss: (0.1262) | Acc: (95.60%) (11136/11648)\n",
            "Epoch: 69 | Batch_idx: 100 |  Loss: (0.1265) | Acc: (95.60%) (12359/12928)\n",
            "Epoch: 69 | Batch_idx: 110 |  Loss: (0.1271) | Acc: (95.61%) (13584/14208)\n",
            "Epoch: 69 | Batch_idx: 120 |  Loss: (0.1263) | Acc: (95.64%) (14812/15488)\n",
            "Epoch: 69 | Batch_idx: 130 |  Loss: (0.1275) | Acc: (95.61%) (16032/16768)\n",
            "Epoch: 69 | Batch_idx: 140 |  Loss: (0.1275) | Acc: (95.64%) (17262/18048)\n",
            "Epoch: 69 | Batch_idx: 150 |  Loss: (0.1274) | Acc: (95.66%) (18490/19328)\n",
            "Epoch: 69 | Batch_idx: 160 |  Loss: (0.1304) | Acc: (95.57%) (19696/20608)\n",
            "Epoch: 69 | Batch_idx: 170 |  Loss: (0.1309) | Acc: (95.56%) (20917/21888)\n",
            "Epoch: 69 | Batch_idx: 180 |  Loss: (0.1312) | Acc: (95.54%) (22134/23168)\n",
            "Epoch: 69 | Batch_idx: 190 |  Loss: (0.1310) | Acc: (95.54%) (23358/24448)\n",
            "Epoch: 69 | Batch_idx: 200 |  Loss: (0.1317) | Acc: (95.49%) (24567/25728)\n",
            "Epoch: 69 | Batch_idx: 210 |  Loss: (0.1325) | Acc: (95.47%) (25784/27008)\n",
            "Epoch: 69 | Batch_idx: 220 |  Loss: (0.1331) | Acc: (95.44%) (26997/28288)\n",
            "Epoch: 69 | Batch_idx: 230 |  Loss: (0.1329) | Acc: (95.45%) (28222/29568)\n",
            "Epoch: 69 | Batch_idx: 240 |  Loss: (0.1331) | Acc: (95.44%) (29442/30848)\n",
            "Epoch: 69 | Batch_idx: 250 |  Loss: (0.1332) | Acc: (95.43%) (30659/32128)\n",
            "Epoch: 69 | Batch_idx: 260 |  Loss: (0.1337) | Acc: (95.41%) (31874/33408)\n",
            "Epoch: 69 | Batch_idx: 270 |  Loss: (0.1340) | Acc: (95.40%) (33094/34688)\n",
            "Epoch: 69 | Batch_idx: 280 |  Loss: (0.1343) | Acc: (95.38%) (34306/35968)\n",
            "Epoch: 69 | Batch_idx: 290 |  Loss: (0.1343) | Acc: (95.38%) (35527/37248)\n",
            "Epoch: 69 | Batch_idx: 300 |  Loss: (0.1341) | Acc: (95.39%) (36751/38528)\n",
            "Epoch: 69 | Batch_idx: 310 |  Loss: (0.1340) | Acc: (95.39%) (37971/39808)\n",
            "Epoch: 69 | Batch_idx: 320 |  Loss: (0.1338) | Acc: (95.38%) (39191/41088)\n",
            "Epoch: 69 | Batch_idx: 330 |  Loss: (0.1346) | Acc: (95.36%) (40403/42368)\n",
            "Epoch: 69 | Batch_idx: 340 |  Loss: (0.1343) | Acc: (95.38%) (41632/43648)\n",
            "Epoch: 69 | Batch_idx: 350 |  Loss: (0.1345) | Acc: (95.38%) (42854/44928)\n",
            "Epoch: 69 | Batch_idx: 360 |  Loss: (0.1350) | Acc: (95.36%) (44063/46208)\n",
            "Epoch: 69 | Batch_idx: 370 |  Loss: (0.1351) | Acc: (95.35%) (45278/47488)\n",
            "Epoch: 69 | Batch_idx: 380 |  Loss: (0.1351) | Acc: (95.33%) (46492/48768)\n",
            "Epoch: 69 | Batch_idx: 390 |  Loss: (0.1359) | Acc: (95.32%) (47661/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3911) | Acc: (88.81%) (8881/10000)\n",
            "Epoch: 70 | Batch_idx: 0 |  Loss: (0.1570) | Acc: (94.53%) (121/128)\n",
            "Epoch: 70 | Batch_idx: 10 |  Loss: (0.1352) | Acc: (95.45%) (1344/1408)\n",
            "Epoch: 70 | Batch_idx: 20 |  Loss: (0.1399) | Acc: (94.98%) (2553/2688)\n",
            "Epoch: 70 | Batch_idx: 30 |  Loss: (0.1390) | Acc: (95.01%) (3770/3968)\n",
            "Epoch: 70 | Batch_idx: 40 |  Loss: (0.1313) | Acc: (95.27%) (5000/5248)\n",
            "Epoch: 70 | Batch_idx: 50 |  Loss: (0.1288) | Acc: (95.34%) (6224/6528)\n",
            "Epoch: 70 | Batch_idx: 60 |  Loss: (0.1307) | Acc: (95.31%) (7442/7808)\n",
            "Epoch: 70 | Batch_idx: 70 |  Loss: (0.1354) | Acc: (95.11%) (8644/9088)\n",
            "Epoch: 70 | Batch_idx: 80 |  Loss: (0.1324) | Acc: (95.24%) (9875/10368)\n",
            "Epoch: 70 | Batch_idx: 90 |  Loss: (0.1306) | Acc: (95.29%) (11099/11648)\n",
            "Epoch: 70 | Batch_idx: 100 |  Loss: (0.1318) | Acc: (95.26%) (12315/12928)\n",
            "Epoch: 70 | Batch_idx: 110 |  Loss: (0.1317) | Acc: (95.24%) (13531/14208)\n",
            "Epoch: 70 | Batch_idx: 120 |  Loss: (0.1312) | Acc: (95.25%) (14753/15488)\n",
            "Epoch: 70 | Batch_idx: 130 |  Loss: (0.1317) | Acc: (95.24%) (15970/16768)\n",
            "Epoch: 70 | Batch_idx: 140 |  Loss: (0.1299) | Acc: (95.34%) (17207/18048)\n",
            "Epoch: 70 | Batch_idx: 150 |  Loss: (0.1302) | Acc: (95.33%) (18426/19328)\n",
            "Epoch: 70 | Batch_idx: 160 |  Loss: (0.1300) | Acc: (95.33%) (19645/20608)\n",
            "Epoch: 70 | Batch_idx: 170 |  Loss: (0.1291) | Acc: (95.34%) (20869/21888)\n",
            "Epoch: 70 | Batch_idx: 180 |  Loss: (0.1296) | Acc: (95.33%) (22087/23168)\n",
            "Epoch: 70 | Batch_idx: 190 |  Loss: (0.1305) | Acc: (95.30%) (23298/24448)\n",
            "Epoch: 70 | Batch_idx: 200 |  Loss: (0.1313) | Acc: (95.30%) (24520/25728)\n",
            "Epoch: 70 | Batch_idx: 210 |  Loss: (0.1323) | Acc: (95.31%) (25740/27008)\n",
            "Epoch: 70 | Batch_idx: 220 |  Loss: (0.1321) | Acc: (95.31%) (26962/28288)\n",
            "Epoch: 70 | Batch_idx: 230 |  Loss: (0.1325) | Acc: (95.28%) (28173/29568)\n",
            "Epoch: 70 | Batch_idx: 240 |  Loss: (0.1324) | Acc: (95.30%) (29397/30848)\n",
            "Epoch: 70 | Batch_idx: 250 |  Loss: (0.1320) | Acc: (95.30%) (30619/32128)\n",
            "Epoch: 70 | Batch_idx: 260 |  Loss: (0.1320) | Acc: (95.31%) (31841/33408)\n",
            "Epoch: 70 | Batch_idx: 270 |  Loss: (0.1316) | Acc: (95.33%) (33069/34688)\n",
            "Epoch: 70 | Batch_idx: 280 |  Loss: (0.1320) | Acc: (95.32%) (34285/35968)\n",
            "Epoch: 70 | Batch_idx: 290 |  Loss: (0.1317) | Acc: (95.35%) (35517/37248)\n",
            "Epoch: 70 | Batch_idx: 300 |  Loss: (0.1318) | Acc: (95.37%) (36746/38528)\n",
            "Epoch: 70 | Batch_idx: 310 |  Loss: (0.1328) | Acc: (95.35%) (37956/39808)\n",
            "Epoch: 70 | Batch_idx: 320 |  Loss: (0.1327) | Acc: (95.34%) (39172/41088)\n",
            "Epoch: 70 | Batch_idx: 330 |  Loss: (0.1331) | Acc: (95.33%) (40388/42368)\n",
            "Epoch: 70 | Batch_idx: 340 |  Loss: (0.1331) | Acc: (95.32%) (41606/43648)\n",
            "Epoch: 70 | Batch_idx: 350 |  Loss: (0.1329) | Acc: (95.32%) (42825/44928)\n",
            "Epoch: 70 | Batch_idx: 360 |  Loss: (0.1333) | Acc: (95.30%) (44035/46208)\n",
            "Epoch: 70 | Batch_idx: 370 |  Loss: (0.1338) | Acc: (95.27%) (45240/47488)\n",
            "Epoch: 70 | Batch_idx: 380 |  Loss: (0.1336) | Acc: (95.28%) (46466/48768)\n",
            "Epoch: 70 | Batch_idx: 390 |  Loss: (0.1336) | Acc: (95.29%) (47646/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3967) | Acc: (89.34%) (8934/10000)\n",
            "Epoch: 71 | Batch_idx: 0 |  Loss: (0.0691) | Acc: (98.44%) (126/128)\n",
            "Epoch: 71 | Batch_idx: 10 |  Loss: (0.1031) | Acc: (96.66%) (1361/1408)\n",
            "Epoch: 71 | Batch_idx: 20 |  Loss: (0.1067) | Acc: (96.54%) (2595/2688)\n",
            "Epoch: 71 | Batch_idx: 30 |  Loss: (0.1084) | Acc: (96.32%) (3822/3968)\n",
            "Epoch: 71 | Batch_idx: 40 |  Loss: (0.1127) | Acc: (96.07%) (5042/5248)\n",
            "Epoch: 71 | Batch_idx: 50 |  Loss: (0.1100) | Acc: (96.11%) (6274/6528)\n",
            "Epoch: 71 | Batch_idx: 60 |  Loss: (0.1110) | Acc: (96.06%) (7500/7808)\n",
            "Epoch: 71 | Batch_idx: 70 |  Loss: (0.1127) | Acc: (95.90%) (8715/9088)\n",
            "Epoch: 71 | Batch_idx: 80 |  Loss: (0.1155) | Acc: (95.78%) (9930/10368)\n",
            "Epoch: 71 | Batch_idx: 90 |  Loss: (0.1175) | Acc: (95.71%) (11148/11648)\n",
            "Epoch: 71 | Batch_idx: 100 |  Loss: (0.1174) | Acc: (95.71%) (12373/12928)\n",
            "Epoch: 71 | Batch_idx: 110 |  Loss: (0.1188) | Acc: (95.71%) (13599/14208)\n",
            "Epoch: 71 | Batch_idx: 120 |  Loss: (0.1199) | Acc: (95.71%) (14824/15488)\n",
            "Epoch: 71 | Batch_idx: 130 |  Loss: (0.1212) | Acc: (95.71%) (16049/16768)\n",
            "Epoch: 71 | Batch_idx: 140 |  Loss: (0.1225) | Acc: (95.66%) (17265/18048)\n",
            "Epoch: 71 | Batch_idx: 150 |  Loss: (0.1224) | Acc: (95.67%) (18491/19328)\n",
            "Epoch: 71 | Batch_idx: 160 |  Loss: (0.1226) | Acc: (95.68%) (19718/20608)\n",
            "Epoch: 71 | Batch_idx: 170 |  Loss: (0.1229) | Acc: (95.68%) (20942/21888)\n",
            "Epoch: 71 | Batch_idx: 180 |  Loss: (0.1242) | Acc: (95.64%) (22159/23168)\n",
            "Epoch: 71 | Batch_idx: 190 |  Loss: (0.1252) | Acc: (95.61%) (23374/24448)\n",
            "Epoch: 71 | Batch_idx: 200 |  Loss: (0.1261) | Acc: (95.57%) (24587/25728)\n",
            "Epoch: 71 | Batch_idx: 210 |  Loss: (0.1263) | Acc: (95.56%) (25808/27008)\n",
            "Epoch: 71 | Batch_idx: 220 |  Loss: (0.1275) | Acc: (95.51%) (27019/28288)\n",
            "Epoch: 71 | Batch_idx: 230 |  Loss: (0.1283) | Acc: (95.50%) (28236/29568)\n",
            "Epoch: 71 | Batch_idx: 240 |  Loss: (0.1295) | Acc: (95.45%) (29445/30848)\n",
            "Epoch: 71 | Batch_idx: 250 |  Loss: (0.1311) | Acc: (95.41%) (30653/32128)\n",
            "Epoch: 71 | Batch_idx: 260 |  Loss: (0.1307) | Acc: (95.40%) (31872/33408)\n",
            "Epoch: 71 | Batch_idx: 270 |  Loss: (0.1308) | Acc: (95.40%) (33094/34688)\n",
            "Epoch: 71 | Batch_idx: 280 |  Loss: (0.1311) | Acc: (95.40%) (34314/35968)\n",
            "Epoch: 71 | Batch_idx: 290 |  Loss: (0.1314) | Acc: (95.39%) (35532/37248)\n",
            "Epoch: 71 | Batch_idx: 300 |  Loss: (0.1316) | Acc: (95.38%) (36749/38528)\n",
            "Epoch: 71 | Batch_idx: 310 |  Loss: (0.1320) | Acc: (95.38%) (37968/39808)\n",
            "Epoch: 71 | Batch_idx: 320 |  Loss: (0.1320) | Acc: (95.39%) (39192/41088)\n",
            "Epoch: 71 | Batch_idx: 330 |  Loss: (0.1326) | Acc: (95.37%) (40406/42368)\n",
            "Epoch: 71 | Batch_idx: 340 |  Loss: (0.1331) | Acc: (95.34%) (41614/43648)\n",
            "Epoch: 71 | Batch_idx: 350 |  Loss: (0.1338) | Acc: (95.31%) (42821/44928)\n",
            "Epoch: 71 | Batch_idx: 360 |  Loss: (0.1340) | Acc: (95.31%) (44041/46208)\n",
            "Epoch: 71 | Batch_idx: 370 |  Loss: (0.1341) | Acc: (95.32%) (45265/47488)\n",
            "Epoch: 71 | Batch_idx: 380 |  Loss: (0.1340) | Acc: (95.32%) (46484/48768)\n",
            "Epoch: 71 | Batch_idx: 390 |  Loss: (0.1340) | Acc: (95.31%) (47653/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3581) | Acc: (89.77%) (8977/10000)\n",
            "Epoch: 72 | Batch_idx: 0 |  Loss: (0.0876) | Acc: (97.66%) (125/128)\n",
            "Epoch: 72 | Batch_idx: 10 |  Loss: (0.1174) | Acc: (95.81%) (1349/1408)\n",
            "Epoch: 72 | Batch_idx: 20 |  Loss: (0.1146) | Acc: (95.76%) (2574/2688)\n",
            "Epoch: 72 | Batch_idx: 30 |  Loss: (0.1166) | Acc: (95.82%) (3802/3968)\n",
            "Epoch: 72 | Batch_idx: 40 |  Loss: (0.1156) | Acc: (95.94%) (5035/5248)\n",
            "Epoch: 72 | Batch_idx: 50 |  Loss: (0.1144) | Acc: (95.99%) (6266/6528)\n",
            "Epoch: 72 | Batch_idx: 60 |  Loss: (0.1171) | Acc: (95.91%) (7489/7808)\n",
            "Epoch: 72 | Batch_idx: 70 |  Loss: (0.1153) | Acc: (95.93%) (8718/9088)\n",
            "Epoch: 72 | Batch_idx: 80 |  Loss: (0.1139) | Acc: (95.93%) (9946/10368)\n",
            "Epoch: 72 | Batch_idx: 90 |  Loss: (0.1160) | Acc: (95.90%) (11170/11648)\n",
            "Epoch: 72 | Batch_idx: 100 |  Loss: (0.1170) | Acc: (95.85%) (12392/12928)\n",
            "Epoch: 72 | Batch_idx: 110 |  Loss: (0.1163) | Acc: (95.93%) (13630/14208)\n",
            "Epoch: 72 | Batch_idx: 120 |  Loss: (0.1176) | Acc: (95.89%) (14852/15488)\n",
            "Epoch: 72 | Batch_idx: 130 |  Loss: (0.1200) | Acc: (95.83%) (16069/16768)\n",
            "Epoch: 72 | Batch_idx: 140 |  Loss: (0.1212) | Acc: (95.79%) (17288/18048)\n",
            "Epoch: 72 | Batch_idx: 150 |  Loss: (0.1231) | Acc: (95.74%) (18504/19328)\n",
            "Epoch: 72 | Batch_idx: 160 |  Loss: (0.1239) | Acc: (95.71%) (19723/20608)\n",
            "Epoch: 72 | Batch_idx: 170 |  Loss: (0.1229) | Acc: (95.76%) (20960/21888)\n",
            "Epoch: 72 | Batch_idx: 180 |  Loss: (0.1238) | Acc: (95.73%) (22178/23168)\n",
            "Epoch: 72 | Batch_idx: 190 |  Loss: (0.1265) | Acc: (95.66%) (23386/24448)\n",
            "Epoch: 72 | Batch_idx: 200 |  Loss: (0.1268) | Acc: (95.62%) (24602/25728)\n",
            "Epoch: 72 | Batch_idx: 210 |  Loss: (0.1271) | Acc: (95.63%) (25829/27008)\n",
            "Epoch: 72 | Batch_idx: 220 |  Loss: (0.1267) | Acc: (95.64%) (27054/28288)\n",
            "Epoch: 72 | Batch_idx: 230 |  Loss: (0.1285) | Acc: (95.58%) (28260/29568)\n",
            "Epoch: 72 | Batch_idx: 240 |  Loss: (0.1289) | Acc: (95.54%) (29472/30848)\n",
            "Epoch: 72 | Batch_idx: 250 |  Loss: (0.1294) | Acc: (95.51%) (30684/32128)\n",
            "Epoch: 72 | Batch_idx: 260 |  Loss: (0.1284) | Acc: (95.54%) (31918/33408)\n",
            "Epoch: 72 | Batch_idx: 270 |  Loss: (0.1287) | Acc: (95.53%) (33138/34688)\n",
            "Epoch: 72 | Batch_idx: 280 |  Loss: (0.1289) | Acc: (95.53%) (34361/35968)\n",
            "Epoch: 72 | Batch_idx: 290 |  Loss: (0.1296) | Acc: (95.51%) (35574/37248)\n",
            "Epoch: 72 | Batch_idx: 300 |  Loss: (0.1303) | Acc: (95.46%) (36777/38528)\n",
            "Epoch: 72 | Batch_idx: 310 |  Loss: (0.1308) | Acc: (95.44%) (37992/39808)\n",
            "Epoch: 72 | Batch_idx: 320 |  Loss: (0.1305) | Acc: (95.45%) (39218/41088)\n",
            "Epoch: 72 | Batch_idx: 330 |  Loss: (0.1312) | Acc: (95.42%) (40426/42368)\n",
            "Epoch: 72 | Batch_idx: 340 |  Loss: (0.1323) | Acc: (95.36%) (41624/43648)\n",
            "Epoch: 72 | Batch_idx: 350 |  Loss: (0.1334) | Acc: (95.32%) (42826/44928)\n",
            "Epoch: 72 | Batch_idx: 360 |  Loss: (0.1332) | Acc: (95.33%) (44051/46208)\n",
            "Epoch: 72 | Batch_idx: 370 |  Loss: (0.1335) | Acc: (95.33%) (45271/47488)\n",
            "Epoch: 72 | Batch_idx: 380 |  Loss: (0.1338) | Acc: (95.33%) (46491/48768)\n",
            "Epoch: 72 | Batch_idx: 390 |  Loss: (0.1341) | Acc: (95.31%) (47654/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3855) | Acc: (89.36%) (8936/10000)\n",
            "Epoch: 73 | Batch_idx: 0 |  Loss: (0.0950) | Acc: (97.66%) (125/128)\n",
            "Epoch: 73 | Batch_idx: 10 |  Loss: (0.1262) | Acc: (95.74%) (1348/1408)\n",
            "Epoch: 73 | Batch_idx: 20 |  Loss: (0.1210) | Acc: (96.06%) (2582/2688)\n",
            "Epoch: 73 | Batch_idx: 30 |  Loss: (0.1181) | Acc: (96.09%) (3813/3968)\n",
            "Epoch: 73 | Batch_idx: 40 |  Loss: (0.1185) | Acc: (95.98%) (5037/5248)\n",
            "Epoch: 73 | Batch_idx: 50 |  Loss: (0.1207) | Acc: (95.97%) (6265/6528)\n",
            "Epoch: 73 | Batch_idx: 60 |  Loss: (0.1234) | Acc: (95.88%) (7486/7808)\n",
            "Epoch: 73 | Batch_idx: 70 |  Loss: (0.1245) | Acc: (95.76%) (8703/9088)\n",
            "Epoch: 73 | Batch_idx: 80 |  Loss: (0.1242) | Acc: (95.86%) (9939/10368)\n",
            "Epoch: 73 | Batch_idx: 90 |  Loss: (0.1240) | Acc: (95.81%) (11160/11648)\n",
            "Epoch: 73 | Batch_idx: 100 |  Loss: (0.1223) | Acc: (95.85%) (12392/12928)\n",
            "Epoch: 73 | Batch_idx: 110 |  Loss: (0.1214) | Acc: (95.85%) (13619/14208)\n",
            "Epoch: 73 | Batch_idx: 120 |  Loss: (0.1206) | Acc: (95.91%) (14854/15488)\n",
            "Epoch: 73 | Batch_idx: 130 |  Loss: (0.1208) | Acc: (95.89%) (16079/16768)\n",
            "Epoch: 73 | Batch_idx: 140 |  Loss: (0.1213) | Acc: (95.88%) (17304/18048)\n",
            "Epoch: 73 | Batch_idx: 150 |  Loss: (0.1202) | Acc: (95.90%) (18535/19328)\n",
            "Epoch: 73 | Batch_idx: 160 |  Loss: (0.1231) | Acc: (95.82%) (19747/20608)\n",
            "Epoch: 73 | Batch_idx: 170 |  Loss: (0.1238) | Acc: (95.82%) (20974/21888)\n",
            "Epoch: 73 | Batch_idx: 180 |  Loss: (0.1261) | Acc: (95.76%) (22186/23168)\n",
            "Epoch: 73 | Batch_idx: 190 |  Loss: (0.1267) | Acc: (95.73%) (23405/24448)\n",
            "Epoch: 73 | Batch_idx: 200 |  Loss: (0.1282) | Acc: (95.71%) (24624/25728)\n",
            "Epoch: 73 | Batch_idx: 210 |  Loss: (0.1278) | Acc: (95.71%) (25850/27008)\n",
            "Epoch: 73 | Batch_idx: 220 |  Loss: (0.1286) | Acc: (95.65%) (27058/28288)\n",
            "Epoch: 73 | Batch_idx: 230 |  Loss: (0.1285) | Acc: (95.65%) (28281/29568)\n",
            "Epoch: 73 | Batch_idx: 240 |  Loss: (0.1279) | Acc: (95.66%) (29509/30848)\n",
            "Epoch: 73 | Batch_idx: 250 |  Loss: (0.1278) | Acc: (95.67%) (30737/32128)\n",
            "Epoch: 73 | Batch_idx: 260 |  Loss: (0.1284) | Acc: (95.65%) (31954/33408)\n",
            "Epoch: 73 | Batch_idx: 270 |  Loss: (0.1291) | Acc: (95.63%) (33171/34688)\n",
            "Epoch: 73 | Batch_idx: 280 |  Loss: (0.1291) | Acc: (95.61%) (34390/35968)\n",
            "Epoch: 73 | Batch_idx: 290 |  Loss: (0.1288) | Acc: (95.61%) (35614/37248)\n",
            "Epoch: 73 | Batch_idx: 300 |  Loss: (0.1286) | Acc: (95.60%) (36834/38528)\n",
            "Epoch: 73 | Batch_idx: 310 |  Loss: (0.1287) | Acc: (95.60%) (38055/39808)\n",
            "Epoch: 73 | Batch_idx: 320 |  Loss: (0.1293) | Acc: (95.56%) (39265/41088)\n",
            "Epoch: 73 | Batch_idx: 330 |  Loss: (0.1293) | Acc: (95.56%) (40487/42368)\n",
            "Epoch: 73 | Batch_idx: 340 |  Loss: (0.1294) | Acc: (95.55%) (41704/43648)\n",
            "Epoch: 73 | Batch_idx: 350 |  Loss: (0.1294) | Acc: (95.55%) (42927/44928)\n",
            "Epoch: 73 | Batch_idx: 360 |  Loss: (0.1298) | Acc: (95.54%) (44148/46208)\n",
            "Epoch: 73 | Batch_idx: 370 |  Loss: (0.1297) | Acc: (95.54%) (45368/47488)\n",
            "Epoch: 73 | Batch_idx: 380 |  Loss: (0.1299) | Acc: (95.51%) (46578/48768)\n",
            "Epoch: 73 | Batch_idx: 390 |  Loss: (0.1305) | Acc: (95.48%) (47739/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4158) | Acc: (88.39%) (8839/10000)\n",
            "Epoch: 74 | Batch_idx: 0 |  Loss: (0.1535) | Acc: (93.75%) (120/128)\n",
            "Epoch: 74 | Batch_idx: 10 |  Loss: (0.1397) | Acc: (94.96%) (1337/1408)\n",
            "Epoch: 74 | Batch_idx: 20 |  Loss: (0.1310) | Acc: (95.46%) (2566/2688)\n",
            "Epoch: 74 | Batch_idx: 30 |  Loss: (0.1291) | Acc: (95.39%) (3785/3968)\n",
            "Epoch: 74 | Batch_idx: 40 |  Loss: (0.1261) | Acc: (95.60%) (5017/5248)\n",
            "Epoch: 74 | Batch_idx: 50 |  Loss: (0.1253) | Acc: (95.76%) (6251/6528)\n",
            "Epoch: 74 | Batch_idx: 60 |  Loss: (0.1240) | Acc: (95.81%) (7481/7808)\n",
            "Epoch: 74 | Batch_idx: 70 |  Loss: (0.1256) | Acc: (95.73%) (8700/9088)\n",
            "Epoch: 74 | Batch_idx: 80 |  Loss: (0.1233) | Acc: (95.77%) (9929/10368)\n",
            "Epoch: 74 | Batch_idx: 90 |  Loss: (0.1216) | Acc: (95.86%) (11166/11648)\n",
            "Epoch: 74 | Batch_idx: 100 |  Loss: (0.1189) | Acc: (95.95%) (12404/12928)\n",
            "Epoch: 74 | Batch_idx: 110 |  Loss: (0.1207) | Acc: (95.87%) (13621/14208)\n",
            "Epoch: 74 | Batch_idx: 120 |  Loss: (0.1219) | Acc: (95.82%) (14840/15488)\n",
            "Epoch: 74 | Batch_idx: 130 |  Loss: (0.1223) | Acc: (95.82%) (16067/16768)\n",
            "Epoch: 74 | Batch_idx: 140 |  Loss: (0.1234) | Acc: (95.78%) (17287/18048)\n",
            "Epoch: 74 | Batch_idx: 150 |  Loss: (0.1236) | Acc: (95.79%) (18514/19328)\n",
            "Epoch: 74 | Batch_idx: 160 |  Loss: (0.1256) | Acc: (95.71%) (19723/20608)\n",
            "Epoch: 74 | Batch_idx: 170 |  Loss: (0.1271) | Acc: (95.64%) (20933/21888)\n",
            "Epoch: 74 | Batch_idx: 180 |  Loss: (0.1268) | Acc: (95.64%) (22157/23168)\n",
            "Epoch: 74 | Batch_idx: 190 |  Loss: (0.1277) | Acc: (95.61%) (23374/24448)\n",
            "Epoch: 74 | Batch_idx: 200 |  Loss: (0.1279) | Acc: (95.60%) (24595/25728)\n",
            "Epoch: 74 | Batch_idx: 210 |  Loss: (0.1283) | Acc: (95.55%) (25805/27008)\n",
            "Epoch: 74 | Batch_idx: 220 |  Loss: (0.1278) | Acc: (95.56%) (27031/28288)\n",
            "Epoch: 74 | Batch_idx: 230 |  Loss: (0.1277) | Acc: (95.57%) (28257/29568)\n",
            "Epoch: 74 | Batch_idx: 240 |  Loss: (0.1267) | Acc: (95.59%) (29489/30848)\n",
            "Epoch: 74 | Batch_idx: 250 |  Loss: (0.1274) | Acc: (95.60%) (30714/32128)\n",
            "Epoch: 74 | Batch_idx: 260 |  Loss: (0.1286) | Acc: (95.55%) (31923/33408)\n",
            "Epoch: 74 | Batch_idx: 270 |  Loss: (0.1282) | Acc: (95.57%) (33153/34688)\n",
            "Epoch: 74 | Batch_idx: 280 |  Loss: (0.1280) | Acc: (95.58%) (34380/35968)\n",
            "Epoch: 74 | Batch_idx: 290 |  Loss: (0.1300) | Acc: (95.49%) (35568/37248)\n",
            "Epoch: 74 | Batch_idx: 300 |  Loss: (0.1305) | Acc: (95.47%) (36784/38528)\n",
            "Epoch: 74 | Batch_idx: 310 |  Loss: (0.1302) | Acc: (95.48%) (38007/39808)\n",
            "Epoch: 74 | Batch_idx: 320 |  Loss: (0.1309) | Acc: (95.44%) (39215/41088)\n",
            "Epoch: 74 | Batch_idx: 330 |  Loss: (0.1304) | Acc: (95.46%) (40444/42368)\n",
            "Epoch: 74 | Batch_idx: 340 |  Loss: (0.1309) | Acc: (95.44%) (41658/43648)\n",
            "Epoch: 74 | Batch_idx: 350 |  Loss: (0.1316) | Acc: (95.42%) (42870/44928)\n",
            "Epoch: 74 | Batch_idx: 360 |  Loss: (0.1319) | Acc: (95.40%) (44081/46208)\n",
            "Epoch: 74 | Batch_idx: 370 |  Loss: (0.1311) | Acc: (95.42%) (45313/47488)\n",
            "Epoch: 74 | Batch_idx: 380 |  Loss: (0.1316) | Acc: (95.40%) (46523/48768)\n",
            "Epoch: 74 | Batch_idx: 390 |  Loss: (0.1318) | Acc: (95.39%) (47696/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4168) | Acc: (88.80%) (8880/10000)\n",
            "Epoch: 75 | Batch_idx: 0 |  Loss: (0.0910) | Acc: (96.88%) (124/128)\n",
            "Epoch: 75 | Batch_idx: 10 |  Loss: (0.1256) | Acc: (95.45%) (1344/1408)\n",
            "Epoch: 75 | Batch_idx: 20 |  Loss: (0.1186) | Acc: (95.54%) (2568/2688)\n",
            "Epoch: 75 | Batch_idx: 30 |  Loss: (0.1160) | Acc: (95.46%) (3788/3968)\n",
            "Epoch: 75 | Batch_idx: 40 |  Loss: (0.1162) | Acc: (95.46%) (5010/5248)\n",
            "Epoch: 75 | Batch_idx: 50 |  Loss: (0.1185) | Acc: (95.62%) (6242/6528)\n",
            "Epoch: 75 | Batch_idx: 60 |  Loss: (0.1218) | Acc: (95.54%) (7460/7808)\n",
            "Epoch: 75 | Batch_idx: 70 |  Loss: (0.1256) | Acc: (95.42%) (8672/9088)\n",
            "Epoch: 75 | Batch_idx: 80 |  Loss: (0.1274) | Acc: (95.47%) (9898/10368)\n",
            "Epoch: 75 | Batch_idx: 90 |  Loss: (0.1278) | Acc: (95.58%) (11133/11648)\n",
            "Epoch: 75 | Batch_idx: 100 |  Loss: (0.1272) | Acc: (95.55%) (12353/12928)\n",
            "Epoch: 75 | Batch_idx: 110 |  Loss: (0.1265) | Acc: (95.57%) (13579/14208)\n",
            "Epoch: 75 | Batch_idx: 120 |  Loss: (0.1258) | Acc: (95.60%) (14806/15488)\n",
            "Epoch: 75 | Batch_idx: 130 |  Loss: (0.1246) | Acc: (95.63%) (16035/16768)\n",
            "Epoch: 75 | Batch_idx: 140 |  Loss: (0.1248) | Acc: (95.65%) (17263/18048)\n",
            "Epoch: 75 | Batch_idx: 150 |  Loss: (0.1258) | Acc: (95.62%) (18482/19328)\n",
            "Epoch: 75 | Batch_idx: 160 |  Loss: (0.1235) | Acc: (95.72%) (19725/20608)\n",
            "Epoch: 75 | Batch_idx: 170 |  Loss: (0.1229) | Acc: (95.72%) (20952/21888)\n",
            "Epoch: 75 | Batch_idx: 180 |  Loss: (0.1234) | Acc: (95.71%) (22174/23168)\n",
            "Epoch: 75 | Batch_idx: 190 |  Loss: (0.1234) | Acc: (95.67%) (23390/24448)\n",
            "Epoch: 75 | Batch_idx: 200 |  Loss: (0.1230) | Acc: (95.67%) (24614/25728)\n",
            "Epoch: 75 | Batch_idx: 210 |  Loss: (0.1229) | Acc: (95.69%) (25845/27008)\n",
            "Epoch: 75 | Batch_idx: 220 |  Loss: (0.1231) | Acc: (95.67%) (27063/28288)\n",
            "Epoch: 75 | Batch_idx: 230 |  Loss: (0.1232) | Acc: (95.68%) (28290/29568)\n",
            "Epoch: 75 | Batch_idx: 240 |  Loss: (0.1242) | Acc: (95.62%) (29498/30848)\n",
            "Epoch: 75 | Batch_idx: 250 |  Loss: (0.1246) | Acc: (95.62%) (30720/32128)\n",
            "Epoch: 75 | Batch_idx: 260 |  Loss: (0.1245) | Acc: (95.60%) (31939/33408)\n",
            "Epoch: 75 | Batch_idx: 270 |  Loss: (0.1247) | Acc: (95.62%) (33167/34688)\n",
            "Epoch: 75 | Batch_idx: 280 |  Loss: (0.1256) | Acc: (95.59%) (34383/35968)\n",
            "Epoch: 75 | Batch_idx: 290 |  Loss: (0.1260) | Acc: (95.57%) (35598/37248)\n",
            "Epoch: 75 | Batch_idx: 300 |  Loss: (0.1260) | Acc: (95.56%) (36818/38528)\n",
            "Epoch: 75 | Batch_idx: 310 |  Loss: (0.1267) | Acc: (95.53%) (38029/39808)\n",
            "Epoch: 75 | Batch_idx: 320 |  Loss: (0.1269) | Acc: (95.53%) (39250/41088)\n",
            "Epoch: 75 | Batch_idx: 330 |  Loss: (0.1276) | Acc: (95.50%) (40463/42368)\n",
            "Epoch: 75 | Batch_idx: 340 |  Loss: (0.1277) | Acc: (95.51%) (41687/43648)\n",
            "Epoch: 75 | Batch_idx: 350 |  Loss: (0.1285) | Acc: (95.49%) (42900/44928)\n",
            "Epoch: 75 | Batch_idx: 360 |  Loss: (0.1291) | Acc: (95.47%) (44113/46208)\n",
            "Epoch: 75 | Batch_idx: 370 |  Loss: (0.1298) | Acc: (95.44%) (45321/47488)\n",
            "Epoch: 75 | Batch_idx: 380 |  Loss: (0.1307) | Acc: (95.41%) (46531/48768)\n",
            "Epoch: 75 | Batch_idx: 390 |  Loss: (0.1312) | Acc: (95.39%) (47697/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4433) | Acc: (88.22%) (8822/10000)\n",
            "Epoch: 76 | Batch_idx: 0 |  Loss: (0.0890) | Acc: (96.09%) (123/128)\n",
            "Epoch: 76 | Batch_idx: 10 |  Loss: (0.1436) | Acc: (94.46%) (1330/1408)\n",
            "Epoch: 76 | Batch_idx: 20 |  Loss: (0.1254) | Acc: (95.65%) (2571/2688)\n",
            "Epoch: 76 | Batch_idx: 30 |  Loss: (0.1206) | Acc: (95.82%) (3802/3968)\n",
            "Epoch: 76 | Batch_idx: 40 |  Loss: (0.1191) | Acc: (95.94%) (5035/5248)\n",
            "Epoch: 76 | Batch_idx: 50 |  Loss: (0.1229) | Acc: (95.82%) (6255/6528)\n",
            "Epoch: 76 | Batch_idx: 60 |  Loss: (0.1227) | Acc: (95.85%) (7484/7808)\n",
            "Epoch: 76 | Batch_idx: 70 |  Loss: (0.1194) | Acc: (95.96%) (8721/9088)\n",
            "Epoch: 76 | Batch_idx: 80 |  Loss: (0.1221) | Acc: (95.87%) (9940/10368)\n",
            "Epoch: 76 | Batch_idx: 90 |  Loss: (0.1214) | Acc: (95.87%) (11167/11648)\n",
            "Epoch: 76 | Batch_idx: 100 |  Loss: (0.1227) | Acc: (95.81%) (12386/12928)\n",
            "Epoch: 76 | Batch_idx: 110 |  Loss: (0.1239) | Acc: (95.76%) (13606/14208)\n",
            "Epoch: 76 | Batch_idx: 120 |  Loss: (0.1220) | Acc: (95.80%) (14838/15488)\n",
            "Epoch: 76 | Batch_idx: 130 |  Loss: (0.1226) | Acc: (95.78%) (16061/16768)\n",
            "Epoch: 76 | Batch_idx: 140 |  Loss: (0.1234) | Acc: (95.74%) (17280/18048)\n",
            "Epoch: 76 | Batch_idx: 150 |  Loss: (0.1223) | Acc: (95.81%) (18519/19328)\n",
            "Epoch: 76 | Batch_idx: 160 |  Loss: (0.1224) | Acc: (95.79%) (19741/20608)\n",
            "Epoch: 76 | Batch_idx: 170 |  Loss: (0.1227) | Acc: (95.76%) (20961/21888)\n",
            "Epoch: 76 | Batch_idx: 180 |  Loss: (0.1244) | Acc: (95.70%) (22171/23168)\n",
            "Epoch: 76 | Batch_idx: 190 |  Loss: (0.1236) | Acc: (95.71%) (23400/24448)\n",
            "Epoch: 76 | Batch_idx: 200 |  Loss: (0.1248) | Acc: (95.68%) (24616/25728)\n",
            "Epoch: 76 | Batch_idx: 210 |  Loss: (0.1247) | Acc: (95.68%) (25840/27008)\n",
            "Epoch: 76 | Batch_idx: 220 |  Loss: (0.1262) | Acc: (95.62%) (27050/28288)\n",
            "Epoch: 76 | Batch_idx: 230 |  Loss: (0.1264) | Acc: (95.64%) (28280/29568)\n",
            "Epoch: 76 | Batch_idx: 240 |  Loss: (0.1265) | Acc: (95.63%) (29500/30848)\n",
            "Epoch: 76 | Batch_idx: 250 |  Loss: (0.1272) | Acc: (95.62%) (30722/32128)\n",
            "Epoch: 76 | Batch_idx: 260 |  Loss: (0.1287) | Acc: (95.57%) (31929/33408)\n",
            "Epoch: 76 | Batch_idx: 270 |  Loss: (0.1290) | Acc: (95.54%) (33140/34688)\n",
            "Epoch: 76 | Batch_idx: 280 |  Loss: (0.1281) | Acc: (95.58%) (34379/35968)\n",
            "Epoch: 76 | Batch_idx: 290 |  Loss: (0.1286) | Acc: (95.56%) (35594/37248)\n",
            "Epoch: 76 | Batch_idx: 300 |  Loss: (0.1296) | Acc: (95.51%) (36799/38528)\n",
            "Epoch: 76 | Batch_idx: 310 |  Loss: (0.1294) | Acc: (95.52%) (38024/39808)\n",
            "Epoch: 76 | Batch_idx: 320 |  Loss: (0.1299) | Acc: (95.49%) (39235/41088)\n",
            "Epoch: 76 | Batch_idx: 330 |  Loss: (0.1304) | Acc: (95.46%) (40444/42368)\n",
            "Epoch: 76 | Batch_idx: 340 |  Loss: (0.1309) | Acc: (95.43%) (41653/43648)\n",
            "Epoch: 76 | Batch_idx: 350 |  Loss: (0.1310) | Acc: (95.41%) (42867/44928)\n",
            "Epoch: 76 | Batch_idx: 360 |  Loss: (0.1314) | Acc: (95.40%) (44083/46208)\n",
            "Epoch: 76 | Batch_idx: 370 |  Loss: (0.1320) | Acc: (95.38%) (45293/47488)\n",
            "Epoch: 76 | Batch_idx: 380 |  Loss: (0.1323) | Acc: (95.36%) (46504/48768)\n",
            "Epoch: 76 | Batch_idx: 390 |  Loss: (0.1330) | Acc: (95.32%) (47661/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4172) | Acc: (88.57%) (8857/10000)\n",
            "Epoch: 77 | Batch_idx: 0 |  Loss: (0.1304) | Acc: (95.31%) (122/128)\n",
            "Epoch: 77 | Batch_idx: 10 |  Loss: (0.1179) | Acc: (96.31%) (1356/1408)\n",
            "Epoch: 77 | Batch_idx: 20 |  Loss: (0.1145) | Acc: (96.06%) (2582/2688)\n",
            "Epoch: 77 | Batch_idx: 30 |  Loss: (0.1332) | Acc: (95.56%) (3792/3968)\n",
            "Epoch: 77 | Batch_idx: 40 |  Loss: (0.1280) | Acc: (95.56%) (5015/5248)\n",
            "Epoch: 77 | Batch_idx: 50 |  Loss: (0.1266) | Acc: (95.62%) (6242/6528)\n",
            "Epoch: 77 | Batch_idx: 60 |  Loss: (0.1222) | Acc: (95.77%) (7478/7808)\n",
            "Epoch: 77 | Batch_idx: 70 |  Loss: (0.1190) | Acc: (95.83%) (8709/9088)\n",
            "Epoch: 77 | Batch_idx: 80 |  Loss: (0.1169) | Acc: (95.88%) (9941/10368)\n",
            "Epoch: 77 | Batch_idx: 90 |  Loss: (0.1205) | Acc: (95.79%) (11158/11648)\n",
            "Epoch: 77 | Batch_idx: 100 |  Loss: (0.1199) | Acc: (95.83%) (12389/12928)\n",
            "Epoch: 77 | Batch_idx: 110 |  Loss: (0.1221) | Acc: (95.81%) (13613/14208)\n",
            "Epoch: 77 | Batch_idx: 120 |  Loss: (0.1228) | Acc: (95.79%) (14836/15488)\n",
            "Epoch: 77 | Batch_idx: 130 |  Loss: (0.1241) | Acc: (95.72%) (16051/16768)\n",
            "Epoch: 77 | Batch_idx: 140 |  Loss: (0.1240) | Acc: (95.76%) (17283/18048)\n",
            "Epoch: 77 | Batch_idx: 150 |  Loss: (0.1250) | Acc: (95.72%) (18500/19328)\n",
            "Epoch: 77 | Batch_idx: 160 |  Loss: (0.1253) | Acc: (95.72%) (19727/20608)\n",
            "Epoch: 77 | Batch_idx: 170 |  Loss: (0.1252) | Acc: (95.72%) (20951/21888)\n",
            "Epoch: 77 | Batch_idx: 180 |  Loss: (0.1238) | Acc: (95.76%) (22185/23168)\n",
            "Epoch: 77 | Batch_idx: 190 |  Loss: (0.1235) | Acc: (95.77%) (23415/24448)\n",
            "Epoch: 77 | Batch_idx: 200 |  Loss: (0.1235) | Acc: (95.79%) (24645/25728)\n",
            "Epoch: 77 | Batch_idx: 210 |  Loss: (0.1244) | Acc: (95.77%) (25866/27008)\n",
            "Epoch: 77 | Batch_idx: 220 |  Loss: (0.1244) | Acc: (95.74%) (27084/28288)\n",
            "Epoch: 77 | Batch_idx: 230 |  Loss: (0.1241) | Acc: (95.76%) (28315/29568)\n",
            "Epoch: 77 | Batch_idx: 240 |  Loss: (0.1241) | Acc: (95.78%) (29546/30848)\n",
            "Epoch: 77 | Batch_idx: 250 |  Loss: (0.1247) | Acc: (95.77%) (30768/32128)\n",
            "Epoch: 77 | Batch_idx: 260 |  Loss: (0.1253) | Acc: (95.75%) (31987/33408)\n",
            "Epoch: 77 | Batch_idx: 270 |  Loss: (0.1254) | Acc: (95.70%) (33197/34688)\n",
            "Epoch: 77 | Batch_idx: 280 |  Loss: (0.1256) | Acc: (95.68%) (34415/35968)\n",
            "Epoch: 77 | Batch_idx: 290 |  Loss: (0.1263) | Acc: (95.68%) (35638/37248)\n",
            "Epoch: 77 | Batch_idx: 300 |  Loss: (0.1267) | Acc: (95.66%) (36854/38528)\n",
            "Epoch: 77 | Batch_idx: 310 |  Loss: (0.1276) | Acc: (95.62%) (38066/39808)\n",
            "Epoch: 77 | Batch_idx: 320 |  Loss: (0.1282) | Acc: (95.58%) (39270/41088)\n",
            "Epoch: 77 | Batch_idx: 330 |  Loss: (0.1291) | Acc: (95.54%) (40479/42368)\n",
            "Epoch: 77 | Batch_idx: 340 |  Loss: (0.1287) | Acc: (95.55%) (41707/43648)\n",
            "Epoch: 77 | Batch_idx: 350 |  Loss: (0.1294) | Acc: (95.52%) (42915/44928)\n",
            "Epoch: 77 | Batch_idx: 360 |  Loss: (0.1296) | Acc: (95.53%) (44142/46208)\n",
            "Epoch: 77 | Batch_idx: 370 |  Loss: (0.1301) | Acc: (95.51%) (45355/47488)\n",
            "Epoch: 77 | Batch_idx: 380 |  Loss: (0.1301) | Acc: (95.50%) (46574/48768)\n",
            "Epoch: 77 | Batch_idx: 390 |  Loss: (0.1302) | Acc: (95.49%) (47746/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3848) | Acc: (88.93%) (8893/10000)\n",
            "Epoch: 78 | Batch_idx: 0 |  Loss: (0.1395) | Acc: (96.09%) (123/128)\n",
            "Epoch: 78 | Batch_idx: 10 |  Loss: (0.1091) | Acc: (96.52%) (1359/1408)\n",
            "Epoch: 78 | Batch_idx: 20 |  Loss: (0.1190) | Acc: (95.91%) (2578/2688)\n",
            "Epoch: 78 | Batch_idx: 30 |  Loss: (0.1278) | Acc: (95.69%) (3797/3968)\n",
            "Epoch: 78 | Batch_idx: 40 |  Loss: (0.1234) | Acc: (95.83%) (5029/5248)\n",
            "Epoch: 78 | Batch_idx: 50 |  Loss: (0.1234) | Acc: (95.73%) (6249/6528)\n",
            "Epoch: 78 | Batch_idx: 60 |  Loss: (0.1205) | Acc: (95.77%) (7478/7808)\n",
            "Epoch: 78 | Batch_idx: 70 |  Loss: (0.1230) | Acc: (95.68%) (8695/9088)\n",
            "Epoch: 78 | Batch_idx: 80 |  Loss: (0.1201) | Acc: (95.81%) (9934/10368)\n",
            "Epoch: 78 | Batch_idx: 90 |  Loss: (0.1190) | Acc: (95.86%) (11166/11648)\n",
            "Epoch: 78 | Batch_idx: 100 |  Loss: (0.1185) | Acc: (95.83%) (12389/12928)\n",
            "Epoch: 78 | Batch_idx: 110 |  Loss: (0.1184) | Acc: (95.83%) (13616/14208)\n",
            "Epoch: 78 | Batch_idx: 120 |  Loss: (0.1192) | Acc: (95.80%) (14837/15488)\n",
            "Epoch: 78 | Batch_idx: 130 |  Loss: (0.1201) | Acc: (95.77%) (16058/16768)\n",
            "Epoch: 78 | Batch_idx: 140 |  Loss: (0.1221) | Acc: (95.66%) (17264/18048)\n",
            "Epoch: 78 | Batch_idx: 150 |  Loss: (0.1230) | Acc: (95.67%) (18491/19328)\n",
            "Epoch: 78 | Batch_idx: 160 |  Loss: (0.1226) | Acc: (95.68%) (19717/20608)\n",
            "Epoch: 78 | Batch_idx: 170 |  Loss: (0.1235) | Acc: (95.61%) (20928/21888)\n",
            "Epoch: 78 | Batch_idx: 180 |  Loss: (0.1228) | Acc: (95.64%) (22157/23168)\n",
            "Epoch: 78 | Batch_idx: 190 |  Loss: (0.1220) | Acc: (95.70%) (23396/24448)\n",
            "Epoch: 78 | Batch_idx: 200 |  Loss: (0.1210) | Acc: (95.72%) (24626/25728)\n",
            "Epoch: 78 | Batch_idx: 210 |  Loss: (0.1220) | Acc: (95.69%) (25843/27008)\n",
            "Epoch: 78 | Batch_idx: 220 |  Loss: (0.1220) | Acc: (95.70%) (27072/28288)\n",
            "Epoch: 78 | Batch_idx: 230 |  Loss: (0.1216) | Acc: (95.73%) (28305/29568)\n",
            "Epoch: 78 | Batch_idx: 240 |  Loss: (0.1227) | Acc: (95.69%) (29517/30848)\n",
            "Epoch: 78 | Batch_idx: 250 |  Loss: (0.1224) | Acc: (95.69%) (30743/32128)\n",
            "Epoch: 78 | Batch_idx: 260 |  Loss: (0.1231) | Acc: (95.67%) (31963/33408)\n",
            "Epoch: 78 | Batch_idx: 270 |  Loss: (0.1233) | Acc: (95.66%) (33182/34688)\n",
            "Epoch: 78 | Batch_idx: 280 |  Loss: (0.1231) | Acc: (95.67%) (34410/35968)\n",
            "Epoch: 78 | Batch_idx: 290 |  Loss: (0.1236) | Acc: (95.65%) (35629/37248)\n",
            "Epoch: 78 | Batch_idx: 300 |  Loss: (0.1234) | Acc: (95.65%) (36853/38528)\n",
            "Epoch: 78 | Batch_idx: 310 |  Loss: (0.1230) | Acc: (95.67%) (38083/39808)\n",
            "Epoch: 78 | Batch_idx: 320 |  Loss: (0.1230) | Acc: (95.66%) (39306/41088)\n",
            "Epoch: 78 | Batch_idx: 330 |  Loss: (0.1230) | Acc: (95.67%) (40532/42368)\n",
            "Epoch: 78 | Batch_idx: 340 |  Loss: (0.1234) | Acc: (95.67%) (41756/43648)\n",
            "Epoch: 78 | Batch_idx: 350 |  Loss: (0.1237) | Acc: (95.67%) (42983/44928)\n",
            "Epoch: 78 | Batch_idx: 360 |  Loss: (0.1243) | Acc: (95.64%) (44194/46208)\n",
            "Epoch: 78 | Batch_idx: 370 |  Loss: (0.1251) | Acc: (95.63%) (45414/47488)\n",
            "Epoch: 78 | Batch_idx: 380 |  Loss: (0.1253) | Acc: (95.62%) (46631/48768)\n",
            "Epoch: 78 | Batch_idx: 390 |  Loss: (0.1257) | Acc: (95.60%) (47800/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3895) | Acc: (89.35%) (8935/10000)\n",
            "Epoch: 79 | Batch_idx: 0 |  Loss: (0.1404) | Acc: (94.53%) (121/128)\n",
            "Epoch: 79 | Batch_idx: 10 |  Loss: (0.1176) | Acc: (96.16%) (1354/1408)\n",
            "Epoch: 79 | Batch_idx: 20 |  Loss: (0.1126) | Acc: (96.28%) (2588/2688)\n",
            "Epoch: 79 | Batch_idx: 30 |  Loss: (0.1203) | Acc: (95.87%) (3804/3968)\n",
            "Epoch: 79 | Batch_idx: 40 |  Loss: (0.1212) | Acc: (95.75%) (5025/5248)\n",
            "Epoch: 79 | Batch_idx: 50 |  Loss: (0.1249) | Acc: (95.50%) (6234/6528)\n",
            "Epoch: 79 | Batch_idx: 60 |  Loss: (0.1259) | Acc: (95.45%) (7453/7808)\n",
            "Epoch: 79 | Batch_idx: 70 |  Loss: (0.1252) | Acc: (95.44%) (8674/9088)\n",
            "Epoch: 79 | Batch_idx: 80 |  Loss: (0.1272) | Acc: (95.34%) (9885/10368)\n",
            "Epoch: 79 | Batch_idx: 90 |  Loss: (0.1264) | Acc: (95.31%) (11102/11648)\n",
            "Epoch: 79 | Batch_idx: 100 |  Loss: (0.1285) | Acc: (95.25%) (12314/12928)\n",
            "Epoch: 79 | Batch_idx: 110 |  Loss: (0.1285) | Acc: (95.26%) (13535/14208)\n",
            "Epoch: 79 | Batch_idx: 120 |  Loss: (0.1282) | Acc: (95.27%) (14756/15488)\n",
            "Epoch: 79 | Batch_idx: 130 |  Loss: (0.1284) | Acc: (95.26%) (15974/16768)\n",
            "Epoch: 79 | Batch_idx: 140 |  Loss: (0.1270) | Acc: (95.32%) (17204/18048)\n",
            "Epoch: 79 | Batch_idx: 150 |  Loss: (0.1268) | Acc: (95.34%) (18428/19328)\n",
            "Epoch: 79 | Batch_idx: 160 |  Loss: (0.1269) | Acc: (95.35%) (19650/20608)\n",
            "Epoch: 79 | Batch_idx: 170 |  Loss: (0.1255) | Acc: (95.40%) (20881/21888)\n",
            "Epoch: 79 | Batch_idx: 180 |  Loss: (0.1258) | Acc: (95.41%) (22104/23168)\n",
            "Epoch: 79 | Batch_idx: 190 |  Loss: (0.1252) | Acc: (95.43%) (23331/24448)\n",
            "Epoch: 79 | Batch_idx: 200 |  Loss: (0.1253) | Acc: (95.44%) (24554/25728)\n",
            "Epoch: 79 | Batch_idx: 210 |  Loss: (0.1248) | Acc: (95.45%) (25779/27008)\n",
            "Epoch: 79 | Batch_idx: 220 |  Loss: (0.1254) | Acc: (95.43%) (26994/28288)\n",
            "Epoch: 79 | Batch_idx: 230 |  Loss: (0.1260) | Acc: (95.42%) (28214/29568)\n",
            "Epoch: 79 | Batch_idx: 240 |  Loss: (0.1269) | Acc: (95.40%) (29429/30848)\n",
            "Epoch: 79 | Batch_idx: 250 |  Loss: (0.1270) | Acc: (95.39%) (30648/32128)\n",
            "Epoch: 79 | Batch_idx: 260 |  Loss: (0.1272) | Acc: (95.40%) (31871/33408)\n",
            "Epoch: 79 | Batch_idx: 270 |  Loss: (0.1267) | Acc: (95.41%) (33097/34688)\n",
            "Epoch: 79 | Batch_idx: 280 |  Loss: (0.1267) | Acc: (95.43%) (34325/35968)\n",
            "Epoch: 79 | Batch_idx: 290 |  Loss: (0.1275) | Acc: (95.41%) (35540/37248)\n",
            "Epoch: 79 | Batch_idx: 300 |  Loss: (0.1278) | Acc: (95.40%) (36757/38528)\n",
            "Epoch: 79 | Batch_idx: 310 |  Loss: (0.1288) | Acc: (95.37%) (37966/39808)\n",
            "Epoch: 79 | Batch_idx: 320 |  Loss: (0.1290) | Acc: (95.39%) (39192/41088)\n",
            "Epoch: 79 | Batch_idx: 330 |  Loss: (0.1295) | Acc: (95.38%) (40409/42368)\n",
            "Epoch: 79 | Batch_idx: 340 |  Loss: (0.1297) | Acc: (95.37%) (41625/43648)\n",
            "Epoch: 79 | Batch_idx: 350 |  Loss: (0.1304) | Acc: (95.34%) (42833/44928)\n",
            "Epoch: 79 | Batch_idx: 360 |  Loss: (0.1307) | Acc: (95.34%) (44055/46208)\n",
            "Epoch: 79 | Batch_idx: 370 |  Loss: (0.1317) | Acc: (95.30%) (45258/47488)\n",
            "Epoch: 79 | Batch_idx: 380 |  Loss: (0.1320) | Acc: (95.29%) (46469/48768)\n",
            "Epoch: 79 | Batch_idx: 390 |  Loss: (0.1329) | Acc: (95.26%) (47629/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3859) | Acc: (89.44%) (8944/10000)\n",
            "Epoch: 80 | Batch_idx: 0 |  Loss: (0.0875) | Acc: (96.88%) (124/128)\n",
            "Epoch: 80 | Batch_idx: 10 |  Loss: (0.1307) | Acc: (95.53%) (1345/1408)\n",
            "Epoch: 80 | Batch_idx: 20 |  Loss: (0.1232) | Acc: (95.87%) (2577/2688)\n",
            "Epoch: 80 | Batch_idx: 30 |  Loss: (0.1149) | Acc: (96.02%) (3810/3968)\n",
            "Epoch: 80 | Batch_idx: 40 |  Loss: (0.1109) | Acc: (96.21%) (5049/5248)\n",
            "Epoch: 80 | Batch_idx: 50 |  Loss: (0.1098) | Acc: (96.29%) (6286/6528)\n",
            "Epoch: 80 | Batch_idx: 60 |  Loss: (0.1067) | Acc: (96.45%) (7531/7808)\n",
            "Epoch: 80 | Batch_idx: 70 |  Loss: (0.1024) | Acc: (96.58%) (8777/9088)\n",
            "Epoch: 80 | Batch_idx: 80 |  Loss: (0.1007) | Acc: (96.62%) (10018/10368)\n",
            "Epoch: 80 | Batch_idx: 90 |  Loss: (0.0988) | Acc: (96.71%) (11265/11648)\n",
            "Epoch: 80 | Batch_idx: 100 |  Loss: (0.0974) | Acc: (96.79%) (12513/12928)\n",
            "Epoch: 80 | Batch_idx: 110 |  Loss: (0.0954) | Acc: (96.85%) (13761/14208)\n",
            "Epoch: 80 | Batch_idx: 120 |  Loss: (0.0941) | Acc: (96.94%) (15014/15488)\n",
            "Epoch: 80 | Batch_idx: 130 |  Loss: (0.0929) | Acc: (97.00%) (16265/16768)\n",
            "Epoch: 80 | Batch_idx: 140 |  Loss: (0.0921) | Acc: (97.04%) (17513/18048)\n",
            "Epoch: 80 | Batch_idx: 150 |  Loss: (0.0916) | Acc: (97.06%) (18759/19328)\n",
            "Epoch: 80 | Batch_idx: 160 |  Loss: (0.0925) | Acc: (96.98%) (19986/20608)\n",
            "Epoch: 80 | Batch_idx: 170 |  Loss: (0.0912) | Acc: (97.04%) (21240/21888)\n",
            "Epoch: 80 | Batch_idx: 180 |  Loss: (0.0898) | Acc: (97.09%) (22494/23168)\n",
            "Epoch: 80 | Batch_idx: 190 |  Loss: (0.0889) | Acc: (97.13%) (23747/24448)\n",
            "Epoch: 80 | Batch_idx: 200 |  Loss: (0.0876) | Acc: (97.19%) (25005/25728)\n",
            "Epoch: 80 | Batch_idx: 210 |  Loss: (0.0869) | Acc: (97.20%) (26252/27008)\n",
            "Epoch: 80 | Batch_idx: 220 |  Loss: (0.0863) | Acc: (97.22%) (27503/28288)\n",
            "Epoch: 80 | Batch_idx: 230 |  Loss: (0.0857) | Acc: (97.22%) (28747/29568)\n",
            "Epoch: 80 | Batch_idx: 240 |  Loss: (0.0850) | Acc: (97.25%) (30001/30848)\n",
            "Epoch: 80 | Batch_idx: 250 |  Loss: (0.0845) | Acc: (97.27%) (31251/32128)\n",
            "Epoch: 80 | Batch_idx: 260 |  Loss: (0.0842) | Acc: (97.29%) (32502/33408)\n",
            "Epoch: 80 | Batch_idx: 270 |  Loss: (0.0833) | Acc: (97.32%) (33759/34688)\n",
            "Epoch: 80 | Batch_idx: 280 |  Loss: (0.0830) | Acc: (97.33%) (35008/35968)\n",
            "Epoch: 80 | Batch_idx: 290 |  Loss: (0.0822) | Acc: (97.35%) (36260/37248)\n",
            "Epoch: 80 | Batch_idx: 300 |  Loss: (0.0815) | Acc: (97.38%) (37520/38528)\n",
            "Epoch: 80 | Batch_idx: 310 |  Loss: (0.0814) | Acc: (97.38%) (38766/39808)\n",
            "Epoch: 80 | Batch_idx: 320 |  Loss: (0.0808) | Acc: (97.40%) (40019/41088)\n",
            "Epoch: 80 | Batch_idx: 330 |  Loss: (0.0806) | Acc: (97.40%) (41267/42368)\n",
            "Epoch: 80 | Batch_idx: 340 |  Loss: (0.0797) | Acc: (97.43%) (42526/43648)\n",
            "Epoch: 80 | Batch_idx: 350 |  Loss: (0.0794) | Acc: (97.44%) (43778/44928)\n",
            "Epoch: 80 | Batch_idx: 360 |  Loss: (0.0792) | Acc: (97.45%) (45031/46208)\n",
            "Epoch: 80 | Batch_idx: 370 |  Loss: (0.0793) | Acc: (97.45%) (46277/47488)\n",
            "Epoch: 80 | Batch_idx: 380 |  Loss: (0.0783) | Acc: (97.48%) (47541/48768)\n",
            "Epoch: 80 | Batch_idx: 390 |  Loss: (0.0781) | Acc: (97.49%) (48745/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.2832) | Acc: (91.76%) (9176/10000)\n",
            "Epoch: 81 | Batch_idx: 0 |  Loss: (0.0520) | Acc: (99.22%) (127/128)\n",
            "Epoch: 81 | Batch_idx: 10 |  Loss: (0.0641) | Acc: (98.44%) (1386/1408)\n",
            "Epoch: 81 | Batch_idx: 20 |  Loss: (0.0610) | Acc: (98.36%) (2644/2688)\n",
            "Epoch: 81 | Batch_idx: 30 |  Loss: (0.0594) | Acc: (98.34%) (3902/3968)\n",
            "Epoch: 81 | Batch_idx: 40 |  Loss: (0.0610) | Acc: (98.23%) (5155/5248)\n",
            "Epoch: 81 | Batch_idx: 50 |  Loss: (0.0585) | Acc: (98.21%) (6411/6528)\n",
            "Epoch: 81 | Batch_idx: 60 |  Loss: (0.0598) | Acc: (98.17%) (7665/7808)\n",
            "Epoch: 81 | Batch_idx: 70 |  Loss: (0.0606) | Acc: (98.07%) (8913/9088)\n",
            "Epoch: 81 | Batch_idx: 80 |  Loss: (0.0589) | Acc: (98.16%) (10177/10368)\n",
            "Epoch: 81 | Batch_idx: 90 |  Loss: (0.0588) | Acc: (98.14%) (11431/11648)\n",
            "Epoch: 81 | Batch_idx: 100 |  Loss: (0.0593) | Acc: (98.09%) (12681/12928)\n",
            "Epoch: 81 | Batch_idx: 110 |  Loss: (0.0601) | Acc: (98.09%) (13936/14208)\n",
            "Epoch: 81 | Batch_idx: 120 |  Loss: (0.0605) | Acc: (98.04%) (15184/15488)\n",
            "Epoch: 81 | Batch_idx: 130 |  Loss: (0.0605) | Acc: (98.04%) (16439/16768)\n",
            "Epoch: 81 | Batch_idx: 140 |  Loss: (0.0610) | Acc: (98.03%) (17693/18048)\n",
            "Epoch: 81 | Batch_idx: 150 |  Loss: (0.0615) | Acc: (98.01%) (18943/19328)\n",
            "Epoch: 81 | Batch_idx: 160 |  Loss: (0.0601) | Acc: (98.08%) (20213/20608)\n",
            "Epoch: 81 | Batch_idx: 170 |  Loss: (0.0595) | Acc: (98.11%) (21474/21888)\n",
            "Epoch: 81 | Batch_idx: 180 |  Loss: (0.0590) | Acc: (98.12%) (22733/23168)\n",
            "Epoch: 81 | Batch_idx: 190 |  Loss: (0.0586) | Acc: (98.15%) (23995/24448)\n",
            "Epoch: 81 | Batch_idx: 200 |  Loss: (0.0588) | Acc: (98.13%) (25247/25728)\n",
            "Epoch: 81 | Batch_idx: 210 |  Loss: (0.0580) | Acc: (98.15%) (26509/27008)\n",
            "Epoch: 81 | Batch_idx: 220 |  Loss: (0.0579) | Acc: (98.18%) (27772/28288)\n",
            "Epoch: 81 | Batch_idx: 230 |  Loss: (0.0580) | Acc: (98.17%) (29027/29568)\n",
            "Epoch: 81 | Batch_idx: 240 |  Loss: (0.0582) | Acc: (98.15%) (30278/30848)\n",
            "Epoch: 81 | Batch_idx: 250 |  Loss: (0.0587) | Acc: (98.13%) (31527/32128)\n",
            "Epoch: 81 | Batch_idx: 260 |  Loss: (0.0584) | Acc: (98.15%) (32790/33408)\n",
            "Epoch: 81 | Batch_idx: 270 |  Loss: (0.0580) | Acc: (98.16%) (34051/34688)\n",
            "Epoch: 81 | Batch_idx: 280 |  Loss: (0.0578) | Acc: (98.18%) (35312/35968)\n",
            "Epoch: 81 | Batch_idx: 290 |  Loss: (0.0579) | Acc: (98.17%) (36566/37248)\n",
            "Epoch: 81 | Batch_idx: 300 |  Loss: (0.0578) | Acc: (98.18%) (37827/38528)\n",
            "Epoch: 81 | Batch_idx: 310 |  Loss: (0.0579) | Acc: (98.18%) (39082/39808)\n",
            "Epoch: 81 | Batch_idx: 320 |  Loss: (0.0580) | Acc: (98.16%) (40334/41088)\n",
            "Epoch: 81 | Batch_idx: 330 |  Loss: (0.0581) | Acc: (98.16%) (41590/42368)\n",
            "Epoch: 81 | Batch_idx: 340 |  Loss: (0.0577) | Acc: (98.18%) (42853/43648)\n",
            "Epoch: 81 | Batch_idx: 350 |  Loss: (0.0578) | Acc: (98.18%) (44110/44928)\n",
            "Epoch: 81 | Batch_idx: 360 |  Loss: (0.0573) | Acc: (98.20%) (45377/46208)\n",
            "Epoch: 81 | Batch_idx: 370 |  Loss: (0.0569) | Acc: (98.21%) (46639/47488)\n",
            "Epoch: 81 | Batch_idx: 380 |  Loss: (0.0572) | Acc: (98.21%) (47896/48768)\n",
            "Epoch: 81 | Batch_idx: 390 |  Loss: (0.0571) | Acc: (98.22%) (49108/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.2799) | Acc: (91.89%) (9189/10000)\n",
            "Epoch: 82 | Batch_idx: 0 |  Loss: (0.0726) | Acc: (98.44%) (126/128)\n",
            "Epoch: 82 | Batch_idx: 10 |  Loss: (0.0540) | Acc: (98.44%) (1386/1408)\n",
            "Epoch: 82 | Batch_idx: 20 |  Loss: (0.0504) | Acc: (98.47%) (2647/2688)\n",
            "Epoch: 82 | Batch_idx: 30 |  Loss: (0.0507) | Acc: (98.41%) (3905/3968)\n",
            "Epoch: 82 | Batch_idx: 40 |  Loss: (0.0492) | Acc: (98.46%) (5167/5248)\n",
            "Epoch: 82 | Batch_idx: 50 |  Loss: (0.0477) | Acc: (98.54%) (6433/6528)\n",
            "Epoch: 82 | Batch_idx: 60 |  Loss: (0.0464) | Acc: (98.57%) (7696/7808)\n",
            "Epoch: 82 | Batch_idx: 70 |  Loss: (0.0462) | Acc: (98.61%) (8962/9088)\n",
            "Epoch: 82 | Batch_idx: 80 |  Loss: (0.0471) | Acc: (98.57%) (10220/10368)\n",
            "Epoch: 82 | Batch_idx: 90 |  Loss: (0.0473) | Acc: (98.54%) (11478/11648)\n",
            "Epoch: 82 | Batch_idx: 100 |  Loss: (0.0471) | Acc: (98.58%) (12744/12928)\n",
            "Epoch: 82 | Batch_idx: 110 |  Loss: (0.0467) | Acc: (98.61%) (14011/14208)\n",
            "Epoch: 82 | Batch_idx: 120 |  Loss: (0.0471) | Acc: (98.57%) (15267/15488)\n",
            "Epoch: 82 | Batch_idx: 130 |  Loss: (0.0469) | Acc: (98.59%) (16531/16768)\n",
            "Epoch: 82 | Batch_idx: 140 |  Loss: (0.0473) | Acc: (98.59%) (17793/18048)\n",
            "Epoch: 82 | Batch_idx: 150 |  Loss: (0.0484) | Acc: (98.55%) (19048/19328)\n",
            "Epoch: 82 | Batch_idx: 160 |  Loss: (0.0486) | Acc: (98.54%) (20307/20608)\n",
            "Epoch: 82 | Batch_idx: 170 |  Loss: (0.0483) | Acc: (98.53%) (21567/21888)\n",
            "Epoch: 82 | Batch_idx: 180 |  Loss: (0.0488) | Acc: (98.51%) (22822/23168)\n",
            "Epoch: 82 | Batch_idx: 190 |  Loss: (0.0493) | Acc: (98.49%) (24079/24448)\n",
            "Epoch: 82 | Batch_idx: 200 |  Loss: (0.0496) | Acc: (98.48%) (25336/25728)\n",
            "Epoch: 82 | Batch_idx: 210 |  Loss: (0.0501) | Acc: (98.44%) (26587/27008)\n",
            "Epoch: 82 | Batch_idx: 220 |  Loss: (0.0502) | Acc: (98.44%) (27848/28288)\n",
            "Epoch: 82 | Batch_idx: 230 |  Loss: (0.0502) | Acc: (98.45%) (29111/29568)\n",
            "Epoch: 82 | Batch_idx: 240 |  Loss: (0.0508) | Acc: (98.44%) (30366/30848)\n",
            "Epoch: 82 | Batch_idx: 250 |  Loss: (0.0507) | Acc: (98.43%) (31622/32128)\n",
            "Epoch: 82 | Batch_idx: 260 |  Loss: (0.0504) | Acc: (98.44%) (32888/33408)\n",
            "Epoch: 82 | Batch_idx: 270 |  Loss: (0.0506) | Acc: (98.43%) (34144/34688)\n",
            "Epoch: 82 | Batch_idx: 280 |  Loss: (0.0503) | Acc: (98.44%) (35408/35968)\n",
            "Epoch: 82 | Batch_idx: 290 |  Loss: (0.0504) | Acc: (98.42%) (36661/37248)\n",
            "Epoch: 82 | Batch_idx: 300 |  Loss: (0.0503) | Acc: (98.41%) (37916/38528)\n",
            "Epoch: 82 | Batch_idx: 310 |  Loss: (0.0504) | Acc: (98.41%) (39175/39808)\n",
            "Epoch: 82 | Batch_idx: 320 |  Loss: (0.0502) | Acc: (98.42%) (40440/41088)\n",
            "Epoch: 82 | Batch_idx: 330 |  Loss: (0.0502) | Acc: (98.42%) (41700/42368)\n",
            "Epoch: 82 | Batch_idx: 340 |  Loss: (0.0499) | Acc: (98.43%) (42964/43648)\n",
            "Epoch: 82 | Batch_idx: 350 |  Loss: (0.0498) | Acc: (98.44%) (44225/44928)\n",
            "Epoch: 82 | Batch_idx: 360 |  Loss: (0.0500) | Acc: (98.43%) (45482/46208)\n",
            "Epoch: 82 | Batch_idx: 370 |  Loss: (0.0497) | Acc: (98.45%) (46750/47488)\n",
            "Epoch: 82 | Batch_idx: 380 |  Loss: (0.0497) | Acc: (98.44%) (48006/48768)\n",
            "Epoch: 82 | Batch_idx: 390 |  Loss: (0.0498) | Acc: (98.44%) (49218/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.2796) | Acc: (91.91%) (9191/10000)\n",
            "Epoch: 83 | Batch_idx: 0 |  Loss: (0.0279) | Acc: (100.00%) (128/128)\n",
            "Epoch: 83 | Batch_idx: 10 |  Loss: (0.0395) | Acc: (98.58%) (1388/1408)\n",
            "Epoch: 83 | Batch_idx: 20 |  Loss: (0.0368) | Acc: (98.85%) (2657/2688)\n",
            "Epoch: 83 | Batch_idx: 30 |  Loss: (0.0378) | Acc: (98.71%) (3917/3968)\n",
            "Epoch: 83 | Batch_idx: 40 |  Loss: (0.0384) | Acc: (98.72%) (5181/5248)\n",
            "Epoch: 83 | Batch_idx: 50 |  Loss: (0.0407) | Acc: (98.62%) (6438/6528)\n",
            "Epoch: 83 | Batch_idx: 60 |  Loss: (0.0407) | Acc: (98.66%) (7703/7808)\n",
            "Epoch: 83 | Batch_idx: 70 |  Loss: (0.0407) | Acc: (98.67%) (8967/9088)\n",
            "Epoch: 83 | Batch_idx: 80 |  Loss: (0.0404) | Acc: (98.70%) (10233/10368)\n",
            "Epoch: 83 | Batch_idx: 90 |  Loss: (0.0411) | Acc: (98.66%) (11492/11648)\n",
            "Epoch: 83 | Batch_idx: 100 |  Loss: (0.0425) | Acc: (98.63%) (12751/12928)\n",
            "Epoch: 83 | Batch_idx: 110 |  Loss: (0.0424) | Acc: (98.65%) (14016/14208)\n",
            "Epoch: 83 | Batch_idx: 120 |  Loss: (0.0425) | Acc: (98.65%) (15279/15488)\n",
            "Epoch: 83 | Batch_idx: 130 |  Loss: (0.0425) | Acc: (98.68%) (16547/16768)\n",
            "Epoch: 83 | Batch_idx: 140 |  Loss: (0.0428) | Acc: (98.69%) (17812/18048)\n",
            "Epoch: 83 | Batch_idx: 150 |  Loss: (0.0432) | Acc: (98.68%) (19072/19328)\n",
            "Epoch: 83 | Batch_idx: 160 |  Loss: (0.0434) | Acc: (98.66%) (20332/20608)\n",
            "Epoch: 83 | Batch_idx: 170 |  Loss: (0.0439) | Acc: (98.66%) (21595/21888)\n",
            "Epoch: 83 | Batch_idx: 180 |  Loss: (0.0434) | Acc: (98.69%) (22865/23168)\n",
            "Epoch: 83 | Batch_idx: 190 |  Loss: (0.0433) | Acc: (98.69%) (24128/24448)\n",
            "Epoch: 83 | Batch_idx: 200 |  Loss: (0.0436) | Acc: (98.66%) (25384/25728)\n",
            "Epoch: 83 | Batch_idx: 210 |  Loss: (0.0435) | Acc: (98.67%) (26650/27008)\n",
            "Epoch: 83 | Batch_idx: 220 |  Loss: (0.0432) | Acc: (98.69%) (27917/28288)\n",
            "Epoch: 83 | Batch_idx: 230 |  Loss: (0.0435) | Acc: (98.67%) (29176/29568)\n",
            "Epoch: 83 | Batch_idx: 240 |  Loss: (0.0437) | Acc: (98.66%) (30434/30848)\n",
            "Epoch: 83 | Batch_idx: 250 |  Loss: (0.0440) | Acc: (98.64%) (31692/32128)\n",
            "Epoch: 83 | Batch_idx: 260 |  Loss: (0.0436) | Acc: (98.66%) (32960/33408)\n",
            "Epoch: 83 | Batch_idx: 270 |  Loss: (0.0438) | Acc: (98.66%) (34223/34688)\n",
            "Epoch: 83 | Batch_idx: 280 |  Loss: (0.0439) | Acc: (98.65%) (35483/35968)\n",
            "Epoch: 83 | Batch_idx: 290 |  Loss: (0.0437) | Acc: (98.65%) (36747/37248)\n",
            "Epoch: 83 | Batch_idx: 300 |  Loss: (0.0435) | Acc: (98.66%) (38013/38528)\n",
            "Epoch: 83 | Batch_idx: 310 |  Loss: (0.0438) | Acc: (98.66%) (39274/39808)\n",
            "Epoch: 83 | Batch_idx: 320 |  Loss: (0.0439) | Acc: (98.66%) (40537/41088)\n",
            "Epoch: 83 | Batch_idx: 330 |  Loss: (0.0437) | Acc: (98.67%) (41804/42368)\n",
            "Epoch: 83 | Batch_idx: 340 |  Loss: (0.0436) | Acc: (98.67%) (43067/43648)\n",
            "Epoch: 83 | Batch_idx: 350 |  Loss: (0.0434) | Acc: (98.68%) (44334/44928)\n",
            "Epoch: 83 | Batch_idx: 360 |  Loss: (0.0435) | Acc: (98.67%) (45592/46208)\n",
            "Epoch: 83 | Batch_idx: 370 |  Loss: (0.0435) | Acc: (98.67%) (46857/47488)\n",
            "Epoch: 83 | Batch_idx: 380 |  Loss: (0.0436) | Acc: (98.67%) (48118/48768)\n",
            "Epoch: 83 | Batch_idx: 390 |  Loss: (0.0436) | Acc: (98.66%) (49329/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.2812) | Acc: (92.17%) (9217/10000)\n",
            "Epoch: 84 | Batch_idx: 0 |  Loss: (0.0258) | Acc: (99.22%) (127/128)\n",
            "Epoch: 84 | Batch_idx: 10 |  Loss: (0.0389) | Acc: (98.93%) (1393/1408)\n",
            "Epoch: 84 | Batch_idx: 20 |  Loss: (0.0397) | Acc: (98.81%) (2656/2688)\n",
            "Epoch: 84 | Batch_idx: 30 |  Loss: (0.0383) | Acc: (98.77%) (3919/3968)\n",
            "Epoch: 84 | Batch_idx: 40 |  Loss: (0.0391) | Acc: (98.78%) (5184/5248)\n",
            "Epoch: 84 | Batch_idx: 50 |  Loss: (0.0400) | Acc: (98.74%) (6446/6528)\n",
            "Epoch: 84 | Batch_idx: 60 |  Loss: (0.0404) | Acc: (98.67%) (7704/7808)\n",
            "Epoch: 84 | Batch_idx: 70 |  Loss: (0.0396) | Acc: (98.72%) (8972/9088)\n",
            "Epoch: 84 | Batch_idx: 80 |  Loss: (0.0401) | Acc: (98.71%) (10234/10368)\n",
            "Epoch: 84 | Batch_idx: 90 |  Loss: (0.0396) | Acc: (98.76%) (11504/11648)\n",
            "Epoch: 84 | Batch_idx: 100 |  Loss: (0.0397) | Acc: (98.77%) (12769/12928)\n",
            "Epoch: 84 | Batch_idx: 110 |  Loss: (0.0395) | Acc: (98.79%) (14036/14208)\n",
            "Epoch: 84 | Batch_idx: 120 |  Loss: (0.0394) | Acc: (98.79%) (15300/15488)\n",
            "Epoch: 84 | Batch_idx: 130 |  Loss: (0.0389) | Acc: (98.81%) (16569/16768)\n",
            "Epoch: 84 | Batch_idx: 140 |  Loss: (0.0386) | Acc: (98.83%) (17836/18048)\n",
            "Epoch: 84 | Batch_idx: 150 |  Loss: (0.0382) | Acc: (98.85%) (19106/19328)\n",
            "Epoch: 84 | Batch_idx: 160 |  Loss: (0.0380) | Acc: (98.87%) (20375/20608)\n",
            "Epoch: 84 | Batch_idx: 170 |  Loss: (0.0385) | Acc: (98.83%) (21632/21888)\n",
            "Epoch: 84 | Batch_idx: 180 |  Loss: (0.0379) | Acc: (98.85%) (22902/23168)\n",
            "Epoch: 84 | Batch_idx: 190 |  Loss: (0.0379) | Acc: (98.86%) (24169/24448)\n",
            "Epoch: 84 | Batch_idx: 200 |  Loss: (0.0376) | Acc: (98.88%) (25439/25728)\n",
            "Epoch: 84 | Batch_idx: 210 |  Loss: (0.0381) | Acc: (98.84%) (26696/27008)\n",
            "Epoch: 84 | Batch_idx: 220 |  Loss: (0.0387) | Acc: (98.81%) (27950/28288)\n",
            "Epoch: 84 | Batch_idx: 230 |  Loss: (0.0388) | Acc: (98.80%) (29214/29568)\n",
            "Epoch: 84 | Batch_idx: 240 |  Loss: (0.0388) | Acc: (98.78%) (30473/30848)\n",
            "Epoch: 84 | Batch_idx: 250 |  Loss: (0.0389) | Acc: (98.78%) (31735/32128)\n",
            "Epoch: 84 | Batch_idx: 260 |  Loss: (0.0391) | Acc: (98.76%) (32994/33408)\n",
            "Epoch: 84 | Batch_idx: 270 |  Loss: (0.0394) | Acc: (98.75%) (34255/34688)\n",
            "Epoch: 84 | Batch_idx: 280 |  Loss: (0.0390) | Acc: (98.77%) (35524/35968)\n",
            "Epoch: 84 | Batch_idx: 290 |  Loss: (0.0392) | Acc: (98.75%) (36783/37248)\n",
            "Epoch: 84 | Batch_idx: 300 |  Loss: (0.0389) | Acc: (98.77%) (38054/38528)\n",
            "Epoch: 84 | Batch_idx: 310 |  Loss: (0.0391) | Acc: (98.77%) (39317/39808)\n",
            "Epoch: 84 | Batch_idx: 320 |  Loss: (0.0391) | Acc: (98.77%) (40581/41088)\n",
            "Epoch: 84 | Batch_idx: 330 |  Loss: (0.0388) | Acc: (98.78%) (41850/42368)\n",
            "Epoch: 84 | Batch_idx: 340 |  Loss: (0.0388) | Acc: (98.78%) (43116/43648)\n",
            "Epoch: 84 | Batch_idx: 350 |  Loss: (0.0389) | Acc: (98.79%) (44384/44928)\n",
            "Epoch: 84 | Batch_idx: 360 |  Loss: (0.0386) | Acc: (98.80%) (45653/46208)\n",
            "Epoch: 84 | Batch_idx: 370 |  Loss: (0.0384) | Acc: (98.81%) (46921/47488)\n",
            "Epoch: 84 | Batch_idx: 380 |  Loss: (0.0382) | Acc: (98.81%) (48189/48768)\n",
            "Epoch: 84 | Batch_idx: 390 |  Loss: (0.0379) | Acc: (98.83%) (49413/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.2838) | Acc: (92.23%) (9223/10000)\n",
            "Epoch: 85 | Batch_idx: 0 |  Loss: (0.0183) | Acc: (100.00%) (128/128)\n",
            "Epoch: 85 | Batch_idx: 10 |  Loss: (0.0352) | Acc: (98.93%) (1393/1408)\n",
            "Epoch: 85 | Batch_idx: 20 |  Loss: (0.0373) | Acc: (99.07%) (2663/2688)\n",
            "Epoch: 85 | Batch_idx: 30 |  Loss: (0.0347) | Acc: (99.14%) (3934/3968)\n",
            "Epoch: 85 | Batch_idx: 40 |  Loss: (0.0332) | Acc: (99.07%) (5199/5248)\n",
            "Epoch: 85 | Batch_idx: 50 |  Loss: (0.0314) | Acc: (99.14%) (6472/6528)\n",
            "Epoch: 85 | Batch_idx: 60 |  Loss: (0.0312) | Acc: (99.19%) (7745/7808)\n",
            "Epoch: 85 | Batch_idx: 70 |  Loss: (0.0310) | Acc: (99.19%) (9014/9088)\n",
            "Epoch: 85 | Batch_idx: 80 |  Loss: (0.0323) | Acc: (99.12%) (10277/10368)\n",
            "Epoch: 85 | Batch_idx: 90 |  Loss: (0.0328) | Acc: (99.10%) (11543/11648)\n",
            "Epoch: 85 | Batch_idx: 100 |  Loss: (0.0325) | Acc: (99.06%) (12807/12928)\n",
            "Epoch: 85 | Batch_idx: 110 |  Loss: (0.0332) | Acc: (99.06%) (14074/14208)\n",
            "Epoch: 85 | Batch_idx: 120 |  Loss: (0.0324) | Acc: (99.09%) (15347/15488)\n",
            "Epoch: 85 | Batch_idx: 130 |  Loss: (0.0322) | Acc: (99.08%) (16614/16768)\n",
            "Epoch: 85 | Batch_idx: 140 |  Loss: (0.0328) | Acc: (99.07%) (17881/18048)\n",
            "Epoch: 85 | Batch_idx: 150 |  Loss: (0.0328) | Acc: (99.06%) (19146/19328)\n",
            "Epoch: 85 | Batch_idx: 160 |  Loss: (0.0326) | Acc: (99.05%) (20413/20608)\n",
            "Epoch: 85 | Batch_idx: 170 |  Loss: (0.0326) | Acc: (99.07%) (21684/21888)\n",
            "Epoch: 85 | Batch_idx: 180 |  Loss: (0.0325) | Acc: (99.08%) (22956/23168)\n",
            "Epoch: 85 | Batch_idx: 190 |  Loss: (0.0328) | Acc: (99.07%) (24221/24448)\n",
            "Epoch: 85 | Batch_idx: 200 |  Loss: (0.0332) | Acc: (99.06%) (25487/25728)\n",
            "Epoch: 85 | Batch_idx: 210 |  Loss: (0.0330) | Acc: (99.07%) (26756/27008)\n",
            "Epoch: 85 | Batch_idx: 220 |  Loss: (0.0333) | Acc: (99.04%) (28016/28288)\n",
            "Epoch: 85 | Batch_idx: 230 |  Loss: (0.0337) | Acc: (99.03%) (29281/29568)\n",
            "Epoch: 85 | Batch_idx: 240 |  Loss: (0.0335) | Acc: (99.04%) (30551/30848)\n",
            "Epoch: 85 | Batch_idx: 250 |  Loss: (0.0337) | Acc: (99.03%) (31815/32128)\n",
            "Epoch: 85 | Batch_idx: 260 |  Loss: (0.0336) | Acc: (99.03%) (33085/33408)\n",
            "Epoch: 85 | Batch_idx: 270 |  Loss: (0.0335) | Acc: (99.04%) (34354/34688)\n",
            "Epoch: 85 | Batch_idx: 280 |  Loss: (0.0336) | Acc: (99.04%) (35621/35968)\n",
            "Epoch: 85 | Batch_idx: 290 |  Loss: (0.0334) | Acc: (99.04%) (36890/37248)\n",
            "Epoch: 85 | Batch_idx: 300 |  Loss: (0.0333) | Acc: (99.04%) (38157/38528)\n",
            "Epoch: 85 | Batch_idx: 310 |  Loss: (0.0332) | Acc: (99.04%) (39425/39808)\n",
            "Epoch: 85 | Batch_idx: 320 |  Loss: (0.0335) | Acc: (99.02%) (40685/41088)\n",
            "Epoch: 85 | Batch_idx: 330 |  Loss: (0.0335) | Acc: (99.02%) (41952/42368)\n",
            "Epoch: 85 | Batch_idx: 340 |  Loss: (0.0336) | Acc: (99.01%) (43217/43648)\n",
            "Epoch: 85 | Batch_idx: 350 |  Loss: (0.0336) | Acc: (99.02%) (44486/44928)\n",
            "Epoch: 85 | Batch_idx: 360 |  Loss: (0.0336) | Acc: (99.01%) (45752/46208)\n",
            "Epoch: 85 | Batch_idx: 370 |  Loss: (0.0337) | Acc: (99.01%) (47017/47488)\n",
            "Epoch: 85 | Batch_idx: 380 |  Loss: (0.0340) | Acc: (99.00%) (48281/48768)\n",
            "Epoch: 85 | Batch_idx: 390 |  Loss: (0.0339) | Acc: (99.01%) (49503/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.2841) | Acc: (92.28%) (9228/10000)\n",
            "Epoch: 86 | Batch_idx: 0 |  Loss: (0.0133) | Acc: (100.00%) (128/128)\n",
            "Epoch: 86 | Batch_idx: 10 |  Loss: (0.0303) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 86 | Batch_idx: 20 |  Loss: (0.0318) | Acc: (99.03%) (2662/2688)\n",
            "Epoch: 86 | Batch_idx: 30 |  Loss: (0.0312) | Acc: (99.02%) (3929/3968)\n",
            "Epoch: 86 | Batch_idx: 40 |  Loss: (0.0314) | Acc: (99.01%) (5196/5248)\n",
            "Epoch: 86 | Batch_idx: 50 |  Loss: (0.0313) | Acc: (99.02%) (6464/6528)\n",
            "Epoch: 86 | Batch_idx: 60 |  Loss: (0.0315) | Acc: (98.99%) (7729/7808)\n",
            "Epoch: 86 | Batch_idx: 70 |  Loss: (0.0313) | Acc: (99.01%) (8998/9088)\n",
            "Epoch: 86 | Batch_idx: 80 |  Loss: (0.0320) | Acc: (98.98%) (10262/10368)\n",
            "Epoch: 86 | Batch_idx: 90 |  Loss: (0.0325) | Acc: (98.96%) (11527/11648)\n",
            "Epoch: 86 | Batch_idx: 100 |  Loss: (0.0324) | Acc: (98.95%) (12792/12928)\n",
            "Epoch: 86 | Batch_idx: 110 |  Loss: (0.0329) | Acc: (98.95%) (14059/14208)\n",
            "Epoch: 86 | Batch_idx: 120 |  Loss: (0.0337) | Acc: (98.92%) (15320/15488)\n",
            "Epoch: 86 | Batch_idx: 130 |  Loss: (0.0332) | Acc: (98.94%) (16590/16768)\n",
            "Epoch: 86 | Batch_idx: 140 |  Loss: (0.0327) | Acc: (98.96%) (17861/18048)\n",
            "Epoch: 86 | Batch_idx: 150 |  Loss: (0.0321) | Acc: (99.00%) (19134/19328)\n",
            "Epoch: 86 | Batch_idx: 160 |  Loss: (0.0319) | Acc: (99.02%) (20407/20608)\n",
            "Epoch: 86 | Batch_idx: 170 |  Loss: (0.0319) | Acc: (99.04%) (21678/21888)\n",
            "Epoch: 86 | Batch_idx: 180 |  Loss: (0.0319) | Acc: (99.02%) (22942/23168)\n",
            "Epoch: 86 | Batch_idx: 190 |  Loss: (0.0318) | Acc: (99.03%) (24212/24448)\n",
            "Epoch: 86 | Batch_idx: 200 |  Loss: (0.0320) | Acc: (99.02%) (25475/25728)\n",
            "Epoch: 86 | Batch_idx: 210 |  Loss: (0.0317) | Acc: (99.03%) (26745/27008)\n",
            "Epoch: 86 | Batch_idx: 220 |  Loss: (0.0317) | Acc: (99.03%) (28015/28288)\n",
            "Epoch: 86 | Batch_idx: 230 |  Loss: (0.0315) | Acc: (99.03%) (29280/29568)\n",
            "Epoch: 86 | Batch_idx: 240 |  Loss: (0.0312) | Acc: (99.06%) (30558/30848)\n",
            "Epoch: 86 | Batch_idx: 250 |  Loss: (0.0311) | Acc: (99.05%) (31823/32128)\n",
            "Epoch: 86 | Batch_idx: 260 |  Loss: (0.0311) | Acc: (99.06%) (33093/33408)\n",
            "Epoch: 86 | Batch_idx: 270 |  Loss: (0.0313) | Acc: (99.05%) (34360/34688)\n",
            "Epoch: 86 | Batch_idx: 280 |  Loss: (0.0314) | Acc: (99.05%) (35627/35968)\n",
            "Epoch: 86 | Batch_idx: 290 |  Loss: (0.0313) | Acc: (99.06%) (36898/37248)\n",
            "Epoch: 86 | Batch_idx: 300 |  Loss: (0.0313) | Acc: (99.06%) (38165/38528)\n",
            "Epoch: 86 | Batch_idx: 310 |  Loss: (0.0314) | Acc: (99.05%) (39429/39808)\n",
            "Epoch: 86 | Batch_idx: 320 |  Loss: (0.0317) | Acc: (99.04%) (40695/41088)\n",
            "Epoch: 86 | Batch_idx: 330 |  Loss: (0.0315) | Acc: (99.05%) (41967/42368)\n",
            "Epoch: 86 | Batch_idx: 340 |  Loss: (0.0316) | Acc: (99.05%) (43232/43648)\n",
            "Epoch: 86 | Batch_idx: 350 |  Loss: (0.0316) | Acc: (99.05%) (44500/44928)\n",
            "Epoch: 86 | Batch_idx: 360 |  Loss: (0.0316) | Acc: (99.06%) (45772/46208)\n",
            "Epoch: 86 | Batch_idx: 370 |  Loss: (0.0316) | Acc: (99.06%) (47041/47488)\n",
            "Epoch: 86 | Batch_idx: 380 |  Loss: (0.0316) | Acc: (99.06%) (48309/48768)\n",
            "Epoch: 86 | Batch_idx: 390 |  Loss: (0.0318) | Acc: (99.05%) (49523/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.2886) | Acc: (92.34%) (9234/10000)\n",
            "Epoch: 87 | Batch_idx: 0 |  Loss: (0.0542) | Acc: (97.66%) (125/128)\n",
            "Epoch: 87 | Batch_idx: 10 |  Loss: (0.0375) | Acc: (98.79%) (1391/1408)\n",
            "Epoch: 87 | Batch_idx: 20 |  Loss: (0.0330) | Acc: (99.00%) (2661/2688)\n",
            "Epoch: 87 | Batch_idx: 30 |  Loss: (0.0354) | Acc: (98.94%) (3926/3968)\n",
            "Epoch: 87 | Batch_idx: 40 |  Loss: (0.0323) | Acc: (99.09%) (5200/5248)\n",
            "Epoch: 87 | Batch_idx: 50 |  Loss: (0.0297) | Acc: (99.19%) (6475/6528)\n",
            "Epoch: 87 | Batch_idx: 60 |  Loss: (0.0308) | Acc: (99.14%) (7741/7808)\n",
            "Epoch: 87 | Batch_idx: 70 |  Loss: (0.0300) | Acc: (99.16%) (9012/9088)\n",
            "Epoch: 87 | Batch_idx: 80 |  Loss: (0.0300) | Acc: (99.14%) (10279/10368)\n",
            "Epoch: 87 | Batch_idx: 90 |  Loss: (0.0302) | Acc: (99.12%) (11545/11648)\n",
            "Epoch: 87 | Batch_idx: 100 |  Loss: (0.0303) | Acc: (99.13%) (12816/12928)\n",
            "Epoch: 87 | Batch_idx: 110 |  Loss: (0.0296) | Acc: (99.18%) (14092/14208)\n",
            "Epoch: 87 | Batch_idx: 120 |  Loss: (0.0297) | Acc: (99.18%) (15361/15488)\n",
            "Epoch: 87 | Batch_idx: 130 |  Loss: (0.0300) | Acc: (99.15%) (16625/16768)\n",
            "Epoch: 87 | Batch_idx: 140 |  Loss: (0.0310) | Acc: (99.10%) (17886/18048)\n",
            "Epoch: 87 | Batch_idx: 150 |  Loss: (0.0312) | Acc: (99.08%) (19151/19328)\n",
            "Epoch: 87 | Batch_idx: 160 |  Loss: (0.0313) | Acc: (99.07%) (20417/20608)\n",
            "Epoch: 87 | Batch_idx: 170 |  Loss: (0.0308) | Acc: (99.10%) (21690/21888)\n",
            "Epoch: 87 | Batch_idx: 180 |  Loss: (0.0305) | Acc: (99.10%) (22959/23168)\n",
            "Epoch: 87 | Batch_idx: 190 |  Loss: (0.0307) | Acc: (99.09%) (24225/24448)\n",
            "Epoch: 87 | Batch_idx: 200 |  Loss: (0.0306) | Acc: (99.09%) (25493/25728)\n",
            "Epoch: 87 | Batch_idx: 210 |  Loss: (0.0306) | Acc: (99.08%) (26760/27008)\n",
            "Epoch: 87 | Batch_idx: 220 |  Loss: (0.0304) | Acc: (99.08%) (28029/28288)\n",
            "Epoch: 87 | Batch_idx: 230 |  Loss: (0.0304) | Acc: (99.09%) (29298/29568)\n",
            "Epoch: 87 | Batch_idx: 240 |  Loss: (0.0305) | Acc: (99.07%) (30562/30848)\n",
            "Epoch: 87 | Batch_idx: 250 |  Loss: (0.0306) | Acc: (99.08%) (31831/32128)\n",
            "Epoch: 87 | Batch_idx: 260 |  Loss: (0.0305) | Acc: (99.08%) (33101/33408)\n",
            "Epoch: 87 | Batch_idx: 270 |  Loss: (0.0306) | Acc: (99.07%) (34366/34688)\n",
            "Epoch: 87 | Batch_idx: 280 |  Loss: (0.0305) | Acc: (99.08%) (35636/35968)\n",
            "Epoch: 87 | Batch_idx: 290 |  Loss: (0.0303) | Acc: (99.08%) (36907/37248)\n",
            "Epoch: 87 | Batch_idx: 300 |  Loss: (0.0301) | Acc: (99.10%) (38180/38528)\n",
            "Epoch: 87 | Batch_idx: 310 |  Loss: (0.0299) | Acc: (99.11%) (39455/39808)\n",
            "Epoch: 87 | Batch_idx: 320 |  Loss: (0.0298) | Acc: (99.12%) (40725/41088)\n",
            "Epoch: 87 | Batch_idx: 330 |  Loss: (0.0296) | Acc: (99.13%) (41999/42368)\n",
            "Epoch: 87 | Batch_idx: 340 |  Loss: (0.0296) | Acc: (99.13%) (43269/43648)\n",
            "Epoch: 87 | Batch_idx: 350 |  Loss: (0.0294) | Acc: (99.14%) (44542/44928)\n",
            "Epoch: 87 | Batch_idx: 360 |  Loss: (0.0295) | Acc: (99.14%) (45811/46208)\n",
            "Epoch: 87 | Batch_idx: 370 |  Loss: (0.0296) | Acc: (99.13%) (47075/47488)\n",
            "Epoch: 87 | Batch_idx: 380 |  Loss: (0.0296) | Acc: (99.13%) (48345/48768)\n",
            "Epoch: 87 | Batch_idx: 390 |  Loss: (0.0295) | Acc: (99.13%) (49567/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.2952) | Acc: (92.27%) (9227/10000)\n",
            "Epoch: 88 | Batch_idx: 0 |  Loss: (0.0097) | Acc: (100.00%) (128/128)\n",
            "Epoch: 88 | Batch_idx: 10 |  Loss: (0.0231) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 88 | Batch_idx: 20 |  Loss: (0.0220) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 88 | Batch_idx: 30 |  Loss: (0.0231) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 88 | Batch_idx: 40 |  Loss: (0.0255) | Acc: (99.37%) (5215/5248)\n",
            "Epoch: 88 | Batch_idx: 50 |  Loss: (0.0266) | Acc: (99.33%) (6484/6528)\n",
            "Epoch: 88 | Batch_idx: 60 |  Loss: (0.0254) | Acc: (99.40%) (7761/7808)\n",
            "Epoch: 88 | Batch_idx: 70 |  Loss: (0.0253) | Acc: (99.37%) (9031/9088)\n",
            "Epoch: 88 | Batch_idx: 80 |  Loss: (0.0247) | Acc: (99.37%) (10303/10368)\n",
            "Epoch: 88 | Batch_idx: 90 |  Loss: (0.0245) | Acc: (99.39%) (11577/11648)\n",
            "Epoch: 88 | Batch_idx: 100 |  Loss: (0.0241) | Acc: (99.40%) (12850/12928)\n",
            "Epoch: 88 | Batch_idx: 110 |  Loss: (0.0240) | Acc: (99.39%) (14122/14208)\n",
            "Epoch: 88 | Batch_idx: 120 |  Loss: (0.0250) | Acc: (99.36%) (15389/15488)\n",
            "Epoch: 88 | Batch_idx: 130 |  Loss: (0.0253) | Acc: (99.33%) (16656/16768)\n",
            "Epoch: 88 | Batch_idx: 140 |  Loss: (0.0250) | Acc: (99.34%) (17929/18048)\n",
            "Epoch: 88 | Batch_idx: 150 |  Loss: (0.0251) | Acc: (99.33%) (19199/19328)\n",
            "Epoch: 88 | Batch_idx: 160 |  Loss: (0.0252) | Acc: (99.33%) (20470/20608)\n",
            "Epoch: 88 | Batch_idx: 170 |  Loss: (0.0251) | Acc: (99.33%) (21742/21888)\n",
            "Epoch: 88 | Batch_idx: 180 |  Loss: (0.0254) | Acc: (99.31%) (23007/23168)\n",
            "Epoch: 88 | Batch_idx: 190 |  Loss: (0.0253) | Acc: (99.32%) (24281/24448)\n",
            "Epoch: 88 | Batch_idx: 200 |  Loss: (0.0256) | Acc: (99.30%) (25549/25728)\n",
            "Epoch: 88 | Batch_idx: 210 |  Loss: (0.0258) | Acc: (99.31%) (26821/27008)\n",
            "Epoch: 88 | Batch_idx: 220 |  Loss: (0.0257) | Acc: (99.30%) (28091/28288)\n",
            "Epoch: 88 | Batch_idx: 230 |  Loss: (0.0255) | Acc: (99.32%) (29367/29568)\n",
            "Epoch: 88 | Batch_idx: 240 |  Loss: (0.0255) | Acc: (99.32%) (30639/30848)\n",
            "Epoch: 88 | Batch_idx: 250 |  Loss: (0.0257) | Acc: (99.31%) (31907/32128)\n",
            "Epoch: 88 | Batch_idx: 260 |  Loss: (0.0257) | Acc: (99.31%) (33179/33408)\n",
            "Epoch: 88 | Batch_idx: 270 |  Loss: (0.0257) | Acc: (99.32%) (34452/34688)\n",
            "Epoch: 88 | Batch_idx: 280 |  Loss: (0.0255) | Acc: (99.33%) (35726/35968)\n",
            "Epoch: 88 | Batch_idx: 290 |  Loss: (0.0255) | Acc: (99.32%) (36996/37248)\n",
            "Epoch: 88 | Batch_idx: 300 |  Loss: (0.0255) | Acc: (99.32%) (38266/38528)\n",
            "Epoch: 88 | Batch_idx: 310 |  Loss: (0.0257) | Acc: (99.32%) (39537/39808)\n",
            "Epoch: 88 | Batch_idx: 320 |  Loss: (0.0259) | Acc: (99.29%) (40798/41088)\n",
            "Epoch: 88 | Batch_idx: 330 |  Loss: (0.0259) | Acc: (99.29%) (42069/42368)\n",
            "Epoch: 88 | Batch_idx: 340 |  Loss: (0.0257) | Acc: (99.30%) (43343/43648)\n",
            "Epoch: 88 | Batch_idx: 350 |  Loss: (0.0258) | Acc: (99.30%) (44614/44928)\n",
            "Epoch: 88 | Batch_idx: 360 |  Loss: (0.0260) | Acc: (99.29%) (45881/46208)\n",
            "Epoch: 88 | Batch_idx: 370 |  Loss: (0.0262) | Acc: (99.28%) (47146/47488)\n",
            "Epoch: 88 | Batch_idx: 380 |  Loss: (0.0262) | Acc: (99.28%) (48415/48768)\n",
            "Epoch: 88 | Batch_idx: 390 |  Loss: (0.0263) | Acc: (99.27%) (49637/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.2957) | Acc: (92.41%) (9241/10000)\n",
            "Epoch: 89 | Batch_idx: 0 |  Loss: (0.0068) | Acc: (100.00%) (128/128)\n",
            "Epoch: 89 | Batch_idx: 10 |  Loss: (0.0231) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 89 | Batch_idx: 20 |  Loss: (0.0236) | Acc: (99.37%) (2671/2688)\n",
            "Epoch: 89 | Batch_idx: 30 |  Loss: (0.0242) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 89 | Batch_idx: 40 |  Loss: (0.0251) | Acc: (99.29%) (5211/5248)\n",
            "Epoch: 89 | Batch_idx: 50 |  Loss: (0.0261) | Acc: (99.23%) (6478/6528)\n",
            "Epoch: 89 | Batch_idx: 60 |  Loss: (0.0251) | Acc: (99.27%) (7751/7808)\n",
            "Epoch: 89 | Batch_idx: 70 |  Loss: (0.0241) | Acc: (99.34%) (9028/9088)\n",
            "Epoch: 89 | Batch_idx: 80 |  Loss: (0.0240) | Acc: (99.32%) (10297/10368)\n",
            "Epoch: 89 | Batch_idx: 90 |  Loss: (0.0242) | Acc: (99.30%) (11567/11648)\n",
            "Epoch: 89 | Batch_idx: 100 |  Loss: (0.0240) | Acc: (99.32%) (12840/12928)\n",
            "Epoch: 89 | Batch_idx: 110 |  Loss: (0.0235) | Acc: (99.32%) (14112/14208)\n",
            "Epoch: 89 | Batch_idx: 120 |  Loss: (0.0242) | Acc: (99.30%) (15380/15488)\n",
            "Epoch: 89 | Batch_idx: 130 |  Loss: (0.0243) | Acc: (99.30%) (16650/16768)\n",
            "Epoch: 89 | Batch_idx: 140 |  Loss: (0.0240) | Acc: (99.32%) (17925/18048)\n",
            "Epoch: 89 | Batch_idx: 150 |  Loss: (0.0238) | Acc: (99.32%) (19196/19328)\n",
            "Epoch: 89 | Batch_idx: 160 |  Loss: (0.0241) | Acc: (99.30%) (20464/20608)\n",
            "Epoch: 89 | Batch_idx: 170 |  Loss: (0.0241) | Acc: (99.29%) (21733/21888)\n",
            "Epoch: 89 | Batch_idx: 180 |  Loss: (0.0239) | Acc: (99.31%) (23008/23168)\n",
            "Epoch: 89 | Batch_idx: 190 |  Loss: (0.0239) | Acc: (99.31%) (24279/24448)\n",
            "Epoch: 89 | Batch_idx: 200 |  Loss: (0.0243) | Acc: (99.29%) (25546/25728)\n",
            "Epoch: 89 | Batch_idx: 210 |  Loss: (0.0241) | Acc: (99.31%) (26822/27008)\n",
            "Epoch: 89 | Batch_idx: 220 |  Loss: (0.0242) | Acc: (99.30%) (28091/28288)\n",
            "Epoch: 89 | Batch_idx: 230 |  Loss: (0.0243) | Acc: (99.29%) (29358/29568)\n",
            "Epoch: 89 | Batch_idx: 240 |  Loss: (0.0244) | Acc: (99.29%) (30628/30848)\n",
            "Epoch: 89 | Batch_idx: 250 |  Loss: (0.0245) | Acc: (99.28%) (31897/32128)\n",
            "Epoch: 89 | Batch_idx: 260 |  Loss: (0.0244) | Acc: (99.28%) (33167/33408)\n",
            "Epoch: 89 | Batch_idx: 270 |  Loss: (0.0243) | Acc: (99.29%) (34440/34688)\n",
            "Epoch: 89 | Batch_idx: 280 |  Loss: (0.0245) | Acc: (99.27%) (35706/35968)\n",
            "Epoch: 89 | Batch_idx: 290 |  Loss: (0.0245) | Acc: (99.27%) (36977/37248)\n",
            "Epoch: 89 | Batch_idx: 300 |  Loss: (0.0243) | Acc: (99.28%) (38249/38528)\n",
            "Epoch: 89 | Batch_idx: 310 |  Loss: (0.0244) | Acc: (99.27%) (39518/39808)\n",
            "Epoch: 89 | Batch_idx: 320 |  Loss: (0.0246) | Acc: (99.27%) (40789/41088)\n",
            "Epoch: 89 | Batch_idx: 330 |  Loss: (0.0246) | Acc: (99.28%) (42062/42368)\n",
            "Epoch: 89 | Batch_idx: 340 |  Loss: (0.0244) | Acc: (99.28%) (43332/43648)\n",
            "Epoch: 89 | Batch_idx: 350 |  Loss: (0.0243) | Acc: (99.28%) (44605/44928)\n",
            "Epoch: 89 | Batch_idx: 360 |  Loss: (0.0246) | Acc: (99.27%) (45872/46208)\n",
            "Epoch: 89 | Batch_idx: 370 |  Loss: (0.0244) | Acc: (99.28%) (47145/47488)\n",
            "Epoch: 89 | Batch_idx: 380 |  Loss: (0.0243) | Acc: (99.28%) (48417/48768)\n",
            "Epoch: 89 | Batch_idx: 390 |  Loss: (0.0243) | Acc: (99.28%) (49641/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3062) | Acc: (92.32%) (9232/10000)\n",
            "Epoch: 90 | Batch_idx: 0 |  Loss: (0.0211) | Acc: (99.22%) (127/128)\n",
            "Epoch: 90 | Batch_idx: 10 |  Loss: (0.0247) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 90 | Batch_idx: 20 |  Loss: (0.0271) | Acc: (99.14%) (2665/2688)\n",
            "Epoch: 90 | Batch_idx: 30 |  Loss: (0.0260) | Acc: (99.19%) (3936/3968)\n",
            "Epoch: 90 | Batch_idx: 40 |  Loss: (0.0263) | Acc: (99.24%) (5208/5248)\n",
            "Epoch: 90 | Batch_idx: 50 |  Loss: (0.0256) | Acc: (99.28%) (6481/6528)\n",
            "Epoch: 90 | Batch_idx: 60 |  Loss: (0.0246) | Acc: (99.33%) (7756/7808)\n",
            "Epoch: 90 | Batch_idx: 70 |  Loss: (0.0243) | Acc: (99.32%) (9026/9088)\n",
            "Epoch: 90 | Batch_idx: 80 |  Loss: (0.0246) | Acc: (99.31%) (10296/10368)\n",
            "Epoch: 90 | Batch_idx: 90 |  Loss: (0.0239) | Acc: (99.36%) (11573/11648)\n",
            "Epoch: 90 | Batch_idx: 100 |  Loss: (0.0237) | Acc: (99.36%) (12845/12928)\n",
            "Epoch: 90 | Batch_idx: 110 |  Loss: (0.0233) | Acc: (99.37%) (14119/14208)\n",
            "Epoch: 90 | Batch_idx: 120 |  Loss: (0.0231) | Acc: (99.37%) (15391/15488)\n",
            "Epoch: 90 | Batch_idx: 130 |  Loss: (0.0232) | Acc: (99.37%) (16663/16768)\n",
            "Epoch: 90 | Batch_idx: 140 |  Loss: (0.0228) | Acc: (99.37%) (17935/18048)\n",
            "Epoch: 90 | Batch_idx: 150 |  Loss: (0.0227) | Acc: (99.38%) (19208/19328)\n",
            "Epoch: 90 | Batch_idx: 160 |  Loss: (0.0226) | Acc: (99.38%) (20481/20608)\n",
            "Epoch: 90 | Batch_idx: 170 |  Loss: (0.0223) | Acc: (99.39%) (21754/21888)\n",
            "Epoch: 90 | Batch_idx: 180 |  Loss: (0.0223) | Acc: (99.40%) (23029/23168)\n",
            "Epoch: 90 | Batch_idx: 190 |  Loss: (0.0224) | Acc: (99.39%) (24299/24448)\n",
            "Epoch: 90 | Batch_idx: 200 |  Loss: (0.0227) | Acc: (99.38%) (25568/25728)\n",
            "Epoch: 90 | Batch_idx: 210 |  Loss: (0.0229) | Acc: (99.37%) (26837/27008)\n",
            "Epoch: 90 | Batch_idx: 220 |  Loss: (0.0229) | Acc: (99.37%) (28109/28288)\n",
            "Epoch: 90 | Batch_idx: 230 |  Loss: (0.0228) | Acc: (99.38%) (29385/29568)\n",
            "Epoch: 90 | Batch_idx: 240 |  Loss: (0.0226) | Acc: (99.39%) (30660/30848)\n",
            "Epoch: 90 | Batch_idx: 250 |  Loss: (0.0228) | Acc: (99.39%) (31932/32128)\n",
            "Epoch: 90 | Batch_idx: 260 |  Loss: (0.0229) | Acc: (99.39%) (33203/33408)\n",
            "Epoch: 90 | Batch_idx: 270 |  Loss: (0.0231) | Acc: (99.37%) (34471/34688)\n",
            "Epoch: 90 | Batch_idx: 280 |  Loss: (0.0229) | Acc: (99.37%) (35742/35968)\n",
            "Epoch: 90 | Batch_idx: 290 |  Loss: (0.0232) | Acc: (99.36%) (37010/37248)\n",
            "Epoch: 90 | Batch_idx: 300 |  Loss: (0.0233) | Acc: (99.35%) (38279/38528)\n",
            "Epoch: 90 | Batch_idx: 310 |  Loss: (0.0231) | Acc: (99.36%) (39552/39808)\n",
            "Epoch: 90 | Batch_idx: 320 |  Loss: (0.0231) | Acc: (99.36%) (40823/41088)\n",
            "Epoch: 90 | Batch_idx: 330 |  Loss: (0.0229) | Acc: (99.36%) (42098/42368)\n",
            "Epoch: 90 | Batch_idx: 340 |  Loss: (0.0227) | Acc: (99.37%) (43375/43648)\n",
            "Epoch: 90 | Batch_idx: 350 |  Loss: (0.0227) | Acc: (99.37%) (44646/44928)\n",
            "Epoch: 90 | Batch_idx: 360 |  Loss: (0.0227) | Acc: (99.37%) (45918/46208)\n",
            "Epoch: 90 | Batch_idx: 370 |  Loss: (0.0230) | Acc: (99.36%) (47186/47488)\n",
            "Epoch: 90 | Batch_idx: 380 |  Loss: (0.0230) | Acc: (99.36%) (48455/48768)\n",
            "Epoch: 90 | Batch_idx: 390 |  Loss: (0.0230) | Acc: (99.36%) (49679/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3033) | Acc: (92.43%) (9243/10000)\n",
            "Epoch: 91 | Batch_idx: 0 |  Loss: (0.0127) | Acc: (100.00%) (128/128)\n",
            "Epoch: 91 | Batch_idx: 10 |  Loss: (0.0312) | Acc: (98.86%) (1392/1408)\n",
            "Epoch: 91 | Batch_idx: 20 |  Loss: (0.0272) | Acc: (99.11%) (2664/2688)\n",
            "Epoch: 91 | Batch_idx: 30 |  Loss: (0.0279) | Acc: (99.14%) (3934/3968)\n",
            "Epoch: 91 | Batch_idx: 40 |  Loss: (0.0260) | Acc: (99.20%) (5206/5248)\n",
            "Epoch: 91 | Batch_idx: 50 |  Loss: (0.0250) | Acc: (99.22%) (6477/6528)\n",
            "Epoch: 91 | Batch_idx: 60 |  Loss: (0.0243) | Acc: (99.28%) (7752/7808)\n",
            "Epoch: 91 | Batch_idx: 70 |  Loss: (0.0246) | Acc: (99.22%) (9017/9088)\n",
            "Epoch: 91 | Batch_idx: 80 |  Loss: (0.0256) | Acc: (99.17%) (10282/10368)\n",
            "Epoch: 91 | Batch_idx: 90 |  Loss: (0.0247) | Acc: (99.20%) (11555/11648)\n",
            "Epoch: 91 | Batch_idx: 100 |  Loss: (0.0254) | Acc: (99.16%) (12819/12928)\n",
            "Epoch: 91 | Batch_idx: 110 |  Loss: (0.0246) | Acc: (99.18%) (14092/14208)\n",
            "Epoch: 91 | Batch_idx: 120 |  Loss: (0.0244) | Acc: (99.20%) (15364/15488)\n",
            "Epoch: 91 | Batch_idx: 130 |  Loss: (0.0242) | Acc: (99.20%) (16634/16768)\n",
            "Epoch: 91 | Batch_idx: 140 |  Loss: (0.0242) | Acc: (99.22%) (17907/18048)\n",
            "Epoch: 91 | Batch_idx: 150 |  Loss: (0.0238) | Acc: (99.25%) (19183/19328)\n",
            "Epoch: 91 | Batch_idx: 160 |  Loss: (0.0241) | Acc: (99.24%) (20452/20608)\n",
            "Epoch: 91 | Batch_idx: 170 |  Loss: (0.0247) | Acc: (99.21%) (21715/21888)\n",
            "Epoch: 91 | Batch_idx: 180 |  Loss: (0.0248) | Acc: (99.21%) (22986/23168)\n",
            "Epoch: 91 | Batch_idx: 190 |  Loss: (0.0253) | Acc: (99.19%) (24249/24448)\n",
            "Epoch: 91 | Batch_idx: 200 |  Loss: (0.0250) | Acc: (99.20%) (25522/25728)\n",
            "Epoch: 91 | Batch_idx: 210 |  Loss: (0.0248) | Acc: (99.20%) (26793/27008)\n",
            "Epoch: 91 | Batch_idx: 220 |  Loss: (0.0246) | Acc: (99.21%) (28064/28288)\n",
            "Epoch: 91 | Batch_idx: 230 |  Loss: (0.0246) | Acc: (99.21%) (29335/29568)\n",
            "Epoch: 91 | Batch_idx: 240 |  Loss: (0.0242) | Acc: (99.23%) (30609/30848)\n",
            "Epoch: 91 | Batch_idx: 250 |  Loss: (0.0242) | Acc: (99.23%) (31881/32128)\n",
            "Epoch: 91 | Batch_idx: 260 |  Loss: (0.0240) | Acc: (99.25%) (33156/33408)\n",
            "Epoch: 91 | Batch_idx: 270 |  Loss: (0.0239) | Acc: (99.26%) (34430/34688)\n",
            "Epoch: 91 | Batch_idx: 280 |  Loss: (0.0237) | Acc: (99.26%) (35702/35968)\n",
            "Epoch: 91 | Batch_idx: 290 |  Loss: (0.0240) | Acc: (99.26%) (36971/37248)\n",
            "Epoch: 91 | Batch_idx: 300 |  Loss: (0.0240) | Acc: (99.26%) (38242/38528)\n",
            "Epoch: 91 | Batch_idx: 310 |  Loss: (0.0239) | Acc: (99.26%) (39514/39808)\n",
            "Epoch: 91 | Batch_idx: 320 |  Loss: (0.0239) | Acc: (99.26%) (40785/41088)\n",
            "Epoch: 91 | Batch_idx: 330 |  Loss: (0.0236) | Acc: (99.27%) (42060/42368)\n",
            "Epoch: 91 | Batch_idx: 340 |  Loss: (0.0236) | Acc: (99.28%) (43335/43648)\n",
            "Epoch: 91 | Batch_idx: 350 |  Loss: (0.0236) | Acc: (99.28%) (44606/44928)\n",
            "Epoch: 91 | Batch_idx: 360 |  Loss: (0.0233) | Acc: (99.30%) (45883/46208)\n",
            "Epoch: 91 | Batch_idx: 370 |  Loss: (0.0233) | Acc: (99.30%) (47157/47488)\n",
            "Epoch: 91 | Batch_idx: 380 |  Loss: (0.0233) | Acc: (99.30%) (48429/48768)\n",
            "Epoch: 91 | Batch_idx: 390 |  Loss: (0.0234) | Acc: (99.30%) (49651/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3103) | Acc: (92.46%) (9246/10000)\n",
            "Epoch: 92 | Batch_idx: 0 |  Loss: (0.0117) | Acc: (100.00%) (128/128)\n",
            "Epoch: 92 | Batch_idx: 10 |  Loss: (0.0118) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 92 | Batch_idx: 20 |  Loss: (0.0139) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 92 | Batch_idx: 30 |  Loss: (0.0151) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 92 | Batch_idx: 40 |  Loss: (0.0160) | Acc: (99.54%) (5224/5248)\n",
            "Epoch: 92 | Batch_idx: 50 |  Loss: (0.0173) | Acc: (99.51%) (6496/6528)\n",
            "Epoch: 92 | Batch_idx: 60 |  Loss: (0.0178) | Acc: (99.49%) (7768/7808)\n",
            "Epoch: 92 | Batch_idx: 70 |  Loss: (0.0183) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 92 | Batch_idx: 80 |  Loss: (0.0184) | Acc: (99.47%) (10313/10368)\n",
            "Epoch: 92 | Batch_idx: 90 |  Loss: (0.0190) | Acc: (99.45%) (11584/11648)\n",
            "Epoch: 92 | Batch_idx: 100 |  Loss: (0.0194) | Acc: (99.44%) (12856/12928)\n",
            "Epoch: 92 | Batch_idx: 110 |  Loss: (0.0193) | Acc: (99.44%) (14129/14208)\n",
            "Epoch: 92 | Batch_idx: 120 |  Loss: (0.0193) | Acc: (99.44%) (15402/15488)\n",
            "Epoch: 92 | Batch_idx: 130 |  Loss: (0.0199) | Acc: (99.44%) (16674/16768)\n",
            "Epoch: 92 | Batch_idx: 140 |  Loss: (0.0195) | Acc: (99.46%) (17951/18048)\n",
            "Epoch: 92 | Batch_idx: 150 |  Loss: (0.0195) | Acc: (99.47%) (19225/19328)\n",
            "Epoch: 92 | Batch_idx: 160 |  Loss: (0.0199) | Acc: (99.45%) (20494/20608)\n",
            "Epoch: 92 | Batch_idx: 170 |  Loss: (0.0197) | Acc: (99.46%) (21770/21888)\n",
            "Epoch: 92 | Batch_idx: 180 |  Loss: (0.0197) | Acc: (99.46%) (23044/23168)\n",
            "Epoch: 92 | Batch_idx: 190 |  Loss: (0.0197) | Acc: (99.47%) (24318/24448)\n",
            "Epoch: 92 | Batch_idx: 200 |  Loss: (0.0197) | Acc: (99.47%) (25591/25728)\n",
            "Epoch: 92 | Batch_idx: 210 |  Loss: (0.0197) | Acc: (99.46%) (26862/27008)\n",
            "Epoch: 92 | Batch_idx: 220 |  Loss: (0.0199) | Acc: (99.46%) (28134/28288)\n",
            "Epoch: 92 | Batch_idx: 230 |  Loss: (0.0202) | Acc: (99.44%) (29402/29568)\n",
            "Epoch: 92 | Batch_idx: 240 |  Loss: (0.0201) | Acc: (99.44%) (30675/30848)\n",
            "Epoch: 92 | Batch_idx: 250 |  Loss: (0.0202) | Acc: (99.43%) (31945/32128)\n",
            "Epoch: 92 | Batch_idx: 260 |  Loss: (0.0201) | Acc: (99.43%) (33216/33408)\n",
            "Epoch: 92 | Batch_idx: 270 |  Loss: (0.0202) | Acc: (99.42%) (34487/34688)\n",
            "Epoch: 92 | Batch_idx: 280 |  Loss: (0.0202) | Acc: (99.42%) (35760/35968)\n",
            "Epoch: 92 | Batch_idx: 290 |  Loss: (0.0201) | Acc: (99.42%) (37032/37248)\n",
            "Epoch: 92 | Batch_idx: 300 |  Loss: (0.0200) | Acc: (99.42%) (38306/38528)\n",
            "Epoch: 92 | Batch_idx: 310 |  Loss: (0.0201) | Acc: (99.42%) (39577/39808)\n",
            "Epoch: 92 | Batch_idx: 320 |  Loss: (0.0202) | Acc: (99.42%) (40848/41088)\n",
            "Epoch: 92 | Batch_idx: 330 |  Loss: (0.0202) | Acc: (99.41%) (42119/42368)\n",
            "Epoch: 92 | Batch_idx: 340 |  Loss: (0.0201) | Acc: (99.42%) (43394/43648)\n",
            "Epoch: 92 | Batch_idx: 350 |  Loss: (0.0202) | Acc: (99.41%) (44665/44928)\n",
            "Epoch: 92 | Batch_idx: 360 |  Loss: (0.0203) | Acc: (99.40%) (45932/46208)\n",
            "Epoch: 92 | Batch_idx: 370 |  Loss: (0.0204) | Acc: (99.40%) (47202/47488)\n",
            "Epoch: 92 | Batch_idx: 380 |  Loss: (0.0203) | Acc: (99.40%) (48477/48768)\n",
            "Epoch: 92 | Batch_idx: 390 |  Loss: (0.0203) | Acc: (99.41%) (49703/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3152) | Acc: (92.44%) (9244/10000)\n",
            "Epoch: 93 | Batch_idx: 0 |  Loss: (0.0309) | Acc: (99.22%) (127/128)\n",
            "Epoch: 93 | Batch_idx: 10 |  Loss: (0.0194) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 93 | Batch_idx: 20 |  Loss: (0.0180) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 93 | Batch_idx: 30 |  Loss: (0.0193) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 93 | Batch_idx: 40 |  Loss: (0.0216) | Acc: (99.37%) (5215/5248)\n",
            "Epoch: 93 | Batch_idx: 50 |  Loss: (0.0215) | Acc: (99.33%) (6484/6528)\n",
            "Epoch: 93 | Batch_idx: 60 |  Loss: (0.0206) | Acc: (99.33%) (7756/7808)\n",
            "Epoch: 93 | Batch_idx: 70 |  Loss: (0.0218) | Acc: (99.32%) (9026/9088)\n",
            "Epoch: 93 | Batch_idx: 80 |  Loss: (0.0220) | Acc: (99.31%) (10296/10368)\n",
            "Epoch: 93 | Batch_idx: 90 |  Loss: (0.0219) | Acc: (99.30%) (11567/11648)\n",
            "Epoch: 93 | Batch_idx: 100 |  Loss: (0.0218) | Acc: (99.30%) (12838/12928)\n",
            "Epoch: 93 | Batch_idx: 110 |  Loss: (0.0216) | Acc: (99.29%) (14107/14208)\n",
            "Epoch: 93 | Batch_idx: 120 |  Loss: (0.0221) | Acc: (99.27%) (15375/15488)\n",
            "Epoch: 93 | Batch_idx: 130 |  Loss: (0.0216) | Acc: (99.30%) (16651/16768)\n",
            "Epoch: 93 | Batch_idx: 140 |  Loss: (0.0214) | Acc: (99.31%) (17924/18048)\n",
            "Epoch: 93 | Batch_idx: 150 |  Loss: (0.0214) | Acc: (99.32%) (19196/19328)\n",
            "Epoch: 93 | Batch_idx: 160 |  Loss: (0.0214) | Acc: (99.33%) (20470/20608)\n",
            "Epoch: 93 | Batch_idx: 170 |  Loss: (0.0216) | Acc: (99.32%) (21740/21888)\n",
            "Epoch: 93 | Batch_idx: 180 |  Loss: (0.0212) | Acc: (99.35%) (23017/23168)\n",
            "Epoch: 93 | Batch_idx: 190 |  Loss: (0.0212) | Acc: (99.36%) (24292/24448)\n",
            "Epoch: 93 | Batch_idx: 200 |  Loss: (0.0212) | Acc: (99.36%) (25564/25728)\n",
            "Epoch: 93 | Batch_idx: 210 |  Loss: (0.0212) | Acc: (99.35%) (26833/27008)\n",
            "Epoch: 93 | Batch_idx: 220 |  Loss: (0.0214) | Acc: (99.35%) (28105/28288)\n",
            "Epoch: 93 | Batch_idx: 230 |  Loss: (0.0213) | Acc: (99.35%) (29377/29568)\n",
            "Epoch: 93 | Batch_idx: 240 |  Loss: (0.0214) | Acc: (99.36%) (30651/30848)\n",
            "Epoch: 93 | Batch_idx: 250 |  Loss: (0.0213) | Acc: (99.36%) (31922/32128)\n",
            "Epoch: 93 | Batch_idx: 260 |  Loss: (0.0211) | Acc: (99.37%) (33198/33408)\n",
            "Epoch: 93 | Batch_idx: 270 |  Loss: (0.0212) | Acc: (99.38%) (34473/34688)\n",
            "Epoch: 93 | Batch_idx: 280 |  Loss: (0.0213) | Acc: (99.38%) (35745/35968)\n",
            "Epoch: 93 | Batch_idx: 290 |  Loss: (0.0210) | Acc: (99.39%) (37021/37248)\n",
            "Epoch: 93 | Batch_idx: 300 |  Loss: (0.0208) | Acc: (99.40%) (38295/38528)\n",
            "Epoch: 93 | Batch_idx: 310 |  Loss: (0.0210) | Acc: (99.38%) (39562/39808)\n",
            "Epoch: 93 | Batch_idx: 320 |  Loss: (0.0210) | Acc: (99.39%) (40836/41088)\n",
            "Epoch: 93 | Batch_idx: 330 |  Loss: (0.0210) | Acc: (99.38%) (42107/42368)\n",
            "Epoch: 93 | Batch_idx: 340 |  Loss: (0.0210) | Acc: (99.38%) (43377/43648)\n",
            "Epoch: 93 | Batch_idx: 350 |  Loss: (0.0210) | Acc: (99.38%) (44649/44928)\n",
            "Epoch: 93 | Batch_idx: 360 |  Loss: (0.0212) | Acc: (99.37%) (45917/46208)\n",
            "Epoch: 93 | Batch_idx: 370 |  Loss: (0.0211) | Acc: (99.37%) (47189/47488)\n",
            "Epoch: 93 | Batch_idx: 380 |  Loss: (0.0209) | Acc: (99.38%) (48464/48768)\n",
            "Epoch: 93 | Batch_idx: 390 |  Loss: (0.0211) | Acc: (99.36%) (49681/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3153) | Acc: (92.26%) (9226/10000)\n",
            "Epoch: 94 | Batch_idx: 0 |  Loss: (0.0320) | Acc: (98.44%) (126/128)\n",
            "Epoch: 94 | Batch_idx: 10 |  Loss: (0.0188) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 94 | Batch_idx: 20 |  Loss: (0.0189) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 94 | Batch_idx: 30 |  Loss: (0.0230) | Acc: (99.27%) (3939/3968)\n",
            "Epoch: 94 | Batch_idx: 40 |  Loss: (0.0212) | Acc: (99.37%) (5215/5248)\n",
            "Epoch: 94 | Batch_idx: 50 |  Loss: (0.0210) | Acc: (99.36%) (6486/6528)\n",
            "Epoch: 94 | Batch_idx: 60 |  Loss: (0.0212) | Acc: (99.40%) (7761/7808)\n",
            "Epoch: 94 | Batch_idx: 70 |  Loss: (0.0217) | Acc: (99.35%) (9029/9088)\n",
            "Epoch: 94 | Batch_idx: 80 |  Loss: (0.0205) | Acc: (99.40%) (10306/10368)\n",
            "Epoch: 94 | Batch_idx: 90 |  Loss: (0.0199) | Acc: (99.43%) (11582/11648)\n",
            "Epoch: 94 | Batch_idx: 100 |  Loss: (0.0199) | Acc: (99.43%) (12854/12928)\n",
            "Epoch: 94 | Batch_idx: 110 |  Loss: (0.0203) | Acc: (99.42%) (14125/14208)\n",
            "Epoch: 94 | Batch_idx: 120 |  Loss: (0.0201) | Acc: (99.43%) (15399/15488)\n",
            "Epoch: 94 | Batch_idx: 130 |  Loss: (0.0201) | Acc: (99.43%) (16673/16768)\n",
            "Epoch: 94 | Batch_idx: 140 |  Loss: (0.0201) | Acc: (99.44%) (17947/18048)\n",
            "Epoch: 94 | Batch_idx: 150 |  Loss: (0.0204) | Acc: (99.43%) (19218/19328)\n",
            "Epoch: 94 | Batch_idx: 160 |  Loss: (0.0204) | Acc: (99.43%) (20490/20608)\n",
            "Epoch: 94 | Batch_idx: 170 |  Loss: (0.0204) | Acc: (99.42%) (21762/21888)\n",
            "Epoch: 94 | Batch_idx: 180 |  Loss: (0.0202) | Acc: (99.44%) (23039/23168)\n",
            "Epoch: 94 | Batch_idx: 190 |  Loss: (0.0200) | Acc: (99.44%) (24312/24448)\n",
            "Epoch: 94 | Batch_idx: 200 |  Loss: (0.0200) | Acc: (99.44%) (25585/25728)\n",
            "Epoch: 94 | Batch_idx: 210 |  Loss: (0.0199) | Acc: (99.45%) (26860/27008)\n",
            "Epoch: 94 | Batch_idx: 220 |  Loss: (0.0195) | Acc: (99.46%) (28135/28288)\n",
            "Epoch: 94 | Batch_idx: 230 |  Loss: (0.0197) | Acc: (99.46%) (29407/29568)\n",
            "Epoch: 94 | Batch_idx: 240 |  Loss: (0.0198) | Acc: (99.45%) (30677/30848)\n",
            "Epoch: 94 | Batch_idx: 250 |  Loss: (0.0197) | Acc: (99.45%) (31952/32128)\n",
            "Epoch: 94 | Batch_idx: 260 |  Loss: (0.0197) | Acc: (99.46%) (33228/33408)\n",
            "Epoch: 94 | Batch_idx: 270 |  Loss: (0.0197) | Acc: (99.46%) (34500/34688)\n",
            "Epoch: 94 | Batch_idx: 280 |  Loss: (0.0196) | Acc: (99.46%) (35774/35968)\n",
            "Epoch: 94 | Batch_idx: 290 |  Loss: (0.0201) | Acc: (99.44%) (37041/37248)\n",
            "Epoch: 94 | Batch_idx: 300 |  Loss: (0.0201) | Acc: (99.45%) (38315/38528)\n",
            "Epoch: 94 | Batch_idx: 310 |  Loss: (0.0200) | Acc: (99.45%) (39588/39808)\n",
            "Epoch: 94 | Batch_idx: 320 |  Loss: (0.0199) | Acc: (99.45%) (40864/41088)\n",
            "Epoch: 94 | Batch_idx: 330 |  Loss: (0.0197) | Acc: (99.46%) (42138/42368)\n",
            "Epoch: 94 | Batch_idx: 340 |  Loss: (0.0196) | Acc: (99.47%) (43416/43648)\n",
            "Epoch: 94 | Batch_idx: 350 |  Loss: (0.0194) | Acc: (99.48%) (44693/44928)\n",
            "Epoch: 94 | Batch_idx: 360 |  Loss: (0.0193) | Acc: (99.48%) (45968/46208)\n",
            "Epoch: 94 | Batch_idx: 370 |  Loss: (0.0193) | Acc: (99.48%) (47241/47488)\n",
            "Epoch: 94 | Batch_idx: 380 |  Loss: (0.0192) | Acc: (99.49%) (48518/48768)\n",
            "Epoch: 94 | Batch_idx: 390 |  Loss: (0.0193) | Acc: (99.48%) (49741/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3166) | Acc: (92.39%) (9239/10000)\n",
            "Epoch: 95 | Batch_idx: 0 |  Loss: (0.0220) | Acc: (99.22%) (127/128)\n",
            "Epoch: 95 | Batch_idx: 10 |  Loss: (0.0166) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 95 | Batch_idx: 20 |  Loss: (0.0194) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 95 | Batch_idx: 30 |  Loss: (0.0200) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 95 | Batch_idx: 40 |  Loss: (0.0182) | Acc: (99.50%) (5222/5248)\n",
            "Epoch: 95 | Batch_idx: 50 |  Loss: (0.0182) | Acc: (99.49%) (6495/6528)\n",
            "Epoch: 95 | Batch_idx: 60 |  Loss: (0.0189) | Acc: (99.44%) (7764/7808)\n",
            "Epoch: 95 | Batch_idx: 70 |  Loss: (0.0184) | Acc: (99.45%) (9038/9088)\n",
            "Epoch: 95 | Batch_idx: 80 |  Loss: (0.0182) | Acc: (99.48%) (10314/10368)\n",
            "Epoch: 95 | Batch_idx: 90 |  Loss: (0.0192) | Acc: (99.44%) (11583/11648)\n",
            "Epoch: 95 | Batch_idx: 100 |  Loss: (0.0191) | Acc: (99.44%) (12856/12928)\n",
            "Epoch: 95 | Batch_idx: 110 |  Loss: (0.0192) | Acc: (99.46%) (14131/14208)\n",
            "Epoch: 95 | Batch_idx: 120 |  Loss: (0.0187) | Acc: (99.48%) (15408/15488)\n",
            "Epoch: 95 | Batch_idx: 130 |  Loss: (0.0188) | Acc: (99.49%) (16683/16768)\n",
            "Epoch: 95 | Batch_idx: 140 |  Loss: (0.0186) | Acc: (99.50%) (17957/18048)\n",
            "Epoch: 95 | Batch_idx: 150 |  Loss: (0.0187) | Acc: (99.48%) (19228/19328)\n",
            "Epoch: 95 | Batch_idx: 160 |  Loss: (0.0186) | Acc: (99.49%) (20502/20608)\n",
            "Epoch: 95 | Batch_idx: 170 |  Loss: (0.0192) | Acc: (99.46%) (21770/21888)\n",
            "Epoch: 95 | Batch_idx: 180 |  Loss: (0.0192) | Acc: (99.46%) (23043/23168)\n",
            "Epoch: 95 | Batch_idx: 190 |  Loss: (0.0191) | Acc: (99.46%) (24316/24448)\n",
            "Epoch: 95 | Batch_idx: 200 |  Loss: (0.0190) | Acc: (99.46%) (25590/25728)\n",
            "Epoch: 95 | Batch_idx: 210 |  Loss: (0.0195) | Acc: (99.44%) (26856/27008)\n",
            "Epoch: 95 | Batch_idx: 220 |  Loss: (0.0195) | Acc: (99.44%) (28129/28288)\n",
            "Epoch: 95 | Batch_idx: 230 |  Loss: (0.0200) | Acc: (99.40%) (29391/29568)\n",
            "Epoch: 95 | Batch_idx: 240 |  Loss: (0.0203) | Acc: (99.39%) (30661/30848)\n",
            "Epoch: 95 | Batch_idx: 250 |  Loss: (0.0203) | Acc: (99.39%) (31932/32128)\n",
            "Epoch: 95 | Batch_idx: 260 |  Loss: (0.0205) | Acc: (99.39%) (33203/33408)\n",
            "Epoch: 95 | Batch_idx: 270 |  Loss: (0.0204) | Acc: (99.39%) (34476/34688)\n",
            "Epoch: 95 | Batch_idx: 280 |  Loss: (0.0205) | Acc: (99.39%) (35747/35968)\n",
            "Epoch: 95 | Batch_idx: 290 |  Loss: (0.0205) | Acc: (99.38%) (37018/37248)\n",
            "Epoch: 95 | Batch_idx: 300 |  Loss: (0.0206) | Acc: (99.38%) (38290/38528)\n",
            "Epoch: 95 | Batch_idx: 310 |  Loss: (0.0205) | Acc: (99.38%) (39562/39808)\n",
            "Epoch: 95 | Batch_idx: 320 |  Loss: (0.0205) | Acc: (99.39%) (40836/41088)\n",
            "Epoch: 95 | Batch_idx: 330 |  Loss: (0.0203) | Acc: (99.39%) (42110/42368)\n",
            "Epoch: 95 | Batch_idx: 340 |  Loss: (0.0201) | Acc: (99.40%) (43387/43648)\n",
            "Epoch: 95 | Batch_idx: 350 |  Loss: (0.0201) | Acc: (99.41%) (44661/44928)\n",
            "Epoch: 95 | Batch_idx: 360 |  Loss: (0.0199) | Acc: (99.42%) (45939/46208)\n",
            "Epoch: 95 | Batch_idx: 370 |  Loss: (0.0197) | Acc: (99.43%) (47217/47488)\n",
            "Epoch: 95 | Batch_idx: 380 |  Loss: (0.0195) | Acc: (99.44%) (48494/48768)\n",
            "Epoch: 95 | Batch_idx: 390 |  Loss: (0.0196) | Acc: (99.43%) (49715/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3093) | Acc: (92.44%) (9244/10000)\n",
            "Epoch: 96 | Batch_idx: 0 |  Loss: (0.0169) | Acc: (100.00%) (128/128)\n",
            "Epoch: 96 | Batch_idx: 10 |  Loss: (0.0184) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 96 | Batch_idx: 20 |  Loss: (0.0184) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 96 | Batch_idx: 30 |  Loss: (0.0183) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 96 | Batch_idx: 40 |  Loss: (0.0189) | Acc: (99.37%) (5215/5248)\n",
            "Epoch: 96 | Batch_idx: 50 |  Loss: (0.0176) | Acc: (99.45%) (6492/6528)\n",
            "Epoch: 96 | Batch_idx: 60 |  Loss: (0.0173) | Acc: (99.47%) (7767/7808)\n",
            "Epoch: 96 | Batch_idx: 70 |  Loss: (0.0172) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 96 | Batch_idx: 80 |  Loss: (0.0170) | Acc: (99.50%) (10316/10368)\n",
            "Epoch: 96 | Batch_idx: 90 |  Loss: (0.0167) | Acc: (99.52%) (11592/11648)\n",
            "Epoch: 96 | Batch_idx: 100 |  Loss: (0.0169) | Acc: (99.49%) (12862/12928)\n",
            "Epoch: 96 | Batch_idx: 110 |  Loss: (0.0169) | Acc: (99.48%) (14134/14208)\n",
            "Epoch: 96 | Batch_idx: 120 |  Loss: (0.0166) | Acc: (99.50%) (15410/15488)\n",
            "Epoch: 96 | Batch_idx: 130 |  Loss: (0.0165) | Acc: (99.51%) (16685/16768)\n",
            "Epoch: 96 | Batch_idx: 140 |  Loss: (0.0167) | Acc: (99.50%) (17957/18048)\n",
            "Epoch: 96 | Batch_idx: 150 |  Loss: (0.0170) | Acc: (99.49%) (19229/19328)\n",
            "Epoch: 96 | Batch_idx: 160 |  Loss: (0.0172) | Acc: (99.49%) (20502/20608)\n",
            "Epoch: 96 | Batch_idx: 170 |  Loss: (0.0169) | Acc: (99.50%) (21778/21888)\n",
            "Epoch: 96 | Batch_idx: 180 |  Loss: (0.0172) | Acc: (99.49%) (23051/23168)\n",
            "Epoch: 96 | Batch_idx: 190 |  Loss: (0.0172) | Acc: (99.49%) (24324/24448)\n",
            "Epoch: 96 | Batch_idx: 200 |  Loss: (0.0171) | Acc: (99.50%) (25599/25728)\n",
            "Epoch: 96 | Batch_idx: 210 |  Loss: (0.0173) | Acc: (99.49%) (26870/27008)\n",
            "Epoch: 96 | Batch_idx: 220 |  Loss: (0.0170) | Acc: (99.50%) (28147/28288)\n",
            "Epoch: 96 | Batch_idx: 230 |  Loss: (0.0167) | Acc: (99.52%) (29426/29568)\n",
            "Epoch: 96 | Batch_idx: 240 |  Loss: (0.0168) | Acc: (99.52%) (30701/30848)\n",
            "Epoch: 96 | Batch_idx: 250 |  Loss: (0.0168) | Acc: (99.52%) (31975/32128)\n",
            "Epoch: 96 | Batch_idx: 260 |  Loss: (0.0167) | Acc: (99.53%) (33250/33408)\n",
            "Epoch: 96 | Batch_idx: 270 |  Loss: (0.0168) | Acc: (99.52%) (34521/34688)\n",
            "Epoch: 96 | Batch_idx: 280 |  Loss: (0.0168) | Acc: (99.51%) (35793/35968)\n",
            "Epoch: 96 | Batch_idx: 290 |  Loss: (0.0169) | Acc: (99.52%) (37068/37248)\n",
            "Epoch: 96 | Batch_idx: 300 |  Loss: (0.0170) | Acc: (99.52%) (38342/38528)\n",
            "Epoch: 96 | Batch_idx: 310 |  Loss: (0.0170) | Acc: (99.52%) (39618/39808)\n",
            "Epoch: 96 | Batch_idx: 320 |  Loss: (0.0168) | Acc: (99.54%) (40897/41088)\n",
            "Epoch: 96 | Batch_idx: 330 |  Loss: (0.0168) | Acc: (99.53%) (42169/42368)\n",
            "Epoch: 96 | Batch_idx: 340 |  Loss: (0.0168) | Acc: (99.53%) (43441/43648)\n",
            "Epoch: 96 | Batch_idx: 350 |  Loss: (0.0167) | Acc: (99.53%) (44718/44928)\n",
            "Epoch: 96 | Batch_idx: 360 |  Loss: (0.0167) | Acc: (99.53%) (45993/46208)\n",
            "Epoch: 96 | Batch_idx: 370 |  Loss: (0.0168) | Acc: (99.52%) (47261/47488)\n",
            "Epoch: 96 | Batch_idx: 380 |  Loss: (0.0167) | Acc: (99.52%) (48535/48768)\n",
            "Epoch: 96 | Batch_idx: 390 |  Loss: (0.0171) | Acc: (99.51%) (49755/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3280) | Acc: (92.33%) (9233/10000)\n",
            "Epoch: 97 | Batch_idx: 0 |  Loss: (0.0343) | Acc: (99.22%) (127/128)\n",
            "Epoch: 97 | Batch_idx: 10 |  Loss: (0.0245) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 97 | Batch_idx: 20 |  Loss: (0.0204) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 97 | Batch_idx: 30 |  Loss: (0.0190) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 97 | Batch_idx: 40 |  Loss: (0.0180) | Acc: (99.49%) (5221/5248)\n",
            "Epoch: 97 | Batch_idx: 50 |  Loss: (0.0175) | Acc: (99.56%) (6499/6528)\n",
            "Epoch: 97 | Batch_idx: 60 |  Loss: (0.0165) | Acc: (99.60%) (7777/7808)\n",
            "Epoch: 97 | Batch_idx: 70 |  Loss: (0.0163) | Acc: (99.60%) (9052/9088)\n",
            "Epoch: 97 | Batch_idx: 80 |  Loss: (0.0157) | Acc: (99.63%) (10330/10368)\n",
            "Epoch: 97 | Batch_idx: 90 |  Loss: (0.0153) | Acc: (99.64%) (11606/11648)\n",
            "Epoch: 97 | Batch_idx: 100 |  Loss: (0.0154) | Acc: (99.61%) (12878/12928)\n",
            "Epoch: 97 | Batch_idx: 110 |  Loss: (0.0152) | Acc: (99.63%) (14156/14208)\n",
            "Epoch: 97 | Batch_idx: 120 |  Loss: (0.0150) | Acc: (99.65%) (15434/15488)\n",
            "Epoch: 97 | Batch_idx: 130 |  Loss: (0.0156) | Acc: (99.62%) (16704/16768)\n",
            "Epoch: 97 | Batch_idx: 140 |  Loss: (0.0154) | Acc: (99.63%) (17981/18048)\n",
            "Epoch: 97 | Batch_idx: 150 |  Loss: (0.0153) | Acc: (99.62%) (19255/19328)\n",
            "Epoch: 97 | Batch_idx: 160 |  Loss: (0.0153) | Acc: (99.60%) (20526/20608)\n",
            "Epoch: 97 | Batch_idx: 170 |  Loss: (0.0154) | Acc: (99.58%) (21797/21888)\n",
            "Epoch: 97 | Batch_idx: 180 |  Loss: (0.0155) | Acc: (99.59%) (23073/23168)\n",
            "Epoch: 97 | Batch_idx: 190 |  Loss: (0.0153) | Acc: (99.60%) (24349/24448)\n",
            "Epoch: 97 | Batch_idx: 200 |  Loss: (0.0152) | Acc: (99.60%) (25624/25728)\n",
            "Epoch: 97 | Batch_idx: 210 |  Loss: (0.0150) | Acc: (99.60%) (26901/27008)\n",
            "Epoch: 97 | Batch_idx: 220 |  Loss: (0.0150) | Acc: (99.60%) (28176/28288)\n",
            "Epoch: 97 | Batch_idx: 230 |  Loss: (0.0148) | Acc: (99.61%) (29452/29568)\n",
            "Epoch: 97 | Batch_idx: 240 |  Loss: (0.0147) | Acc: (99.62%) (30730/30848)\n",
            "Epoch: 97 | Batch_idx: 250 |  Loss: (0.0147) | Acc: (99.61%) (32004/32128)\n",
            "Epoch: 97 | Batch_idx: 260 |  Loss: (0.0151) | Acc: (99.60%) (33273/33408)\n",
            "Epoch: 97 | Batch_idx: 270 |  Loss: (0.0151) | Acc: (99.59%) (34546/34688)\n",
            "Epoch: 97 | Batch_idx: 280 |  Loss: (0.0151) | Acc: (99.59%) (35821/35968)\n",
            "Epoch: 97 | Batch_idx: 290 |  Loss: (0.0152) | Acc: (99.58%) (37092/37248)\n",
            "Epoch: 97 | Batch_idx: 300 |  Loss: (0.0153) | Acc: (99.57%) (38364/38528)\n",
            "Epoch: 97 | Batch_idx: 310 |  Loss: (0.0153) | Acc: (99.57%) (39637/39808)\n",
            "Epoch: 97 | Batch_idx: 320 |  Loss: (0.0151) | Acc: (99.58%) (40914/41088)\n",
            "Epoch: 97 | Batch_idx: 330 |  Loss: (0.0151) | Acc: (99.58%) (42191/42368)\n",
            "Epoch: 97 | Batch_idx: 340 |  Loss: (0.0151) | Acc: (99.58%) (43466/43648)\n",
            "Epoch: 97 | Batch_idx: 350 |  Loss: (0.0150) | Acc: (99.58%) (44740/44928)\n",
            "Epoch: 97 | Batch_idx: 360 |  Loss: (0.0149) | Acc: (99.59%) (46017/46208)\n",
            "Epoch: 97 | Batch_idx: 370 |  Loss: (0.0149) | Acc: (99.59%) (47294/47488)\n",
            "Epoch: 97 | Batch_idx: 380 |  Loss: (0.0149) | Acc: (99.59%) (48570/48768)\n",
            "Epoch: 97 | Batch_idx: 390 |  Loss: (0.0150) | Acc: (99.59%) (49797/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3291) | Acc: (92.38%) (9238/10000)\n",
            "Epoch: 98 | Batch_idx: 0 |  Loss: (0.0130) | Acc: (100.00%) (128/128)\n",
            "Epoch: 98 | Batch_idx: 10 |  Loss: (0.0196) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 98 | Batch_idx: 20 |  Loss: (0.0170) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 98 | Batch_idx: 30 |  Loss: (0.0173) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 98 | Batch_idx: 40 |  Loss: (0.0159) | Acc: (99.56%) (5225/5248)\n",
            "Epoch: 98 | Batch_idx: 50 |  Loss: (0.0157) | Acc: (99.59%) (6501/6528)\n",
            "Epoch: 98 | Batch_idx: 60 |  Loss: (0.0162) | Acc: (99.55%) (7773/7808)\n",
            "Epoch: 98 | Batch_idx: 70 |  Loss: (0.0166) | Acc: (99.58%) (9050/9088)\n",
            "Epoch: 98 | Batch_idx: 80 |  Loss: (0.0159) | Acc: (99.59%) (10326/10368)\n",
            "Epoch: 98 | Batch_idx: 90 |  Loss: (0.0156) | Acc: (99.61%) (11602/11648)\n",
            "Epoch: 98 | Batch_idx: 100 |  Loss: (0.0158) | Acc: (99.58%) (12874/12928)\n",
            "Epoch: 98 | Batch_idx: 110 |  Loss: (0.0161) | Acc: (99.58%) (14148/14208)\n",
            "Epoch: 98 | Batch_idx: 120 |  Loss: (0.0160) | Acc: (99.56%) (15420/15488)\n",
            "Epoch: 98 | Batch_idx: 130 |  Loss: (0.0157) | Acc: (99.56%) (16695/16768)\n",
            "Epoch: 98 | Batch_idx: 140 |  Loss: (0.0155) | Acc: (99.56%) (17969/18048)\n",
            "Epoch: 98 | Batch_idx: 150 |  Loss: (0.0154) | Acc: (99.57%) (19244/19328)\n",
            "Epoch: 98 | Batch_idx: 160 |  Loss: (0.0155) | Acc: (99.56%) (20517/20608)\n",
            "Epoch: 98 | Batch_idx: 170 |  Loss: (0.0156) | Acc: (99.56%) (21792/21888)\n",
            "Epoch: 98 | Batch_idx: 180 |  Loss: (0.0158) | Acc: (99.55%) (23064/23168)\n",
            "Epoch: 98 | Batch_idx: 190 |  Loss: (0.0158) | Acc: (99.55%) (24337/24448)\n",
            "Epoch: 98 | Batch_idx: 200 |  Loss: (0.0157) | Acc: (99.54%) (25609/25728)\n",
            "Epoch: 98 | Batch_idx: 210 |  Loss: (0.0154) | Acc: (99.56%) (26888/27008)\n",
            "Epoch: 98 | Batch_idx: 220 |  Loss: (0.0155) | Acc: (99.56%) (28163/28288)\n",
            "Epoch: 98 | Batch_idx: 230 |  Loss: (0.0154) | Acc: (99.57%) (29440/29568)\n",
            "Epoch: 98 | Batch_idx: 240 |  Loss: (0.0154) | Acc: (99.57%) (30714/30848)\n",
            "Epoch: 98 | Batch_idx: 250 |  Loss: (0.0155) | Acc: (99.56%) (31987/32128)\n",
            "Epoch: 98 | Batch_idx: 260 |  Loss: (0.0155) | Acc: (99.56%) (33261/33408)\n",
            "Epoch: 98 | Batch_idx: 270 |  Loss: (0.0157) | Acc: (99.56%) (34536/34688)\n",
            "Epoch: 98 | Batch_idx: 280 |  Loss: (0.0157) | Acc: (99.56%) (35811/35968)\n",
            "Epoch: 98 | Batch_idx: 290 |  Loss: (0.0159) | Acc: (99.56%) (37083/37248)\n",
            "Epoch: 98 | Batch_idx: 300 |  Loss: (0.0160) | Acc: (99.55%) (38355/38528)\n",
            "Epoch: 98 | Batch_idx: 310 |  Loss: (0.0161) | Acc: (99.55%) (39629/39808)\n",
            "Epoch: 98 | Batch_idx: 320 |  Loss: (0.0161) | Acc: (99.55%) (40903/41088)\n",
            "Epoch: 98 | Batch_idx: 330 |  Loss: (0.0163) | Acc: (99.54%) (42173/42368)\n",
            "Epoch: 98 | Batch_idx: 340 |  Loss: (0.0162) | Acc: (99.55%) (43450/43648)\n",
            "Epoch: 98 | Batch_idx: 350 |  Loss: (0.0162) | Acc: (99.55%) (44725/44928)\n",
            "Epoch: 98 | Batch_idx: 360 |  Loss: (0.0164) | Acc: (99.55%) (45998/46208)\n",
            "Epoch: 98 | Batch_idx: 370 |  Loss: (0.0165) | Acc: (99.54%) (47271/47488)\n",
            "Epoch: 98 | Batch_idx: 380 |  Loss: (0.0165) | Acc: (99.54%) (48545/48768)\n",
            "Epoch: 98 | Batch_idx: 390 |  Loss: (0.0164) | Acc: (99.55%) (49773/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3305) | Acc: (92.40%) (9240/10000)\n",
            "Epoch: 99 | Batch_idx: 0 |  Loss: (0.0067) | Acc: (100.00%) (128/128)\n",
            "Epoch: 99 | Batch_idx: 10 |  Loss: (0.0126) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 99 | Batch_idx: 20 |  Loss: (0.0145) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 99 | Batch_idx: 30 |  Loss: (0.0141) | Acc: (99.60%) (3952/3968)\n",
            "Epoch: 99 | Batch_idx: 40 |  Loss: (0.0130) | Acc: (99.68%) (5231/5248)\n",
            "Epoch: 99 | Batch_idx: 50 |  Loss: (0.0135) | Acc: (99.66%) (6506/6528)\n",
            "Epoch: 99 | Batch_idx: 60 |  Loss: (0.0133) | Acc: (99.68%) (7783/7808)\n",
            "Epoch: 99 | Batch_idx: 70 |  Loss: (0.0147) | Acc: (99.63%) (9054/9088)\n",
            "Epoch: 99 | Batch_idx: 80 |  Loss: (0.0148) | Acc: (99.60%) (10327/10368)\n",
            "Epoch: 99 | Batch_idx: 90 |  Loss: (0.0148) | Acc: (99.59%) (11600/11648)\n",
            "Epoch: 99 | Batch_idx: 100 |  Loss: (0.0146) | Acc: (99.59%) (12875/12928)\n",
            "Epoch: 99 | Batch_idx: 110 |  Loss: (0.0146) | Acc: (99.60%) (14151/14208)\n",
            "Epoch: 99 | Batch_idx: 120 |  Loss: (0.0145) | Acc: (99.60%) (15426/15488)\n",
            "Epoch: 99 | Batch_idx: 130 |  Loss: (0.0144) | Acc: (99.61%) (16702/16768)\n",
            "Epoch: 99 | Batch_idx: 140 |  Loss: (0.0146) | Acc: (99.60%) (17975/18048)\n",
            "Epoch: 99 | Batch_idx: 150 |  Loss: (0.0150) | Acc: (99.56%) (19243/19328)\n",
            "Epoch: 99 | Batch_idx: 160 |  Loss: (0.0150) | Acc: (99.55%) (20516/20608)\n",
            "Epoch: 99 | Batch_idx: 170 |  Loss: (0.0147) | Acc: (99.58%) (21795/21888)\n",
            "Epoch: 99 | Batch_idx: 180 |  Loss: (0.0145) | Acc: (99.59%) (23072/23168)\n",
            "Epoch: 99 | Batch_idx: 190 |  Loss: (0.0145) | Acc: (99.59%) (24347/24448)\n",
            "Epoch: 99 | Batch_idx: 200 |  Loss: (0.0148) | Acc: (99.58%) (25621/25728)\n",
            "Epoch: 99 | Batch_idx: 210 |  Loss: (0.0150) | Acc: (99.57%) (26892/27008)\n",
            "Epoch: 99 | Batch_idx: 220 |  Loss: (0.0150) | Acc: (99.58%) (28168/28288)\n",
            "Epoch: 99 | Batch_idx: 230 |  Loss: (0.0152) | Acc: (99.57%) (29442/29568)\n",
            "Epoch: 99 | Batch_idx: 240 |  Loss: (0.0151) | Acc: (99.59%) (30720/30848)\n",
            "Epoch: 99 | Batch_idx: 250 |  Loss: (0.0152) | Acc: (99.59%) (31995/32128)\n",
            "Epoch: 99 | Batch_idx: 260 |  Loss: (0.0151) | Acc: (99.60%) (33273/33408)\n",
            "Epoch: 99 | Batch_idx: 270 |  Loss: (0.0151) | Acc: (99.60%) (34548/34688)\n",
            "Epoch: 99 | Batch_idx: 280 |  Loss: (0.0151) | Acc: (99.59%) (35822/35968)\n",
            "Epoch: 99 | Batch_idx: 290 |  Loss: (0.0152) | Acc: (99.60%) (37099/37248)\n",
            "Epoch: 99 | Batch_idx: 300 |  Loss: (0.0151) | Acc: (99.60%) (38374/38528)\n",
            "Epoch: 99 | Batch_idx: 310 |  Loss: (0.0149) | Acc: (99.61%) (39652/39808)\n",
            "Epoch: 99 | Batch_idx: 320 |  Loss: (0.0148) | Acc: (99.62%) (40931/41088)\n",
            "Epoch: 99 | Batch_idx: 330 |  Loss: (0.0148) | Acc: (99.62%) (42206/42368)\n",
            "Epoch: 99 | Batch_idx: 340 |  Loss: (0.0147) | Acc: (99.62%) (43483/43648)\n",
            "Epoch: 99 | Batch_idx: 350 |  Loss: (0.0147) | Acc: (99.61%) (44754/44928)\n",
            "Epoch: 99 | Batch_idx: 360 |  Loss: (0.0148) | Acc: (99.61%) (46028/46208)\n",
            "Epoch: 99 | Batch_idx: 370 |  Loss: (0.0147) | Acc: (99.61%) (47304/47488)\n",
            "Epoch: 99 | Batch_idx: 380 |  Loss: (0.0147) | Acc: (99.61%) (48579/48768)\n",
            "Epoch: 99 | Batch_idx: 390 |  Loss: (0.0146) | Acc: (99.61%) (49805/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3285) | Acc: (92.32%) (9232/10000)\n",
            "Epoch: 100 | Batch_idx: 0 |  Loss: (0.0121) | Acc: (100.00%) (128/128)\n",
            "Epoch: 100 | Batch_idx: 10 |  Loss: (0.0150) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 100 | Batch_idx: 20 |  Loss: (0.0174) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 100 | Batch_idx: 30 |  Loss: (0.0158) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 100 | Batch_idx: 40 |  Loss: (0.0145) | Acc: (99.68%) (5231/5248)\n",
            "Epoch: 100 | Batch_idx: 50 |  Loss: (0.0147) | Acc: (99.65%) (6505/6528)\n",
            "Epoch: 100 | Batch_idx: 60 |  Loss: (0.0141) | Acc: (99.68%) (7783/7808)\n",
            "Epoch: 100 | Batch_idx: 70 |  Loss: (0.0136) | Acc: (99.69%) (9060/9088)\n",
            "Epoch: 100 | Batch_idx: 80 |  Loss: (0.0138) | Acc: (99.67%) (10334/10368)\n",
            "Epoch: 100 | Batch_idx: 90 |  Loss: (0.0133) | Acc: (99.70%) (11613/11648)\n",
            "Epoch: 100 | Batch_idx: 100 |  Loss: (0.0133) | Acc: (99.71%) (12890/12928)\n",
            "Epoch: 100 | Batch_idx: 110 |  Loss: (0.0131) | Acc: (99.70%) (14166/14208)\n",
            "Epoch: 100 | Batch_idx: 120 |  Loss: (0.0128) | Acc: (99.71%) (15443/15488)\n",
            "Epoch: 100 | Batch_idx: 130 |  Loss: (0.0132) | Acc: (99.68%) (16714/16768)\n",
            "Epoch: 100 | Batch_idx: 140 |  Loss: (0.0134) | Acc: (99.68%) (17991/18048)\n",
            "Epoch: 100 | Batch_idx: 150 |  Loss: (0.0131) | Acc: (99.69%) (19269/19328)\n",
            "Epoch: 100 | Batch_idx: 160 |  Loss: (0.0132) | Acc: (99.68%) (20543/20608)\n",
            "Epoch: 100 | Batch_idx: 170 |  Loss: (0.0134) | Acc: (99.67%) (21816/21888)\n",
            "Epoch: 100 | Batch_idx: 180 |  Loss: (0.0134) | Acc: (99.68%) (23093/23168)\n",
            "Epoch: 100 | Batch_idx: 190 |  Loss: (0.0137) | Acc: (99.67%) (24367/24448)\n",
            "Epoch: 100 | Batch_idx: 200 |  Loss: (0.0142) | Acc: (99.63%) (25634/25728)\n",
            "Epoch: 100 | Batch_idx: 210 |  Loss: (0.0143) | Acc: (99.64%) (26910/27008)\n",
            "Epoch: 100 | Batch_idx: 220 |  Loss: (0.0143) | Acc: (99.64%) (28186/28288)\n",
            "Epoch: 100 | Batch_idx: 230 |  Loss: (0.0143) | Acc: (99.64%) (29463/29568)\n",
            "Epoch: 100 | Batch_idx: 240 |  Loss: (0.0141) | Acc: (99.65%) (30740/30848)\n",
            "Epoch: 100 | Batch_idx: 250 |  Loss: (0.0142) | Acc: (99.64%) (32013/32128)\n",
            "Epoch: 100 | Batch_idx: 260 |  Loss: (0.0142) | Acc: (99.64%) (33289/33408)\n",
            "Epoch: 100 | Batch_idx: 270 |  Loss: (0.0144) | Acc: (99.63%) (34561/34688)\n",
            "Epoch: 100 | Batch_idx: 280 |  Loss: (0.0144) | Acc: (99.62%) (35833/35968)\n",
            "Epoch: 100 | Batch_idx: 290 |  Loss: (0.0141) | Acc: (99.64%) (37113/37248)\n",
            "Epoch: 100 | Batch_idx: 300 |  Loss: (0.0142) | Acc: (99.63%) (38384/38528)\n",
            "Epoch: 100 | Batch_idx: 310 |  Loss: (0.0143) | Acc: (99.63%) (39659/39808)\n",
            "Epoch: 100 | Batch_idx: 320 |  Loss: (0.0143) | Acc: (99.63%) (40934/41088)\n",
            "Epoch: 100 | Batch_idx: 330 |  Loss: (0.0144) | Acc: (99.62%) (42208/42368)\n",
            "Epoch: 100 | Batch_idx: 340 |  Loss: (0.0145) | Acc: (99.61%) (43479/43648)\n",
            "Epoch: 100 | Batch_idx: 350 |  Loss: (0.0145) | Acc: (99.61%) (44755/44928)\n",
            "Epoch: 100 | Batch_idx: 360 |  Loss: (0.0144) | Acc: (99.62%) (46034/46208)\n",
            "Epoch: 100 | Batch_idx: 370 |  Loss: (0.0143) | Acc: (99.63%) (47311/47488)\n",
            "Epoch: 100 | Batch_idx: 380 |  Loss: (0.0143) | Acc: (99.63%) (48587/48768)\n",
            "Epoch: 100 | Batch_idx: 390 |  Loss: (0.0144) | Acc: (99.62%) (49811/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3432) | Acc: (92.33%) (9233/10000)\n",
            "Epoch: 101 | Batch_idx: 0 |  Loss: (0.0069) | Acc: (100.00%) (128/128)\n",
            "Epoch: 101 | Batch_idx: 10 |  Loss: (0.0092) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 101 | Batch_idx: 20 |  Loss: (0.0121) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 101 | Batch_idx: 30 |  Loss: (0.0122) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 101 | Batch_idx: 40 |  Loss: (0.0130) | Acc: (99.68%) (5231/5248)\n",
            "Epoch: 101 | Batch_idx: 50 |  Loss: (0.0145) | Acc: (99.63%) (6504/6528)\n",
            "Epoch: 101 | Batch_idx: 60 |  Loss: (0.0137) | Acc: (99.67%) (7782/7808)\n",
            "Epoch: 101 | Batch_idx: 70 |  Loss: (0.0140) | Acc: (99.65%) (9056/9088)\n",
            "Epoch: 101 | Batch_idx: 80 |  Loss: (0.0137) | Acc: (99.67%) (10334/10368)\n",
            "Epoch: 101 | Batch_idx: 90 |  Loss: (0.0136) | Acc: (99.66%) (11608/11648)\n",
            "Epoch: 101 | Batch_idx: 100 |  Loss: (0.0135) | Acc: (99.66%) (12884/12928)\n",
            "Epoch: 101 | Batch_idx: 110 |  Loss: (0.0136) | Acc: (99.66%) (14159/14208)\n",
            "Epoch: 101 | Batch_idx: 120 |  Loss: (0.0134) | Acc: (99.66%) (15436/15488)\n",
            "Epoch: 101 | Batch_idx: 130 |  Loss: (0.0141) | Acc: (99.64%) (16707/16768)\n",
            "Epoch: 101 | Batch_idx: 140 |  Loss: (0.0142) | Acc: (99.64%) (17983/18048)\n",
            "Epoch: 101 | Batch_idx: 150 |  Loss: (0.0141) | Acc: (99.64%) (19259/19328)\n",
            "Epoch: 101 | Batch_idx: 160 |  Loss: (0.0143) | Acc: (99.63%) (20531/20608)\n",
            "Epoch: 101 | Batch_idx: 170 |  Loss: (0.0139) | Acc: (99.65%) (21811/21888)\n",
            "Epoch: 101 | Batch_idx: 180 |  Loss: (0.0136) | Acc: (99.66%) (23090/23168)\n",
            "Epoch: 101 | Batch_idx: 190 |  Loss: (0.0138) | Acc: (99.64%) (24360/24448)\n",
            "Epoch: 101 | Batch_idx: 200 |  Loss: (0.0137) | Acc: (99.64%) (25635/25728)\n",
            "Epoch: 101 | Batch_idx: 210 |  Loss: (0.0136) | Acc: (99.64%) (26912/27008)\n",
            "Epoch: 101 | Batch_idx: 220 |  Loss: (0.0135) | Acc: (99.65%) (28188/28288)\n",
            "Epoch: 101 | Batch_idx: 230 |  Loss: (0.0135) | Acc: (99.65%) (29464/29568)\n",
            "Epoch: 101 | Batch_idx: 240 |  Loss: (0.0135) | Acc: (99.64%) (30737/30848)\n",
            "Epoch: 101 | Batch_idx: 250 |  Loss: (0.0135) | Acc: (99.64%) (32012/32128)\n",
            "Epoch: 101 | Batch_idx: 260 |  Loss: (0.0139) | Acc: (99.62%) (33281/33408)\n",
            "Epoch: 101 | Batch_idx: 270 |  Loss: (0.0139) | Acc: (99.62%) (34556/34688)\n",
            "Epoch: 101 | Batch_idx: 280 |  Loss: (0.0137) | Acc: (99.62%) (35832/35968)\n",
            "Epoch: 101 | Batch_idx: 290 |  Loss: (0.0137) | Acc: (99.62%) (37107/37248)\n",
            "Epoch: 101 | Batch_idx: 300 |  Loss: (0.0138) | Acc: (99.62%) (38380/38528)\n",
            "Epoch: 101 | Batch_idx: 310 |  Loss: (0.0138) | Acc: (99.61%) (39653/39808)\n",
            "Epoch: 101 | Batch_idx: 320 |  Loss: (0.0139) | Acc: (99.61%) (40928/41088)\n",
            "Epoch: 101 | Batch_idx: 330 |  Loss: (0.0139) | Acc: (99.61%) (42201/42368)\n",
            "Epoch: 101 | Batch_idx: 340 |  Loss: (0.0138) | Acc: (99.61%) (43477/43648)\n",
            "Epoch: 101 | Batch_idx: 350 |  Loss: (0.0139) | Acc: (99.60%) (44749/44928)\n",
            "Epoch: 101 | Batch_idx: 360 |  Loss: (0.0141) | Acc: (99.60%) (46022/46208)\n",
            "Epoch: 101 | Batch_idx: 370 |  Loss: (0.0143) | Acc: (99.59%) (47291/47488)\n",
            "Epoch: 101 | Batch_idx: 380 |  Loss: (0.0146) | Acc: (99.58%) (48562/48768)\n",
            "Epoch: 101 | Batch_idx: 390 |  Loss: (0.0146) | Acc: (99.58%) (49788/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3367) | Acc: (92.43%) (9243/10000)\n",
            "Epoch: 102 | Batch_idx: 0 |  Loss: (0.0108) | Acc: (100.00%) (128/128)\n",
            "Epoch: 102 | Batch_idx: 10 |  Loss: (0.0131) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 102 | Batch_idx: 20 |  Loss: (0.0144) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 102 | Batch_idx: 30 |  Loss: (0.0141) | Acc: (99.55%) (3950/3968)\n",
            "Epoch: 102 | Batch_idx: 40 |  Loss: (0.0130) | Acc: (99.58%) (5226/5248)\n",
            "Epoch: 102 | Batch_idx: 50 |  Loss: (0.0139) | Acc: (99.56%) (6499/6528)\n",
            "Epoch: 102 | Batch_idx: 60 |  Loss: (0.0132) | Acc: (99.60%) (7777/7808)\n",
            "Epoch: 102 | Batch_idx: 70 |  Loss: (0.0133) | Acc: (99.57%) (9049/9088)\n",
            "Epoch: 102 | Batch_idx: 80 |  Loss: (0.0141) | Acc: (99.56%) (10322/10368)\n",
            "Epoch: 102 | Batch_idx: 90 |  Loss: (0.0140) | Acc: (99.57%) (11598/11648)\n",
            "Epoch: 102 | Batch_idx: 100 |  Loss: (0.0136) | Acc: (99.57%) (12873/12928)\n",
            "Epoch: 102 | Batch_idx: 110 |  Loss: (0.0136) | Acc: (99.56%) (14145/14208)\n",
            "Epoch: 102 | Batch_idx: 120 |  Loss: (0.0134) | Acc: (99.57%) (15421/15488)\n",
            "Epoch: 102 | Batch_idx: 130 |  Loss: (0.0135) | Acc: (99.56%) (16695/16768)\n",
            "Epoch: 102 | Batch_idx: 140 |  Loss: (0.0139) | Acc: (99.56%) (17969/18048)\n",
            "Epoch: 102 | Batch_idx: 150 |  Loss: (0.0139) | Acc: (99.56%) (19242/19328)\n",
            "Epoch: 102 | Batch_idx: 160 |  Loss: (0.0137) | Acc: (99.56%) (20517/20608)\n",
            "Epoch: 102 | Batch_idx: 170 |  Loss: (0.0137) | Acc: (99.57%) (21793/21888)\n",
            "Epoch: 102 | Batch_idx: 180 |  Loss: (0.0138) | Acc: (99.55%) (23064/23168)\n",
            "Epoch: 102 | Batch_idx: 190 |  Loss: (0.0137) | Acc: (99.57%) (24342/24448)\n",
            "Epoch: 102 | Batch_idx: 200 |  Loss: (0.0137) | Acc: (99.57%) (25617/25728)\n",
            "Epoch: 102 | Batch_idx: 210 |  Loss: (0.0137) | Acc: (99.58%) (26895/27008)\n",
            "Epoch: 102 | Batch_idx: 220 |  Loss: (0.0140) | Acc: (99.57%) (28166/28288)\n",
            "Epoch: 102 | Batch_idx: 230 |  Loss: (0.0139) | Acc: (99.58%) (29444/29568)\n",
            "Epoch: 102 | Batch_idx: 240 |  Loss: (0.0137) | Acc: (99.59%) (30721/30848)\n",
            "Epoch: 102 | Batch_idx: 250 |  Loss: (0.0137) | Acc: (99.59%) (31997/32128)\n",
            "Epoch: 102 | Batch_idx: 260 |  Loss: (0.0138) | Acc: (99.59%) (33270/33408)\n",
            "Epoch: 102 | Batch_idx: 270 |  Loss: (0.0137) | Acc: (99.59%) (34547/34688)\n",
            "Epoch: 102 | Batch_idx: 280 |  Loss: (0.0136) | Acc: (99.61%) (35826/35968)\n",
            "Epoch: 102 | Batch_idx: 290 |  Loss: (0.0135) | Acc: (99.61%) (37102/37248)\n",
            "Epoch: 102 | Batch_idx: 300 |  Loss: (0.0135) | Acc: (99.61%) (38377/38528)\n",
            "Epoch: 102 | Batch_idx: 310 |  Loss: (0.0135) | Acc: (99.60%) (39649/39808)\n",
            "Epoch: 102 | Batch_idx: 320 |  Loss: (0.0136) | Acc: (99.60%) (40923/41088)\n",
            "Epoch: 102 | Batch_idx: 330 |  Loss: (0.0135) | Acc: (99.61%) (42201/42368)\n",
            "Epoch: 102 | Batch_idx: 340 |  Loss: (0.0134) | Acc: (99.61%) (43476/43648)\n",
            "Epoch: 102 | Batch_idx: 350 |  Loss: (0.0133) | Acc: (99.61%) (44754/44928)\n",
            "Epoch: 102 | Batch_idx: 360 |  Loss: (0.0134) | Acc: (99.61%) (46030/46208)\n",
            "Epoch: 102 | Batch_idx: 370 |  Loss: (0.0133) | Acc: (99.62%) (47306/47488)\n",
            "Epoch: 102 | Batch_idx: 380 |  Loss: (0.0134) | Acc: (99.61%) (48577/48768)\n",
            "Epoch: 102 | Batch_idx: 390 |  Loss: (0.0134) | Acc: (99.61%) (49806/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3481) | Acc: (92.24%) (9224/10000)\n",
            "Epoch: 103 | Batch_idx: 0 |  Loss: (0.0056) | Acc: (100.00%) (128/128)\n",
            "Epoch: 103 | Batch_idx: 10 |  Loss: (0.0108) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 103 | Batch_idx: 20 |  Loss: (0.0120) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 103 | Batch_idx: 30 |  Loss: (0.0126) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 103 | Batch_idx: 40 |  Loss: (0.0130) | Acc: (99.60%) (5227/5248)\n",
            "Epoch: 103 | Batch_idx: 50 |  Loss: (0.0130) | Acc: (99.60%) (6502/6528)\n",
            "Epoch: 103 | Batch_idx: 60 |  Loss: (0.0141) | Acc: (99.54%) (7772/7808)\n",
            "Epoch: 103 | Batch_idx: 70 |  Loss: (0.0136) | Acc: (99.56%) (9048/9088)\n",
            "Epoch: 103 | Batch_idx: 80 |  Loss: (0.0132) | Acc: (99.59%) (10326/10368)\n",
            "Epoch: 103 | Batch_idx: 90 |  Loss: (0.0136) | Acc: (99.60%) (11601/11648)\n",
            "Epoch: 103 | Batch_idx: 100 |  Loss: (0.0135) | Acc: (99.61%) (12878/12928)\n",
            "Epoch: 103 | Batch_idx: 110 |  Loss: (0.0134) | Acc: (99.62%) (14154/14208)\n",
            "Epoch: 103 | Batch_idx: 120 |  Loss: (0.0142) | Acc: (99.61%) (15427/15488)\n",
            "Epoch: 103 | Batch_idx: 130 |  Loss: (0.0140) | Acc: (99.61%) (16703/16768)\n",
            "Epoch: 103 | Batch_idx: 140 |  Loss: (0.0141) | Acc: (99.61%) (17977/18048)\n",
            "Epoch: 103 | Batch_idx: 150 |  Loss: (0.0142) | Acc: (99.61%) (19252/19328)\n",
            "Epoch: 103 | Batch_idx: 160 |  Loss: (0.0144) | Acc: (99.60%) (20525/20608)\n",
            "Epoch: 103 | Batch_idx: 170 |  Loss: (0.0145) | Acc: (99.59%) (21799/21888)\n",
            "Epoch: 103 | Batch_idx: 180 |  Loss: (0.0144) | Acc: (99.59%) (23074/23168)\n",
            "Epoch: 103 | Batch_idx: 190 |  Loss: (0.0145) | Acc: (99.60%) (24349/24448)\n",
            "Epoch: 103 | Batch_idx: 200 |  Loss: (0.0146) | Acc: (99.60%) (25624/25728)\n",
            "Epoch: 103 | Batch_idx: 210 |  Loss: (0.0146) | Acc: (99.59%) (26898/27008)\n",
            "Epoch: 103 | Batch_idx: 220 |  Loss: (0.0144) | Acc: (99.60%) (28176/28288)\n",
            "Epoch: 103 | Batch_idx: 230 |  Loss: (0.0143) | Acc: (99.61%) (29454/29568)\n",
            "Epoch: 103 | Batch_idx: 240 |  Loss: (0.0145) | Acc: (99.61%) (30729/30848)\n",
            "Epoch: 103 | Batch_idx: 250 |  Loss: (0.0143) | Acc: (99.62%) (32007/32128)\n",
            "Epoch: 103 | Batch_idx: 260 |  Loss: (0.0141) | Acc: (99.63%) (33285/33408)\n",
            "Epoch: 103 | Batch_idx: 270 |  Loss: (0.0141) | Acc: (99.64%) (34562/34688)\n",
            "Epoch: 103 | Batch_idx: 280 |  Loss: (0.0141) | Acc: (99.63%) (35836/35968)\n",
            "Epoch: 103 | Batch_idx: 290 |  Loss: (0.0142) | Acc: (99.62%) (37108/37248)\n",
            "Epoch: 103 | Batch_idx: 300 |  Loss: (0.0142) | Acc: (99.63%) (38385/38528)\n",
            "Epoch: 103 | Batch_idx: 310 |  Loss: (0.0142) | Acc: (99.63%) (39660/39808)\n",
            "Epoch: 103 | Batch_idx: 320 |  Loss: (0.0143) | Acc: (99.63%) (40935/41088)\n",
            "Epoch: 103 | Batch_idx: 330 |  Loss: (0.0141) | Acc: (99.63%) (42211/42368)\n",
            "Epoch: 103 | Batch_idx: 340 |  Loss: (0.0141) | Acc: (99.63%) (43487/43648)\n",
            "Epoch: 103 | Batch_idx: 350 |  Loss: (0.0140) | Acc: (99.64%) (44766/44928)\n",
            "Epoch: 103 | Batch_idx: 360 |  Loss: (0.0140) | Acc: (99.63%) (46039/46208)\n",
            "Epoch: 103 | Batch_idx: 370 |  Loss: (0.0139) | Acc: (99.63%) (47313/47488)\n",
            "Epoch: 103 | Batch_idx: 380 |  Loss: (0.0138) | Acc: (99.64%) (48591/48768)\n",
            "Epoch: 103 | Batch_idx: 390 |  Loss: (0.0137) | Acc: (99.64%) (49820/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3402) | Acc: (92.42%) (9242/10000)\n",
            "Epoch: 104 | Batch_idx: 0 |  Loss: (0.0140) | Acc: (99.22%) (127/128)\n",
            "Epoch: 104 | Batch_idx: 10 |  Loss: (0.0087) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 104 | Batch_idx: 20 |  Loss: (0.0104) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 104 | Batch_idx: 30 |  Loss: (0.0102) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 104 | Batch_idx: 40 |  Loss: (0.0103) | Acc: (99.73%) (5234/5248)\n",
            "Epoch: 104 | Batch_idx: 50 |  Loss: (0.0118) | Acc: (99.68%) (6507/6528)\n",
            "Epoch: 104 | Batch_idx: 60 |  Loss: (0.0125) | Acc: (99.67%) (7782/7808)\n",
            "Epoch: 104 | Batch_idx: 70 |  Loss: (0.0125) | Acc: (99.65%) (9056/9088)\n",
            "Epoch: 104 | Batch_idx: 80 |  Loss: (0.0125) | Acc: (99.65%) (10332/10368)\n",
            "Epoch: 104 | Batch_idx: 90 |  Loss: (0.0123) | Acc: (99.66%) (11608/11648)\n",
            "Epoch: 104 | Batch_idx: 100 |  Loss: (0.0130) | Acc: (99.62%) (12879/12928)\n",
            "Epoch: 104 | Batch_idx: 110 |  Loss: (0.0132) | Acc: (99.61%) (14153/14208)\n",
            "Epoch: 104 | Batch_idx: 120 |  Loss: (0.0130) | Acc: (99.63%) (15430/15488)\n",
            "Epoch: 104 | Batch_idx: 130 |  Loss: (0.0136) | Acc: (99.62%) (16704/16768)\n",
            "Epoch: 104 | Batch_idx: 140 |  Loss: (0.0136) | Acc: (99.62%) (17979/18048)\n",
            "Epoch: 104 | Batch_idx: 150 |  Loss: (0.0139) | Acc: (99.60%) (19251/19328)\n",
            "Epoch: 104 | Batch_idx: 160 |  Loss: (0.0139) | Acc: (99.60%) (20525/20608)\n",
            "Epoch: 104 | Batch_idx: 170 |  Loss: (0.0139) | Acc: (99.60%) (21801/21888)\n",
            "Epoch: 104 | Batch_idx: 180 |  Loss: (0.0144) | Acc: (99.58%) (23070/23168)\n",
            "Epoch: 104 | Batch_idx: 190 |  Loss: (0.0147) | Acc: (99.56%) (24341/24448)\n",
            "Epoch: 104 | Batch_idx: 200 |  Loss: (0.0148) | Acc: (99.56%) (25615/25728)\n",
            "Epoch: 104 | Batch_idx: 210 |  Loss: (0.0147) | Acc: (99.57%) (26892/27008)\n",
            "Epoch: 104 | Batch_idx: 220 |  Loss: (0.0145) | Acc: (99.58%) (28170/28288)\n",
            "Epoch: 104 | Batch_idx: 230 |  Loss: (0.0144) | Acc: (99.59%) (29446/29568)\n",
            "Epoch: 104 | Batch_idx: 240 |  Loss: (0.0145) | Acc: (99.58%) (30719/30848)\n",
            "Epoch: 104 | Batch_idx: 250 |  Loss: (0.0144) | Acc: (99.59%) (31996/32128)\n",
            "Epoch: 104 | Batch_idx: 260 |  Loss: (0.0143) | Acc: (99.59%) (33272/33408)\n",
            "Epoch: 104 | Batch_idx: 270 |  Loss: (0.0143) | Acc: (99.59%) (34547/34688)\n",
            "Epoch: 104 | Batch_idx: 280 |  Loss: (0.0144) | Acc: (99.59%) (35820/35968)\n",
            "Epoch: 104 | Batch_idx: 290 |  Loss: (0.0143) | Acc: (99.59%) (37095/37248)\n",
            "Epoch: 104 | Batch_idx: 300 |  Loss: (0.0144) | Acc: (99.58%) (38368/38528)\n",
            "Epoch: 104 | Batch_idx: 310 |  Loss: (0.0144) | Acc: (99.59%) (39643/39808)\n",
            "Epoch: 104 | Batch_idx: 320 |  Loss: (0.0143) | Acc: (99.59%) (40920/41088)\n",
            "Epoch: 104 | Batch_idx: 330 |  Loss: (0.0143) | Acc: (99.58%) (42189/42368)\n",
            "Epoch: 104 | Batch_idx: 340 |  Loss: (0.0143) | Acc: (99.58%) (43465/43648)\n",
            "Epoch: 104 | Batch_idx: 350 |  Loss: (0.0142) | Acc: (99.59%) (44743/44928)\n",
            "Epoch: 104 | Batch_idx: 360 |  Loss: (0.0141) | Acc: (99.59%) (46019/46208)\n",
            "Epoch: 104 | Batch_idx: 370 |  Loss: (0.0141) | Acc: (99.59%) (47295/47488)\n",
            "Epoch: 104 | Batch_idx: 380 |  Loss: (0.0141) | Acc: (99.59%) (48570/48768)\n",
            "Epoch: 104 | Batch_idx: 390 |  Loss: (0.0142) | Acc: (99.59%) (49795/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3473) | Acc: (92.32%) (9232/10000)\n",
            "Epoch: 105 | Batch_idx: 0 |  Loss: (0.0210) | Acc: (99.22%) (127/128)\n",
            "Epoch: 105 | Batch_idx: 10 |  Loss: (0.0152) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 105 | Batch_idx: 20 |  Loss: (0.0118) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 105 | Batch_idx: 30 |  Loss: (0.0130) | Acc: (99.67%) (3955/3968)\n",
            "Epoch: 105 | Batch_idx: 40 |  Loss: (0.0124) | Acc: (99.70%) (5232/5248)\n",
            "Epoch: 105 | Batch_idx: 50 |  Loss: (0.0131) | Acc: (99.68%) (6507/6528)\n",
            "Epoch: 105 | Batch_idx: 60 |  Loss: (0.0129) | Acc: (99.68%) (7783/7808)\n",
            "Epoch: 105 | Batch_idx: 70 |  Loss: (0.0127) | Acc: (99.67%) (9058/9088)\n",
            "Epoch: 105 | Batch_idx: 80 |  Loss: (0.0135) | Acc: (99.63%) (10330/10368)\n",
            "Epoch: 105 | Batch_idx: 90 |  Loss: (0.0135) | Acc: (99.61%) (11603/11648)\n",
            "Epoch: 105 | Batch_idx: 100 |  Loss: (0.0130) | Acc: (99.64%) (12881/12928)\n",
            "Epoch: 105 | Batch_idx: 110 |  Loss: (0.0128) | Acc: (99.66%) (14159/14208)\n",
            "Epoch: 105 | Batch_idx: 120 |  Loss: (0.0124) | Acc: (99.67%) (15437/15488)\n",
            "Epoch: 105 | Batch_idx: 130 |  Loss: (0.0126) | Acc: (99.67%) (16713/16768)\n",
            "Epoch: 105 | Batch_idx: 140 |  Loss: (0.0125) | Acc: (99.68%) (17990/18048)\n",
            "Epoch: 105 | Batch_idx: 150 |  Loss: (0.0125) | Acc: (99.68%) (19267/19328)\n",
            "Epoch: 105 | Batch_idx: 160 |  Loss: (0.0123) | Acc: (99.69%) (20545/20608)\n",
            "Epoch: 105 | Batch_idx: 170 |  Loss: (0.0121) | Acc: (99.70%) (21823/21888)\n",
            "Epoch: 105 | Batch_idx: 180 |  Loss: (0.0123) | Acc: (99.69%) (23096/23168)\n",
            "Epoch: 105 | Batch_idx: 190 |  Loss: (0.0123) | Acc: (99.69%) (24371/24448)\n",
            "Epoch: 105 | Batch_idx: 200 |  Loss: (0.0123) | Acc: (99.69%) (25648/25728)\n",
            "Epoch: 105 | Batch_idx: 210 |  Loss: (0.0126) | Acc: (99.67%) (26918/27008)\n",
            "Epoch: 105 | Batch_idx: 220 |  Loss: (0.0125) | Acc: (99.67%) (28194/28288)\n",
            "Epoch: 105 | Batch_idx: 230 |  Loss: (0.0126) | Acc: (99.66%) (29467/29568)\n",
            "Epoch: 105 | Batch_idx: 240 |  Loss: (0.0128) | Acc: (99.66%) (30742/30848)\n",
            "Epoch: 105 | Batch_idx: 250 |  Loss: (0.0129) | Acc: (99.66%) (32018/32128)\n",
            "Epoch: 105 | Batch_idx: 260 |  Loss: (0.0132) | Acc: (99.64%) (33289/33408)\n",
            "Epoch: 105 | Batch_idx: 270 |  Loss: (0.0131) | Acc: (99.65%) (34567/34688)\n",
            "Epoch: 105 | Batch_idx: 280 |  Loss: (0.0130) | Acc: (99.65%) (35841/35968)\n",
            "Epoch: 105 | Batch_idx: 290 |  Loss: (0.0130) | Acc: (99.65%) (37118/37248)\n",
            "Epoch: 105 | Batch_idx: 300 |  Loss: (0.0129) | Acc: (99.65%) (38393/38528)\n",
            "Epoch: 105 | Batch_idx: 310 |  Loss: (0.0128) | Acc: (99.66%) (39671/39808)\n",
            "Epoch: 105 | Batch_idx: 320 |  Loss: (0.0127) | Acc: (99.66%) (40947/41088)\n",
            "Epoch: 105 | Batch_idx: 330 |  Loss: (0.0126) | Acc: (99.66%) (42226/42368)\n",
            "Epoch: 105 | Batch_idx: 340 |  Loss: (0.0127) | Acc: (99.66%) (43500/43648)\n",
            "Epoch: 105 | Batch_idx: 350 |  Loss: (0.0127) | Acc: (99.66%) (44776/44928)\n",
            "Epoch: 105 | Batch_idx: 360 |  Loss: (0.0127) | Acc: (99.66%) (46050/46208)\n",
            "Epoch: 105 | Batch_idx: 370 |  Loss: (0.0126) | Acc: (99.66%) (47328/47488)\n",
            "Epoch: 105 | Batch_idx: 380 |  Loss: (0.0127) | Acc: (99.66%) (48602/48768)\n",
            "Epoch: 105 | Batch_idx: 390 |  Loss: (0.0126) | Acc: (99.66%) (49832/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3476) | Acc: (92.37%) (9237/10000)\n",
            "Epoch: 106 | Batch_idx: 0 |  Loss: (0.0104) | Acc: (100.00%) (128/128)\n",
            "Epoch: 106 | Batch_idx: 10 |  Loss: (0.0126) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 106 | Batch_idx: 20 |  Loss: (0.0141) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 106 | Batch_idx: 30 |  Loss: (0.0135) | Acc: (99.67%) (3955/3968)\n",
            "Epoch: 106 | Batch_idx: 40 |  Loss: (0.0125) | Acc: (99.71%) (5233/5248)\n",
            "Epoch: 106 | Batch_idx: 50 |  Loss: (0.0131) | Acc: (99.69%) (6508/6528)\n",
            "Epoch: 106 | Batch_idx: 60 |  Loss: (0.0124) | Acc: (99.72%) (7786/7808)\n",
            "Epoch: 106 | Batch_idx: 70 |  Loss: (0.0133) | Acc: (99.66%) (9057/9088)\n",
            "Epoch: 106 | Batch_idx: 80 |  Loss: (0.0134) | Acc: (99.64%) (10331/10368)\n",
            "Epoch: 106 | Batch_idx: 90 |  Loss: (0.0129) | Acc: (99.67%) (11609/11648)\n",
            "Epoch: 106 | Batch_idx: 100 |  Loss: (0.0131) | Acc: (99.67%) (12885/12928)\n",
            "Epoch: 106 | Batch_idx: 110 |  Loss: (0.0126) | Acc: (99.69%) (14164/14208)\n",
            "Epoch: 106 | Batch_idx: 120 |  Loss: (0.0124) | Acc: (99.71%) (15443/15488)\n",
            "Epoch: 106 | Batch_idx: 130 |  Loss: (0.0129) | Acc: (99.69%) (16716/16768)\n",
            "Epoch: 106 | Batch_idx: 140 |  Loss: (0.0126) | Acc: (99.70%) (17993/18048)\n",
            "Epoch: 106 | Batch_idx: 150 |  Loss: (0.0127) | Acc: (99.68%) (19267/19328)\n",
            "Epoch: 106 | Batch_idx: 160 |  Loss: (0.0129) | Acc: (99.67%) (20540/20608)\n",
            "Epoch: 106 | Batch_idx: 170 |  Loss: (0.0128) | Acc: (99.67%) (21816/21888)\n",
            "Epoch: 106 | Batch_idx: 180 |  Loss: (0.0127) | Acc: (99.67%) (23092/23168)\n",
            "Epoch: 106 | Batch_idx: 190 |  Loss: (0.0130) | Acc: (99.67%) (24367/24448)\n",
            "Epoch: 106 | Batch_idx: 200 |  Loss: (0.0128) | Acc: (99.67%) (25644/25728)\n",
            "Epoch: 106 | Batch_idx: 210 |  Loss: (0.0127) | Acc: (99.67%) (26919/27008)\n",
            "Epoch: 106 | Batch_idx: 220 |  Loss: (0.0127) | Acc: (99.67%) (28195/28288)\n",
            "Epoch: 106 | Batch_idx: 230 |  Loss: (0.0130) | Acc: (99.66%) (29468/29568)\n",
            "Epoch: 106 | Batch_idx: 240 |  Loss: (0.0129) | Acc: (99.67%) (30745/30848)\n",
            "Epoch: 106 | Batch_idx: 250 |  Loss: (0.0131) | Acc: (99.65%) (32016/32128)\n",
            "Epoch: 106 | Batch_idx: 260 |  Loss: (0.0132) | Acc: (99.65%) (33291/33408)\n",
            "Epoch: 106 | Batch_idx: 270 |  Loss: (0.0133) | Acc: (99.65%) (34565/34688)\n",
            "Epoch: 106 | Batch_idx: 280 |  Loss: (0.0132) | Acc: (99.65%) (35843/35968)\n",
            "Epoch: 106 | Batch_idx: 290 |  Loss: (0.0132) | Acc: (99.65%) (37118/37248)\n",
            "Epoch: 106 | Batch_idx: 300 |  Loss: (0.0131) | Acc: (99.66%) (38396/38528)\n",
            "Epoch: 106 | Batch_idx: 310 |  Loss: (0.0132) | Acc: (99.65%) (39669/39808)\n",
            "Epoch: 106 | Batch_idx: 320 |  Loss: (0.0133) | Acc: (99.64%) (40940/41088)\n",
            "Epoch: 106 | Batch_idx: 330 |  Loss: (0.0131) | Acc: (99.65%) (42219/42368)\n",
            "Epoch: 106 | Batch_idx: 340 |  Loss: (0.0133) | Acc: (99.64%) (43493/43648)\n",
            "Epoch: 106 | Batch_idx: 350 |  Loss: (0.0133) | Acc: (99.64%) (44768/44928)\n",
            "Epoch: 106 | Batch_idx: 360 |  Loss: (0.0133) | Acc: (99.64%) (46043/46208)\n",
            "Epoch: 106 | Batch_idx: 370 |  Loss: (0.0132) | Acc: (99.65%) (47321/47488)\n",
            "Epoch: 106 | Batch_idx: 380 |  Loss: (0.0131) | Acc: (99.66%) (48600/48768)\n",
            "Epoch: 106 | Batch_idx: 390 |  Loss: (0.0130) | Acc: (99.66%) (49830/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3443) | Acc: (92.33%) (9233/10000)\n",
            "Epoch: 107 | Batch_idx: 0 |  Loss: (0.0143) | Acc: (100.00%) (128/128)\n",
            "Epoch: 107 | Batch_idx: 10 |  Loss: (0.0189) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 107 | Batch_idx: 20 |  Loss: (0.0163) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 107 | Batch_idx: 30 |  Loss: (0.0169) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 107 | Batch_idx: 40 |  Loss: (0.0154) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 107 | Batch_idx: 50 |  Loss: (0.0146) | Acc: (99.57%) (6500/6528)\n",
            "Epoch: 107 | Batch_idx: 60 |  Loss: (0.0141) | Acc: (99.60%) (7777/7808)\n",
            "Epoch: 107 | Batch_idx: 70 |  Loss: (0.0135) | Acc: (99.64%) (9055/9088)\n",
            "Epoch: 107 | Batch_idx: 80 |  Loss: (0.0133) | Acc: (99.64%) (10331/10368)\n",
            "Epoch: 107 | Batch_idx: 90 |  Loss: (0.0136) | Acc: (99.65%) (11607/11648)\n",
            "Epoch: 107 | Batch_idx: 100 |  Loss: (0.0134) | Acc: (99.65%) (12883/12928)\n",
            "Epoch: 107 | Batch_idx: 110 |  Loss: (0.0135) | Acc: (99.64%) (14157/14208)\n",
            "Epoch: 107 | Batch_idx: 120 |  Loss: (0.0141) | Acc: (99.61%) (15428/15488)\n",
            "Epoch: 107 | Batch_idx: 130 |  Loss: (0.0139) | Acc: (99.62%) (16704/16768)\n",
            "Epoch: 107 | Batch_idx: 140 |  Loss: (0.0138) | Acc: (99.62%) (17980/18048)\n",
            "Epoch: 107 | Batch_idx: 150 |  Loss: (0.0139) | Acc: (99.61%) (19253/19328)\n",
            "Epoch: 107 | Batch_idx: 160 |  Loss: (0.0141) | Acc: (99.60%) (20526/20608)\n",
            "Epoch: 107 | Batch_idx: 170 |  Loss: (0.0141) | Acc: (99.60%) (21800/21888)\n",
            "Epoch: 107 | Batch_idx: 180 |  Loss: (0.0143) | Acc: (99.59%) (23072/23168)\n",
            "Epoch: 107 | Batch_idx: 190 |  Loss: (0.0139) | Acc: (99.60%) (24350/24448)\n",
            "Epoch: 107 | Batch_idx: 200 |  Loss: (0.0136) | Acc: (99.62%) (25630/25728)\n",
            "Epoch: 107 | Batch_idx: 210 |  Loss: (0.0136) | Acc: (99.61%) (26904/27008)\n",
            "Epoch: 107 | Batch_idx: 220 |  Loss: (0.0134) | Acc: (99.63%) (28182/28288)\n",
            "Epoch: 107 | Batch_idx: 230 |  Loss: (0.0134) | Acc: (99.62%) (29455/29568)\n",
            "Epoch: 107 | Batch_idx: 240 |  Loss: (0.0132) | Acc: (99.63%) (30735/30848)\n",
            "Epoch: 107 | Batch_idx: 250 |  Loss: (0.0131) | Acc: (99.64%) (32012/32128)\n",
            "Epoch: 107 | Batch_idx: 260 |  Loss: (0.0132) | Acc: (99.63%) (33283/33408)\n",
            "Epoch: 107 | Batch_idx: 270 |  Loss: (0.0130) | Acc: (99.63%) (34560/34688)\n",
            "Epoch: 107 | Batch_idx: 280 |  Loss: (0.0131) | Acc: (99.63%) (35836/35968)\n",
            "Epoch: 107 | Batch_idx: 290 |  Loss: (0.0130) | Acc: (99.64%) (37113/37248)\n",
            "Epoch: 107 | Batch_idx: 300 |  Loss: (0.0130) | Acc: (99.64%) (38388/38528)\n",
            "Epoch: 107 | Batch_idx: 310 |  Loss: (0.0130) | Acc: (99.64%) (39666/39808)\n",
            "Epoch: 107 | Batch_idx: 320 |  Loss: (0.0130) | Acc: (99.64%) (40940/41088)\n",
            "Epoch: 107 | Batch_idx: 330 |  Loss: (0.0131) | Acc: (99.63%) (42211/42368)\n",
            "Epoch: 107 | Batch_idx: 340 |  Loss: (0.0131) | Acc: (99.63%) (43486/43648)\n",
            "Epoch: 107 | Batch_idx: 350 |  Loss: (0.0132) | Acc: (99.62%) (44757/44928)\n",
            "Epoch: 107 | Batch_idx: 360 |  Loss: (0.0131) | Acc: (99.63%) (46035/46208)\n",
            "Epoch: 107 | Batch_idx: 370 |  Loss: (0.0130) | Acc: (99.63%) (47312/47488)\n",
            "Epoch: 107 | Batch_idx: 380 |  Loss: (0.0130) | Acc: (99.63%) (48589/48768)\n",
            "Epoch: 107 | Batch_idx: 390 |  Loss: (0.0130) | Acc: (99.64%) (49818/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3468) | Acc: (92.30%) (9230/10000)\n",
            "Epoch: 108 | Batch_idx: 0 |  Loss: (0.0020) | Acc: (100.00%) (128/128)\n",
            "Epoch: 108 | Batch_idx: 10 |  Loss: (0.0113) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 108 | Batch_idx: 20 |  Loss: (0.0116) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 108 | Batch_idx: 30 |  Loss: (0.0112) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 108 | Batch_idx: 40 |  Loss: (0.0106) | Acc: (99.73%) (5234/5248)\n",
            "Epoch: 108 | Batch_idx: 50 |  Loss: (0.0117) | Acc: (99.72%) (6510/6528)\n",
            "Epoch: 108 | Batch_idx: 60 |  Loss: (0.0117) | Acc: (99.74%) (7788/7808)\n",
            "Epoch: 108 | Batch_idx: 70 |  Loss: (0.0120) | Acc: (99.72%) (9063/9088)\n",
            "Epoch: 108 | Batch_idx: 80 |  Loss: (0.0121) | Acc: (99.72%) (10339/10368)\n",
            "Epoch: 108 | Batch_idx: 90 |  Loss: (0.0122) | Acc: (99.72%) (11615/11648)\n",
            "Epoch: 108 | Batch_idx: 100 |  Loss: (0.0122) | Acc: (99.71%) (12890/12928)\n",
            "Epoch: 108 | Batch_idx: 110 |  Loss: (0.0120) | Acc: (99.70%) (14165/14208)\n",
            "Epoch: 108 | Batch_idx: 120 |  Loss: (0.0116) | Acc: (99.72%) (15444/15488)\n",
            "Epoch: 108 | Batch_idx: 130 |  Loss: (0.0116) | Acc: (99.72%) (16721/16768)\n",
            "Epoch: 108 | Batch_idx: 140 |  Loss: (0.0113) | Acc: (99.73%) (18000/18048)\n",
            "Epoch: 108 | Batch_idx: 150 |  Loss: (0.0113) | Acc: (99.73%) (19275/19328)\n",
            "Epoch: 108 | Batch_idx: 160 |  Loss: (0.0113) | Acc: (99.73%) (20552/20608)\n",
            "Epoch: 108 | Batch_idx: 170 |  Loss: (0.0113) | Acc: (99.73%) (21829/21888)\n",
            "Epoch: 108 | Batch_idx: 180 |  Loss: (0.0111) | Acc: (99.74%) (23107/23168)\n",
            "Epoch: 108 | Batch_idx: 190 |  Loss: (0.0115) | Acc: (99.71%) (24378/24448)\n",
            "Epoch: 108 | Batch_idx: 200 |  Loss: (0.0112) | Acc: (99.72%) (25657/25728)\n",
            "Epoch: 108 | Batch_idx: 210 |  Loss: (0.0114) | Acc: (99.71%) (26931/27008)\n",
            "Epoch: 108 | Batch_idx: 220 |  Loss: (0.0113) | Acc: (99.72%) (28209/28288)\n",
            "Epoch: 108 | Batch_idx: 230 |  Loss: (0.0111) | Acc: (99.73%) (29488/29568)\n",
            "Epoch: 108 | Batch_idx: 240 |  Loss: (0.0113) | Acc: (99.72%) (30763/30848)\n",
            "Epoch: 108 | Batch_idx: 250 |  Loss: (0.0112) | Acc: (99.73%) (32041/32128)\n",
            "Epoch: 108 | Batch_idx: 260 |  Loss: (0.0111) | Acc: (99.73%) (33319/33408)\n",
            "Epoch: 108 | Batch_idx: 270 |  Loss: (0.0110) | Acc: (99.74%) (34597/34688)\n",
            "Epoch: 108 | Batch_idx: 280 |  Loss: (0.0110) | Acc: (99.74%) (35873/35968)\n",
            "Epoch: 108 | Batch_idx: 290 |  Loss: (0.0111) | Acc: (99.73%) (37148/37248)\n",
            "Epoch: 108 | Batch_idx: 300 |  Loss: (0.0111) | Acc: (99.73%) (38424/38528)\n",
            "Epoch: 108 | Batch_idx: 310 |  Loss: (0.0111) | Acc: (99.74%) (39703/39808)\n",
            "Epoch: 108 | Batch_idx: 320 |  Loss: (0.0112) | Acc: (99.73%) (40979/41088)\n",
            "Epoch: 108 | Batch_idx: 330 |  Loss: (0.0112) | Acc: (99.73%) (42254/42368)\n",
            "Epoch: 108 | Batch_idx: 340 |  Loss: (0.0112) | Acc: (99.73%) (43531/43648)\n",
            "Epoch: 108 | Batch_idx: 350 |  Loss: (0.0111) | Acc: (99.73%) (44808/44928)\n",
            "Epoch: 108 | Batch_idx: 360 |  Loss: (0.0111) | Acc: (99.73%) (46084/46208)\n",
            "Epoch: 108 | Batch_idx: 370 |  Loss: (0.0112) | Acc: (99.73%) (47360/47488)\n",
            "Epoch: 108 | Batch_idx: 380 |  Loss: (0.0111) | Acc: (99.73%) (48638/48768)\n",
            "Epoch: 108 | Batch_idx: 390 |  Loss: (0.0110) | Acc: (99.74%) (49868/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3480) | Acc: (92.22%) (9222/10000)\n",
            "Epoch: 109 | Batch_idx: 0 |  Loss: (0.0149) | Acc: (99.22%) (127/128)\n",
            "Epoch: 109 | Batch_idx: 10 |  Loss: (0.0084) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 109 | Batch_idx: 20 |  Loss: (0.0097) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 109 | Batch_idx: 30 |  Loss: (0.0114) | Acc: (99.70%) (3956/3968)\n",
            "Epoch: 109 | Batch_idx: 40 |  Loss: (0.0109) | Acc: (99.71%) (5233/5248)\n",
            "Epoch: 109 | Batch_idx: 50 |  Loss: (0.0114) | Acc: (99.69%) (6508/6528)\n",
            "Epoch: 109 | Batch_idx: 60 |  Loss: (0.0118) | Acc: (99.67%) (7782/7808)\n",
            "Epoch: 109 | Batch_idx: 70 |  Loss: (0.0118) | Acc: (99.68%) (9059/9088)\n",
            "Epoch: 109 | Batch_idx: 80 |  Loss: (0.0113) | Acc: (99.71%) (10338/10368)\n",
            "Epoch: 109 | Batch_idx: 90 |  Loss: (0.0111) | Acc: (99.72%) (11615/11648)\n",
            "Epoch: 109 | Batch_idx: 100 |  Loss: (0.0108) | Acc: (99.74%) (12894/12928)\n",
            "Epoch: 109 | Batch_idx: 110 |  Loss: (0.0106) | Acc: (99.74%) (14171/14208)\n",
            "Epoch: 109 | Batch_idx: 120 |  Loss: (0.0111) | Acc: (99.71%) (15443/15488)\n",
            "Epoch: 109 | Batch_idx: 130 |  Loss: (0.0108) | Acc: (99.73%) (16723/16768)\n",
            "Epoch: 109 | Batch_idx: 140 |  Loss: (0.0108) | Acc: (99.73%) (17999/18048)\n",
            "Epoch: 109 | Batch_idx: 150 |  Loss: (0.0110) | Acc: (99.73%) (19275/19328)\n",
            "Epoch: 109 | Batch_idx: 160 |  Loss: (0.0109) | Acc: (99.71%) (20549/20608)\n",
            "Epoch: 109 | Batch_idx: 170 |  Loss: (0.0108) | Acc: (99.72%) (21826/21888)\n",
            "Epoch: 109 | Batch_idx: 180 |  Loss: (0.0108) | Acc: (99.72%) (23104/23168)\n",
            "Epoch: 109 | Batch_idx: 190 |  Loss: (0.0107) | Acc: (99.73%) (24383/24448)\n",
            "Epoch: 109 | Batch_idx: 200 |  Loss: (0.0108) | Acc: (99.72%) (25657/25728)\n",
            "Epoch: 109 | Batch_idx: 210 |  Loss: (0.0112) | Acc: (99.71%) (26931/27008)\n",
            "Epoch: 109 | Batch_idx: 220 |  Loss: (0.0116) | Acc: (99.70%) (28202/28288)\n",
            "Epoch: 109 | Batch_idx: 230 |  Loss: (0.0118) | Acc: (99.69%) (29477/29568)\n",
            "Epoch: 109 | Batch_idx: 240 |  Loss: (0.0120) | Acc: (99.69%) (30751/30848)\n",
            "Epoch: 109 | Batch_idx: 250 |  Loss: (0.0120) | Acc: (99.68%) (32026/32128)\n",
            "Epoch: 109 | Batch_idx: 260 |  Loss: (0.0123) | Acc: (99.67%) (33299/33408)\n",
            "Epoch: 109 | Batch_idx: 270 |  Loss: (0.0123) | Acc: (99.67%) (34573/34688)\n",
            "Epoch: 109 | Batch_idx: 280 |  Loss: (0.0122) | Acc: (99.67%) (35850/35968)\n",
            "Epoch: 109 | Batch_idx: 290 |  Loss: (0.0121) | Acc: (99.68%) (37127/37248)\n",
            "Epoch: 109 | Batch_idx: 300 |  Loss: (0.0120) | Acc: (99.68%) (38405/38528)\n",
            "Epoch: 109 | Batch_idx: 310 |  Loss: (0.0120) | Acc: (99.68%) (39681/39808)\n",
            "Epoch: 109 | Batch_idx: 320 |  Loss: (0.0121) | Acc: (99.67%) (40953/41088)\n",
            "Epoch: 109 | Batch_idx: 330 |  Loss: (0.0120) | Acc: (99.67%) (42230/42368)\n",
            "Epoch: 109 | Batch_idx: 340 |  Loss: (0.0121) | Acc: (99.67%) (43503/43648)\n",
            "Epoch: 109 | Batch_idx: 350 |  Loss: (0.0122) | Acc: (99.66%) (44773/44928)\n",
            "Epoch: 109 | Batch_idx: 360 |  Loss: (0.0121) | Acc: (99.66%) (46053/46208)\n",
            "Epoch: 109 | Batch_idx: 370 |  Loss: (0.0122) | Acc: (99.66%) (47328/47488)\n",
            "Epoch: 109 | Batch_idx: 380 |  Loss: (0.0121) | Acc: (99.67%) (48606/48768)\n",
            "Epoch: 109 | Batch_idx: 390 |  Loss: (0.0122) | Acc: (99.67%) (49833/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3521) | Acc: (92.27%) (9227/10000)\n",
            "Epoch: 110 | Batch_idx: 0 |  Loss: (0.0076) | Acc: (100.00%) (128/128)\n",
            "Epoch: 110 | Batch_idx: 10 |  Loss: (0.0081) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 110 | Batch_idx: 20 |  Loss: (0.0092) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 110 | Batch_idx: 30 |  Loss: (0.0097) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 110 | Batch_idx: 40 |  Loss: (0.0102) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 110 | Batch_idx: 50 |  Loss: (0.0112) | Acc: (99.75%) (6512/6528)\n",
            "Epoch: 110 | Batch_idx: 60 |  Loss: (0.0103) | Acc: (99.80%) (7792/7808)\n",
            "Epoch: 110 | Batch_idx: 70 |  Loss: (0.0104) | Acc: (99.79%) (9069/9088)\n",
            "Epoch: 110 | Batch_idx: 80 |  Loss: (0.0108) | Acc: (99.75%) (10342/10368)\n",
            "Epoch: 110 | Batch_idx: 90 |  Loss: (0.0112) | Acc: (99.73%) (11616/11648)\n",
            "Epoch: 110 | Batch_idx: 100 |  Loss: (0.0114) | Acc: (99.71%) (12891/12928)\n",
            "Epoch: 110 | Batch_idx: 110 |  Loss: (0.0111) | Acc: (99.73%) (14170/14208)\n",
            "Epoch: 110 | Batch_idx: 120 |  Loss: (0.0112) | Acc: (99.74%) (15447/15488)\n",
            "Epoch: 110 | Batch_idx: 130 |  Loss: (0.0112) | Acc: (99.73%) (16723/16768)\n",
            "Epoch: 110 | Batch_idx: 140 |  Loss: (0.0113) | Acc: (99.72%) (17998/18048)\n",
            "Epoch: 110 | Batch_idx: 150 |  Loss: (0.0115) | Acc: (99.72%) (19273/19328)\n",
            "Epoch: 110 | Batch_idx: 160 |  Loss: (0.0113) | Acc: (99.72%) (20551/20608)\n",
            "Epoch: 110 | Batch_idx: 170 |  Loss: (0.0111) | Acc: (99.73%) (21829/21888)\n",
            "Epoch: 110 | Batch_idx: 180 |  Loss: (0.0111) | Acc: (99.72%) (23103/23168)\n",
            "Epoch: 110 | Batch_idx: 190 |  Loss: (0.0110) | Acc: (99.72%) (24380/24448)\n",
            "Epoch: 110 | Batch_idx: 200 |  Loss: (0.0109) | Acc: (99.72%) (25657/25728)\n",
            "Epoch: 110 | Batch_idx: 210 |  Loss: (0.0108) | Acc: (99.74%) (26937/27008)\n",
            "Epoch: 110 | Batch_idx: 220 |  Loss: (0.0107) | Acc: (99.74%) (28214/28288)\n",
            "Epoch: 110 | Batch_idx: 230 |  Loss: (0.0109) | Acc: (99.73%) (29488/29568)\n",
            "Epoch: 110 | Batch_idx: 240 |  Loss: (0.0108) | Acc: (99.73%) (30765/30848)\n",
            "Epoch: 110 | Batch_idx: 250 |  Loss: (0.0108) | Acc: (99.73%) (32042/32128)\n",
            "Epoch: 110 | Batch_idx: 260 |  Loss: (0.0110) | Acc: (99.72%) (33315/33408)\n",
            "Epoch: 110 | Batch_idx: 270 |  Loss: (0.0110) | Acc: (99.72%) (34590/34688)\n",
            "Epoch: 110 | Batch_idx: 280 |  Loss: (0.0111) | Acc: (99.72%) (35866/35968)\n",
            "Epoch: 110 | Batch_idx: 290 |  Loss: (0.0110) | Acc: (99.72%) (37145/37248)\n",
            "Epoch: 110 | Batch_idx: 300 |  Loss: (0.0110) | Acc: (99.72%) (38421/38528)\n",
            "Epoch: 110 | Batch_idx: 310 |  Loss: (0.0111) | Acc: (99.72%) (39697/39808)\n",
            "Epoch: 110 | Batch_idx: 320 |  Loss: (0.0110) | Acc: (99.73%) (40976/41088)\n",
            "Epoch: 110 | Batch_idx: 330 |  Loss: (0.0114) | Acc: (99.72%) (42249/42368)\n",
            "Epoch: 110 | Batch_idx: 340 |  Loss: (0.0116) | Acc: (99.71%) (43522/43648)\n",
            "Epoch: 110 | Batch_idx: 350 |  Loss: (0.0117) | Acc: (99.71%) (44798/44928)\n",
            "Epoch: 110 | Batch_idx: 360 |  Loss: (0.0117) | Acc: (99.71%) (46075/46208)\n",
            "Epoch: 110 | Batch_idx: 370 |  Loss: (0.0117) | Acc: (99.71%) (47349/47488)\n",
            "Epoch: 110 | Batch_idx: 380 |  Loss: (0.0116) | Acc: (99.71%) (48628/48768)\n",
            "Epoch: 110 | Batch_idx: 390 |  Loss: (0.0115) | Acc: (99.71%) (49857/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3539) | Acc: (92.48%) (9248/10000)\n",
            "Epoch: 111 | Batch_idx: 0 |  Loss: (0.0074) | Acc: (100.00%) (128/128)\n",
            "Epoch: 111 | Batch_idx: 10 |  Loss: (0.0126) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 111 | Batch_idx: 20 |  Loss: (0.0133) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 111 | Batch_idx: 30 |  Loss: (0.0122) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 111 | Batch_idx: 40 |  Loss: (0.0103) | Acc: (99.73%) (5234/5248)\n",
            "Epoch: 111 | Batch_idx: 50 |  Loss: (0.0110) | Acc: (99.74%) (6511/6528)\n",
            "Epoch: 111 | Batch_idx: 60 |  Loss: (0.0120) | Acc: (99.71%) (7785/7808)\n",
            "Epoch: 111 | Batch_idx: 70 |  Loss: (0.0115) | Acc: (99.74%) (9064/9088)\n",
            "Epoch: 111 | Batch_idx: 80 |  Loss: (0.0113) | Acc: (99.73%) (10340/10368)\n",
            "Epoch: 111 | Batch_idx: 90 |  Loss: (0.0110) | Acc: (99.75%) (11619/11648)\n",
            "Epoch: 111 | Batch_idx: 100 |  Loss: (0.0115) | Acc: (99.74%) (12894/12928)\n",
            "Epoch: 111 | Batch_idx: 110 |  Loss: (0.0114) | Acc: (99.73%) (14169/14208)\n",
            "Epoch: 111 | Batch_idx: 120 |  Loss: (0.0116) | Acc: (99.72%) (15444/15488)\n",
            "Epoch: 111 | Batch_idx: 130 |  Loss: (0.0117) | Acc: (99.71%) (16720/16768)\n",
            "Epoch: 111 | Batch_idx: 140 |  Loss: (0.0120) | Acc: (99.71%) (17995/18048)\n",
            "Epoch: 111 | Batch_idx: 150 |  Loss: (0.0121) | Acc: (99.71%) (19271/19328)\n",
            "Epoch: 111 | Batch_idx: 160 |  Loss: (0.0117) | Acc: (99.72%) (20551/20608)\n",
            "Epoch: 111 | Batch_idx: 170 |  Loss: (0.0117) | Acc: (99.71%) (21824/21888)\n",
            "Epoch: 111 | Batch_idx: 180 |  Loss: (0.0118) | Acc: (99.70%) (23099/23168)\n",
            "Epoch: 111 | Batch_idx: 190 |  Loss: (0.0117) | Acc: (99.71%) (24376/24448)\n",
            "Epoch: 111 | Batch_idx: 200 |  Loss: (0.0116) | Acc: (99.72%) (25655/25728)\n",
            "Epoch: 111 | Batch_idx: 210 |  Loss: (0.0114) | Acc: (99.72%) (26932/27008)\n",
            "Epoch: 111 | Batch_idx: 220 |  Loss: (0.0115) | Acc: (99.71%) (28207/28288)\n",
            "Epoch: 111 | Batch_idx: 230 |  Loss: (0.0115) | Acc: (99.72%) (29484/29568)\n",
            "Epoch: 111 | Batch_idx: 240 |  Loss: (0.0116) | Acc: (99.71%) (30757/30848)\n",
            "Epoch: 111 | Batch_idx: 250 |  Loss: (0.0118) | Acc: (99.70%) (32031/32128)\n",
            "Epoch: 111 | Batch_idx: 260 |  Loss: (0.0119) | Acc: (99.69%) (33305/33408)\n",
            "Epoch: 111 | Batch_idx: 270 |  Loss: (0.0119) | Acc: (99.69%) (34581/34688)\n",
            "Epoch: 111 | Batch_idx: 280 |  Loss: (0.0120) | Acc: (99.69%) (35856/35968)\n",
            "Epoch: 111 | Batch_idx: 290 |  Loss: (0.0122) | Acc: (99.67%) (37126/37248)\n",
            "Epoch: 111 | Batch_idx: 300 |  Loss: (0.0122) | Acc: (99.67%) (38399/38528)\n",
            "Epoch: 111 | Batch_idx: 310 |  Loss: (0.0122) | Acc: (99.67%) (39675/39808)\n",
            "Epoch: 111 | Batch_idx: 320 |  Loss: (0.0123) | Acc: (99.66%) (40949/41088)\n",
            "Epoch: 111 | Batch_idx: 330 |  Loss: (0.0123) | Acc: (99.66%) (42225/42368)\n",
            "Epoch: 111 | Batch_idx: 340 |  Loss: (0.0124) | Acc: (99.66%) (43498/43648)\n",
            "Epoch: 111 | Batch_idx: 350 |  Loss: (0.0122) | Acc: (99.67%) (44778/44928)\n",
            "Epoch: 111 | Batch_idx: 360 |  Loss: (0.0123) | Acc: (99.66%) (46053/46208)\n",
            "Epoch: 111 | Batch_idx: 370 |  Loss: (0.0122) | Acc: (99.67%) (47332/47488)\n",
            "Epoch: 111 | Batch_idx: 380 |  Loss: (0.0122) | Acc: (99.67%) (48608/48768)\n",
            "Epoch: 111 | Batch_idx: 390 |  Loss: (0.0122) | Acc: (99.67%) (49835/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3647) | Acc: (92.35%) (9235/10000)\n",
            "Epoch: 112 | Batch_idx: 0 |  Loss: (0.0044) | Acc: (100.00%) (128/128)\n",
            "Epoch: 112 | Batch_idx: 10 |  Loss: (0.0120) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 112 | Batch_idx: 20 |  Loss: (0.0103) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 112 | Batch_idx: 30 |  Loss: (0.0097) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 112 | Batch_idx: 40 |  Loss: (0.0101) | Acc: (99.73%) (5234/5248)\n",
            "Epoch: 112 | Batch_idx: 50 |  Loss: (0.0105) | Acc: (99.72%) (6510/6528)\n",
            "Epoch: 112 | Batch_idx: 60 |  Loss: (0.0100) | Acc: (99.76%) (7789/7808)\n",
            "Epoch: 112 | Batch_idx: 70 |  Loss: (0.0103) | Acc: (99.74%) (9064/9088)\n",
            "Epoch: 112 | Batch_idx: 80 |  Loss: (0.0108) | Acc: (99.73%) (10340/10368)\n",
            "Epoch: 112 | Batch_idx: 90 |  Loss: (0.0106) | Acc: (99.73%) (11616/11648)\n",
            "Epoch: 112 | Batch_idx: 100 |  Loss: (0.0105) | Acc: (99.72%) (12892/12928)\n",
            "Epoch: 112 | Batch_idx: 110 |  Loss: (0.0103) | Acc: (99.73%) (14170/14208)\n",
            "Epoch: 112 | Batch_idx: 120 |  Loss: (0.0105) | Acc: (99.72%) (15445/15488)\n",
            "Epoch: 112 | Batch_idx: 130 |  Loss: (0.0106) | Acc: (99.71%) (16720/16768)\n",
            "Epoch: 112 | Batch_idx: 140 |  Loss: (0.0105) | Acc: (99.71%) (17995/18048)\n",
            "Epoch: 112 | Batch_idx: 150 |  Loss: (0.0105) | Acc: (99.72%) (19273/19328)\n",
            "Epoch: 112 | Batch_idx: 160 |  Loss: (0.0107) | Acc: (99.70%) (20547/20608)\n",
            "Epoch: 112 | Batch_idx: 170 |  Loss: (0.0110) | Acc: (99.70%) (21823/21888)\n",
            "Epoch: 112 | Batch_idx: 180 |  Loss: (0.0110) | Acc: (99.69%) (23097/23168)\n",
            "Epoch: 112 | Batch_idx: 190 |  Loss: (0.0109) | Acc: (99.70%) (24374/24448)\n",
            "Epoch: 112 | Batch_idx: 200 |  Loss: (0.0107) | Acc: (99.71%) (25653/25728)\n",
            "Epoch: 112 | Batch_idx: 210 |  Loss: (0.0107) | Acc: (99.71%) (26929/27008)\n",
            "Epoch: 112 | Batch_idx: 220 |  Loss: (0.0105) | Acc: (99.71%) (28207/28288)\n",
            "Epoch: 112 | Batch_idx: 230 |  Loss: (0.0106) | Acc: (99.71%) (29482/29568)\n",
            "Epoch: 112 | Batch_idx: 240 |  Loss: (0.0107) | Acc: (99.71%) (30758/30848)\n",
            "Epoch: 112 | Batch_idx: 250 |  Loss: (0.0108) | Acc: (99.71%) (32034/32128)\n",
            "Epoch: 112 | Batch_idx: 260 |  Loss: (0.0109) | Acc: (99.70%) (33308/33408)\n",
            "Epoch: 112 | Batch_idx: 270 |  Loss: (0.0110) | Acc: (99.69%) (34582/34688)\n",
            "Epoch: 112 | Batch_idx: 280 |  Loss: (0.0110) | Acc: (99.70%) (35860/35968)\n",
            "Epoch: 112 | Batch_idx: 290 |  Loss: (0.0110) | Acc: (99.70%) (37135/37248)\n",
            "Epoch: 112 | Batch_idx: 300 |  Loss: (0.0109) | Acc: (99.70%) (38411/38528)\n",
            "Epoch: 112 | Batch_idx: 310 |  Loss: (0.0109) | Acc: (99.70%) (39687/39808)\n",
            "Epoch: 112 | Batch_idx: 320 |  Loss: (0.0110) | Acc: (99.69%) (40960/41088)\n",
            "Epoch: 112 | Batch_idx: 330 |  Loss: (0.0110) | Acc: (99.69%) (42237/42368)\n",
            "Epoch: 112 | Batch_idx: 340 |  Loss: (0.0110) | Acc: (99.69%) (43513/43648)\n",
            "Epoch: 112 | Batch_idx: 350 |  Loss: (0.0111) | Acc: (99.69%) (44789/44928)\n",
            "Epoch: 112 | Batch_idx: 360 |  Loss: (0.0110) | Acc: (99.70%) (46068/46208)\n",
            "Epoch: 112 | Batch_idx: 370 |  Loss: (0.0111) | Acc: (99.69%) (47342/47488)\n",
            "Epoch: 112 | Batch_idx: 380 |  Loss: (0.0110) | Acc: (99.69%) (48618/48768)\n",
            "Epoch: 112 | Batch_idx: 390 |  Loss: (0.0109) | Acc: (99.70%) (49848/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3573) | Acc: (92.22%) (9222/10000)\n",
            "Epoch: 113 | Batch_idx: 0 |  Loss: (0.0175) | Acc: (99.22%) (127/128)\n",
            "Epoch: 113 | Batch_idx: 10 |  Loss: (0.0130) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 113 | Batch_idx: 20 |  Loss: (0.0118) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 113 | Batch_idx: 30 |  Loss: (0.0122) | Acc: (99.55%) (3950/3968)\n",
            "Epoch: 113 | Batch_idx: 40 |  Loss: (0.0118) | Acc: (99.60%) (5227/5248)\n",
            "Epoch: 113 | Batch_idx: 50 |  Loss: (0.0121) | Acc: (99.59%) (6501/6528)\n",
            "Epoch: 113 | Batch_idx: 60 |  Loss: (0.0118) | Acc: (99.58%) (7775/7808)\n",
            "Epoch: 113 | Batch_idx: 70 |  Loss: (0.0123) | Acc: (99.55%) (9047/9088)\n",
            "Epoch: 113 | Batch_idx: 80 |  Loss: (0.0117) | Acc: (99.59%) (10326/10368)\n",
            "Epoch: 113 | Batch_idx: 90 |  Loss: (0.0118) | Acc: (99.61%) (11603/11648)\n",
            "Epoch: 113 | Batch_idx: 100 |  Loss: (0.0119) | Acc: (99.62%) (12879/12928)\n",
            "Epoch: 113 | Batch_idx: 110 |  Loss: (0.0117) | Acc: (99.63%) (14156/14208)\n",
            "Epoch: 113 | Batch_idx: 120 |  Loss: (0.0114) | Acc: (99.66%) (15435/15488)\n",
            "Epoch: 113 | Batch_idx: 130 |  Loss: (0.0115) | Acc: (99.63%) (16706/16768)\n",
            "Epoch: 113 | Batch_idx: 140 |  Loss: (0.0116) | Acc: (99.63%) (17981/18048)\n",
            "Epoch: 113 | Batch_idx: 150 |  Loss: (0.0115) | Acc: (99.64%) (19259/19328)\n",
            "Epoch: 113 | Batch_idx: 160 |  Loss: (0.0115) | Acc: (99.64%) (20534/20608)\n",
            "Epoch: 113 | Batch_idx: 170 |  Loss: (0.0115) | Acc: (99.64%) (21809/21888)\n",
            "Epoch: 113 | Batch_idx: 180 |  Loss: (0.0117) | Acc: (99.62%) (23081/23168)\n",
            "Epoch: 113 | Batch_idx: 190 |  Loss: (0.0115) | Acc: (99.64%) (24359/24448)\n",
            "Epoch: 113 | Batch_idx: 200 |  Loss: (0.0114) | Acc: (99.64%) (25636/25728)\n",
            "Epoch: 113 | Batch_idx: 210 |  Loss: (0.0114) | Acc: (99.64%) (26911/27008)\n",
            "Epoch: 113 | Batch_idx: 220 |  Loss: (0.0112) | Acc: (99.64%) (28187/28288)\n",
            "Epoch: 113 | Batch_idx: 230 |  Loss: (0.0115) | Acc: (99.64%) (29461/29568)\n",
            "Epoch: 113 | Batch_idx: 240 |  Loss: (0.0116) | Acc: (99.63%) (30735/30848)\n",
            "Epoch: 113 | Batch_idx: 250 |  Loss: (0.0116) | Acc: (99.64%) (32011/32128)\n",
            "Epoch: 113 | Batch_idx: 260 |  Loss: (0.0117) | Acc: (99.63%) (33285/33408)\n",
            "Epoch: 113 | Batch_idx: 270 |  Loss: (0.0118) | Acc: (99.62%) (34557/34688)\n",
            "Epoch: 113 | Batch_idx: 280 |  Loss: (0.0119) | Acc: (99.63%) (35834/35968)\n",
            "Epoch: 113 | Batch_idx: 290 |  Loss: (0.0117) | Acc: (99.63%) (37112/37248)\n",
            "Epoch: 113 | Batch_idx: 300 |  Loss: (0.0116) | Acc: (99.64%) (38388/38528)\n",
            "Epoch: 113 | Batch_idx: 310 |  Loss: (0.0117) | Acc: (99.63%) (39662/39808)\n",
            "Epoch: 113 | Batch_idx: 320 |  Loss: (0.0117) | Acc: (99.63%) (40938/41088)\n",
            "Epoch: 113 | Batch_idx: 330 |  Loss: (0.0119) | Acc: (99.63%) (42211/42368)\n",
            "Epoch: 113 | Batch_idx: 340 |  Loss: (0.0118) | Acc: (99.63%) (43486/43648)\n",
            "Epoch: 113 | Batch_idx: 350 |  Loss: (0.0118) | Acc: (99.63%) (44762/44928)\n",
            "Epoch: 113 | Batch_idx: 360 |  Loss: (0.0118) | Acc: (99.63%) (46038/46208)\n",
            "Epoch: 113 | Batch_idx: 370 |  Loss: (0.0119) | Acc: (99.63%) (47311/47488)\n",
            "Epoch: 113 | Batch_idx: 380 |  Loss: (0.0118) | Acc: (99.63%) (48588/48768)\n",
            "Epoch: 113 | Batch_idx: 390 |  Loss: (0.0119) | Acc: (99.63%) (49814/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3608) | Acc: (92.10%) (9210/10000)\n",
            "Epoch: 114 | Batch_idx: 0 |  Loss: (0.0057) | Acc: (100.00%) (128/128)\n",
            "Epoch: 114 | Batch_idx: 10 |  Loss: (0.0150) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 114 | Batch_idx: 20 |  Loss: (0.0161) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 114 | Batch_idx: 30 |  Loss: (0.0144) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 114 | Batch_idx: 40 |  Loss: (0.0130) | Acc: (99.56%) (5225/5248)\n",
            "Epoch: 114 | Batch_idx: 50 |  Loss: (0.0122) | Acc: (99.62%) (6503/6528)\n",
            "Epoch: 114 | Batch_idx: 60 |  Loss: (0.0116) | Acc: (99.65%) (7781/7808)\n",
            "Epoch: 114 | Batch_idx: 70 |  Loss: (0.0113) | Acc: (99.68%) (9059/9088)\n",
            "Epoch: 114 | Batch_idx: 80 |  Loss: (0.0110) | Acc: (99.68%) (10335/10368)\n",
            "Epoch: 114 | Batch_idx: 90 |  Loss: (0.0108) | Acc: (99.68%) (11611/11648)\n",
            "Epoch: 114 | Batch_idx: 100 |  Loss: (0.0108) | Acc: (99.69%) (12888/12928)\n",
            "Epoch: 114 | Batch_idx: 110 |  Loss: (0.0114) | Acc: (99.66%) (14160/14208)\n",
            "Epoch: 114 | Batch_idx: 120 |  Loss: (0.0116) | Acc: (99.65%) (15434/15488)\n",
            "Epoch: 114 | Batch_idx: 130 |  Loss: (0.0121) | Acc: (99.62%) (16705/16768)\n",
            "Epoch: 114 | Batch_idx: 140 |  Loss: (0.0119) | Acc: (99.62%) (17980/18048)\n",
            "Epoch: 114 | Batch_idx: 150 |  Loss: (0.0117) | Acc: (99.64%) (19259/19328)\n",
            "Epoch: 114 | Batch_idx: 160 |  Loss: (0.0117) | Acc: (99.65%) (20535/20608)\n",
            "Epoch: 114 | Batch_idx: 170 |  Loss: (0.0116) | Acc: (99.65%) (21811/21888)\n",
            "Epoch: 114 | Batch_idx: 180 |  Loss: (0.0117) | Acc: (99.65%) (23087/23168)\n",
            "Epoch: 114 | Batch_idx: 190 |  Loss: (0.0114) | Acc: (99.66%) (24365/24448)\n",
            "Epoch: 114 | Batch_idx: 200 |  Loss: (0.0116) | Acc: (99.65%) (25639/25728)\n",
            "Epoch: 114 | Batch_idx: 210 |  Loss: (0.0117) | Acc: (99.64%) (26911/27008)\n",
            "Epoch: 114 | Batch_idx: 220 |  Loss: (0.0119) | Acc: (99.64%) (28185/28288)\n",
            "Epoch: 114 | Batch_idx: 230 |  Loss: (0.0118) | Acc: (99.64%) (29461/29568)\n",
            "Epoch: 114 | Batch_idx: 240 |  Loss: (0.0118) | Acc: (99.64%) (30737/30848)\n",
            "Epoch: 114 | Batch_idx: 250 |  Loss: (0.0118) | Acc: (99.64%) (32012/32128)\n",
            "Epoch: 114 | Batch_idx: 260 |  Loss: (0.0116) | Acc: (99.65%) (33290/33408)\n",
            "Epoch: 114 | Batch_idx: 270 |  Loss: (0.0114) | Acc: (99.65%) (34568/34688)\n",
            "Epoch: 114 | Batch_idx: 280 |  Loss: (0.0113) | Acc: (99.66%) (35847/35968)\n",
            "Epoch: 114 | Batch_idx: 290 |  Loss: (0.0113) | Acc: (99.67%) (37124/37248)\n",
            "Epoch: 114 | Batch_idx: 300 |  Loss: (0.0114) | Acc: (99.67%) (38400/38528)\n",
            "Epoch: 114 | Batch_idx: 310 |  Loss: (0.0114) | Acc: (99.66%) (39674/39808)\n",
            "Epoch: 114 | Batch_idx: 320 |  Loss: (0.0113) | Acc: (99.67%) (40951/41088)\n",
            "Epoch: 114 | Batch_idx: 330 |  Loss: (0.0113) | Acc: (99.66%) (42226/42368)\n",
            "Epoch: 114 | Batch_idx: 340 |  Loss: (0.0113) | Acc: (99.67%) (43503/43648)\n",
            "Epoch: 114 | Batch_idx: 350 |  Loss: (0.0113) | Acc: (99.67%) (44781/44928)\n",
            "Epoch: 114 | Batch_idx: 360 |  Loss: (0.0115) | Acc: (99.66%) (46053/46208)\n",
            "Epoch: 114 | Batch_idx: 370 |  Loss: (0.0114) | Acc: (99.67%) (47329/47488)\n",
            "Epoch: 114 | Batch_idx: 380 |  Loss: (0.0114) | Acc: (99.67%) (48606/48768)\n",
            "Epoch: 114 | Batch_idx: 390 |  Loss: (0.0114) | Acc: (99.67%) (49835/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3572) | Acc: (92.41%) (9241/10000)\n",
            "Epoch: 115 | Batch_idx: 0 |  Loss: (0.0150) | Acc: (99.22%) (127/128)\n",
            "Epoch: 115 | Batch_idx: 10 |  Loss: (0.0098) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 115 | Batch_idx: 20 |  Loss: (0.0091) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 115 | Batch_idx: 30 |  Loss: (0.0099) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 115 | Batch_idx: 40 |  Loss: (0.0090) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 115 | Batch_idx: 50 |  Loss: (0.0086) | Acc: (99.80%) (6515/6528)\n",
            "Epoch: 115 | Batch_idx: 60 |  Loss: (0.0090) | Acc: (99.81%) (7793/7808)\n",
            "Epoch: 115 | Batch_idx: 70 |  Loss: (0.0101) | Acc: (99.76%) (9066/9088)\n",
            "Epoch: 115 | Batch_idx: 80 |  Loss: (0.0102) | Acc: (99.75%) (10342/10368)\n",
            "Epoch: 115 | Batch_idx: 90 |  Loss: (0.0099) | Acc: (99.76%) (11620/11648)\n",
            "Epoch: 115 | Batch_idx: 100 |  Loss: (0.0100) | Acc: (99.76%) (12897/12928)\n",
            "Epoch: 115 | Batch_idx: 110 |  Loss: (0.0101) | Acc: (99.74%) (14171/14208)\n",
            "Epoch: 115 | Batch_idx: 120 |  Loss: (0.0100) | Acc: (99.75%) (15449/15488)\n",
            "Epoch: 115 | Batch_idx: 130 |  Loss: (0.0099) | Acc: (99.75%) (16726/16768)\n",
            "Epoch: 115 | Batch_idx: 140 |  Loss: (0.0097) | Acc: (99.77%) (18006/18048)\n",
            "Epoch: 115 | Batch_idx: 150 |  Loss: (0.0101) | Acc: (99.75%) (19280/19328)\n",
            "Epoch: 115 | Batch_idx: 160 |  Loss: (0.0099) | Acc: (99.76%) (20559/20608)\n",
            "Epoch: 115 | Batch_idx: 170 |  Loss: (0.0100) | Acc: (99.75%) (21833/21888)\n",
            "Epoch: 115 | Batch_idx: 180 |  Loss: (0.0101) | Acc: (99.74%) (23107/23168)\n",
            "Epoch: 115 | Batch_idx: 190 |  Loss: (0.0103) | Acc: (99.73%) (24383/24448)\n",
            "Epoch: 115 | Batch_idx: 200 |  Loss: (0.0103) | Acc: (99.73%) (25659/25728)\n",
            "Epoch: 115 | Batch_idx: 210 |  Loss: (0.0101) | Acc: (99.74%) (26939/27008)\n",
            "Epoch: 115 | Batch_idx: 220 |  Loss: (0.0101) | Acc: (99.75%) (28216/28288)\n",
            "Epoch: 115 | Batch_idx: 230 |  Loss: (0.0102) | Acc: (99.74%) (29491/29568)\n",
            "Epoch: 115 | Batch_idx: 240 |  Loss: (0.0105) | Acc: (99.72%) (30762/30848)\n",
            "Epoch: 115 | Batch_idx: 250 |  Loss: (0.0106) | Acc: (99.71%) (32035/32128)\n",
            "Epoch: 115 | Batch_idx: 260 |  Loss: (0.0107) | Acc: (99.71%) (33311/33408)\n",
            "Epoch: 115 | Batch_idx: 270 |  Loss: (0.0106) | Acc: (99.72%) (34590/34688)\n",
            "Epoch: 115 | Batch_idx: 280 |  Loss: (0.0104) | Acc: (99.72%) (35869/35968)\n",
            "Epoch: 115 | Batch_idx: 290 |  Loss: (0.0104) | Acc: (99.72%) (37145/37248)\n",
            "Epoch: 115 | Batch_idx: 300 |  Loss: (0.0103) | Acc: (99.73%) (38424/38528)\n",
            "Epoch: 115 | Batch_idx: 310 |  Loss: (0.0103) | Acc: (99.73%) (39700/39808)\n",
            "Epoch: 115 | Batch_idx: 320 |  Loss: (0.0105) | Acc: (99.72%) (40974/41088)\n",
            "Epoch: 115 | Batch_idx: 330 |  Loss: (0.0106) | Acc: (99.72%) (42250/42368)\n",
            "Epoch: 115 | Batch_idx: 340 |  Loss: (0.0106) | Acc: (99.72%) (43527/43648)\n",
            "Epoch: 115 | Batch_idx: 350 |  Loss: (0.0105) | Acc: (99.73%) (44805/44928)\n",
            "Epoch: 115 | Batch_idx: 360 |  Loss: (0.0105) | Acc: (99.73%) (46081/46208)\n",
            "Epoch: 115 | Batch_idx: 370 |  Loss: (0.0105) | Acc: (99.72%) (47357/47488)\n",
            "Epoch: 115 | Batch_idx: 380 |  Loss: (0.0105) | Acc: (99.72%) (48633/48768)\n",
            "Epoch: 115 | Batch_idx: 390 |  Loss: (0.0104) | Acc: (99.72%) (49862/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3573) | Acc: (92.28%) (9228/10000)\n",
            "Epoch: 116 | Batch_idx: 0 |  Loss: (0.0039) | Acc: (100.00%) (128/128)\n",
            "Epoch: 116 | Batch_idx: 10 |  Loss: (0.0056) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 116 | Batch_idx: 20 |  Loss: (0.0090) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 116 | Batch_idx: 30 |  Loss: (0.0108) | Acc: (99.67%) (3955/3968)\n",
            "Epoch: 116 | Batch_idx: 40 |  Loss: (0.0105) | Acc: (99.68%) (5231/5248)\n",
            "Epoch: 116 | Batch_idx: 50 |  Loss: (0.0099) | Acc: (99.68%) (6507/6528)\n",
            "Epoch: 116 | Batch_idx: 60 |  Loss: (0.0105) | Acc: (99.69%) (7784/7808)\n",
            "Epoch: 116 | Batch_idx: 70 |  Loss: (0.0100) | Acc: (99.70%) (9061/9088)\n",
            "Epoch: 116 | Batch_idx: 80 |  Loss: (0.0101) | Acc: (99.71%) (10338/10368)\n",
            "Epoch: 116 | Batch_idx: 90 |  Loss: (0.0097) | Acc: (99.73%) (11616/11648)\n",
            "Epoch: 116 | Batch_idx: 100 |  Loss: (0.0097) | Acc: (99.73%) (12893/12928)\n",
            "Epoch: 116 | Batch_idx: 110 |  Loss: (0.0095) | Acc: (99.75%) (14172/14208)\n",
            "Epoch: 116 | Batch_idx: 120 |  Loss: (0.0096) | Acc: (99.74%) (15448/15488)\n",
            "Epoch: 116 | Batch_idx: 130 |  Loss: (0.0098) | Acc: (99.73%) (16723/16768)\n",
            "Epoch: 116 | Batch_idx: 140 |  Loss: (0.0099) | Acc: (99.72%) (17998/18048)\n",
            "Epoch: 116 | Batch_idx: 150 |  Loss: (0.0100) | Acc: (99.73%) (19275/19328)\n",
            "Epoch: 116 | Batch_idx: 160 |  Loss: (0.0102) | Acc: (99.73%) (20552/20608)\n",
            "Epoch: 116 | Batch_idx: 170 |  Loss: (0.0101) | Acc: (99.73%) (21828/21888)\n",
            "Epoch: 116 | Batch_idx: 180 |  Loss: (0.0101) | Acc: (99.73%) (23106/23168)\n",
            "Epoch: 116 | Batch_idx: 190 |  Loss: (0.0102) | Acc: (99.73%) (24383/24448)\n",
            "Epoch: 116 | Batch_idx: 200 |  Loss: (0.0101) | Acc: (99.74%) (25662/25728)\n",
            "Epoch: 116 | Batch_idx: 210 |  Loss: (0.0100) | Acc: (99.75%) (26940/27008)\n",
            "Epoch: 116 | Batch_idx: 220 |  Loss: (0.0100) | Acc: (99.76%) (28219/28288)\n",
            "Epoch: 116 | Batch_idx: 230 |  Loss: (0.0098) | Acc: (99.76%) (29496/29568)\n",
            "Epoch: 116 | Batch_idx: 240 |  Loss: (0.0098) | Acc: (99.76%) (30774/30848)\n",
            "Epoch: 116 | Batch_idx: 250 |  Loss: (0.0098) | Acc: (99.76%) (32051/32128)\n",
            "Epoch: 116 | Batch_idx: 260 |  Loss: (0.0097) | Acc: (99.76%) (33329/33408)\n",
            "Epoch: 116 | Batch_idx: 270 |  Loss: (0.0098) | Acc: (99.76%) (34605/34688)\n",
            "Epoch: 116 | Batch_idx: 280 |  Loss: (0.0098) | Acc: (99.76%) (35883/35968)\n",
            "Epoch: 116 | Batch_idx: 290 |  Loss: (0.0097) | Acc: (99.77%) (37161/37248)\n",
            "Epoch: 116 | Batch_idx: 300 |  Loss: (0.0098) | Acc: (99.76%) (38437/38528)\n",
            "Epoch: 116 | Batch_idx: 310 |  Loss: (0.0097) | Acc: (99.76%) (39711/39808)\n",
            "Epoch: 116 | Batch_idx: 320 |  Loss: (0.0096) | Acc: (99.76%) (40990/41088)\n",
            "Epoch: 116 | Batch_idx: 330 |  Loss: (0.0095) | Acc: (99.76%) (42268/42368)\n",
            "Epoch: 116 | Batch_idx: 340 |  Loss: (0.0097) | Acc: (99.76%) (43542/43648)\n",
            "Epoch: 116 | Batch_idx: 350 |  Loss: (0.0097) | Acc: (99.75%) (44817/44928)\n",
            "Epoch: 116 | Batch_idx: 360 |  Loss: (0.0098) | Acc: (99.75%) (46092/46208)\n",
            "Epoch: 116 | Batch_idx: 370 |  Loss: (0.0098) | Acc: (99.75%) (47369/47488)\n",
            "Epoch: 116 | Batch_idx: 380 |  Loss: (0.0100) | Acc: (99.74%) (48643/48768)\n",
            "Epoch: 116 | Batch_idx: 390 |  Loss: (0.0101) | Acc: (99.74%) (49870/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3654) | Acc: (92.35%) (9235/10000)\n",
            "Epoch: 117 | Batch_idx: 0 |  Loss: (0.0037) | Acc: (100.00%) (128/128)\n",
            "Epoch: 117 | Batch_idx: 10 |  Loss: (0.0116) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 117 | Batch_idx: 20 |  Loss: (0.0113) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 117 | Batch_idx: 30 |  Loss: (0.0118) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 117 | Batch_idx: 40 |  Loss: (0.0107) | Acc: (99.73%) (5234/5248)\n",
            "Epoch: 117 | Batch_idx: 50 |  Loss: (0.0107) | Acc: (99.75%) (6512/6528)\n",
            "Epoch: 117 | Batch_idx: 60 |  Loss: (0.0115) | Acc: (99.72%) (7786/7808)\n",
            "Epoch: 117 | Batch_idx: 70 |  Loss: (0.0114) | Acc: (99.70%) (9061/9088)\n",
            "Epoch: 117 | Batch_idx: 80 |  Loss: (0.0111) | Acc: (99.70%) (10337/10368)\n",
            "Epoch: 117 | Batch_idx: 90 |  Loss: (0.0112) | Acc: (99.70%) (11613/11648)\n",
            "Epoch: 117 | Batch_idx: 100 |  Loss: (0.0113) | Acc: (99.70%) (12889/12928)\n",
            "Epoch: 117 | Batch_idx: 110 |  Loss: (0.0112) | Acc: (99.70%) (14166/14208)\n",
            "Epoch: 117 | Batch_idx: 120 |  Loss: (0.0109) | Acc: (99.72%) (15445/15488)\n",
            "Epoch: 117 | Batch_idx: 130 |  Loss: (0.0106) | Acc: (99.73%) (16722/16768)\n",
            "Epoch: 117 | Batch_idx: 140 |  Loss: (0.0106) | Acc: (99.73%) (17999/18048)\n",
            "Epoch: 117 | Batch_idx: 150 |  Loss: (0.0107) | Acc: (99.72%) (19273/19328)\n",
            "Epoch: 117 | Batch_idx: 160 |  Loss: (0.0106) | Acc: (99.71%) (20548/20608)\n",
            "Epoch: 117 | Batch_idx: 170 |  Loss: (0.0104) | Acc: (99.72%) (21826/21888)\n",
            "Epoch: 117 | Batch_idx: 180 |  Loss: (0.0103) | Acc: (99.72%) (23103/23168)\n",
            "Epoch: 117 | Batch_idx: 190 |  Loss: (0.0103) | Acc: (99.72%) (24379/24448)\n",
            "Epoch: 117 | Batch_idx: 200 |  Loss: (0.0102) | Acc: (99.72%) (25657/25728)\n",
            "Epoch: 117 | Batch_idx: 210 |  Loss: (0.0101) | Acc: (99.73%) (26936/27008)\n",
            "Epoch: 117 | Batch_idx: 220 |  Loss: (0.0101) | Acc: (99.74%) (28215/28288)\n",
            "Epoch: 117 | Batch_idx: 230 |  Loss: (0.0099) | Acc: (99.75%) (29494/29568)\n",
            "Epoch: 117 | Batch_idx: 240 |  Loss: (0.0100) | Acc: (99.75%) (30771/30848)\n",
            "Epoch: 117 | Batch_idx: 250 |  Loss: (0.0101) | Acc: (99.75%) (32047/32128)\n",
            "Epoch: 117 | Batch_idx: 260 |  Loss: (0.0100) | Acc: (99.75%) (33325/33408)\n",
            "Epoch: 117 | Batch_idx: 270 |  Loss: (0.0100) | Acc: (99.75%) (34602/34688)\n",
            "Epoch: 117 | Batch_idx: 280 |  Loss: (0.0099) | Acc: (99.76%) (35881/35968)\n",
            "Epoch: 117 | Batch_idx: 290 |  Loss: (0.0099) | Acc: (99.76%) (37158/37248)\n",
            "Epoch: 117 | Batch_idx: 300 |  Loss: (0.0098) | Acc: (99.76%) (38436/38528)\n",
            "Epoch: 117 | Batch_idx: 310 |  Loss: (0.0098) | Acc: (99.76%) (39712/39808)\n",
            "Epoch: 117 | Batch_idx: 320 |  Loss: (0.0099) | Acc: (99.75%) (40987/41088)\n",
            "Epoch: 117 | Batch_idx: 330 |  Loss: (0.0098) | Acc: (99.76%) (42266/42368)\n",
            "Epoch: 117 | Batch_idx: 340 |  Loss: (0.0099) | Acc: (99.76%) (43542/43648)\n",
            "Epoch: 117 | Batch_idx: 350 |  Loss: (0.0098) | Acc: (99.76%) (44821/44928)\n",
            "Epoch: 117 | Batch_idx: 360 |  Loss: (0.0097) | Acc: (99.77%) (46101/46208)\n",
            "Epoch: 117 | Batch_idx: 370 |  Loss: (0.0097) | Acc: (99.77%) (47377/47488)\n",
            "Epoch: 117 | Batch_idx: 380 |  Loss: (0.0098) | Acc: (99.76%) (48652/48768)\n",
            "Epoch: 117 | Batch_idx: 390 |  Loss: (0.0098) | Acc: (99.77%) (49883/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3639) | Acc: (92.22%) (9222/10000)\n",
            "Epoch: 118 | Batch_idx: 0 |  Loss: (0.0237) | Acc: (99.22%) (127/128)\n",
            "Epoch: 118 | Batch_idx: 10 |  Loss: (0.0089) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 118 | Batch_idx: 20 |  Loss: (0.0089) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 118 | Batch_idx: 30 |  Loss: (0.0091) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 118 | Batch_idx: 40 |  Loss: (0.0084) | Acc: (99.85%) (5240/5248)\n",
            "Epoch: 118 | Batch_idx: 50 |  Loss: (0.0082) | Acc: (99.85%) (6518/6528)\n",
            "Epoch: 118 | Batch_idx: 60 |  Loss: (0.0084) | Acc: (99.83%) (7795/7808)\n",
            "Epoch: 118 | Batch_idx: 70 |  Loss: (0.0081) | Acc: (99.83%) (9073/9088)\n",
            "Epoch: 118 | Batch_idx: 80 |  Loss: (0.0081) | Acc: (99.85%) (10352/10368)\n",
            "Epoch: 118 | Batch_idx: 90 |  Loss: (0.0083) | Acc: (99.85%) (11630/11648)\n",
            "Epoch: 118 | Batch_idx: 100 |  Loss: (0.0082) | Acc: (99.85%) (12908/12928)\n",
            "Epoch: 118 | Batch_idx: 110 |  Loss: (0.0083) | Acc: (99.83%) (14184/14208)\n",
            "Epoch: 118 | Batch_idx: 120 |  Loss: (0.0084) | Acc: (99.83%) (15461/15488)\n",
            "Epoch: 118 | Batch_idx: 130 |  Loss: (0.0085) | Acc: (99.82%) (16737/16768)\n",
            "Epoch: 118 | Batch_idx: 140 |  Loss: (0.0087) | Acc: (99.81%) (18013/18048)\n",
            "Epoch: 118 | Batch_idx: 150 |  Loss: (0.0088) | Acc: (99.80%) (19289/19328)\n",
            "Epoch: 118 | Batch_idx: 160 |  Loss: (0.0088) | Acc: (99.80%) (20567/20608)\n",
            "Epoch: 118 | Batch_idx: 170 |  Loss: (0.0088) | Acc: (99.79%) (21843/21888)\n",
            "Epoch: 118 | Batch_idx: 180 |  Loss: (0.0089) | Acc: (99.79%) (23120/23168)\n",
            "Epoch: 118 | Batch_idx: 190 |  Loss: (0.0089) | Acc: (99.79%) (24397/24448)\n",
            "Epoch: 118 | Batch_idx: 200 |  Loss: (0.0094) | Acc: (99.77%) (25670/25728)\n",
            "Epoch: 118 | Batch_idx: 210 |  Loss: (0.0094) | Acc: (99.78%) (26949/27008)\n",
            "Epoch: 118 | Batch_idx: 220 |  Loss: (0.0093) | Acc: (99.78%) (28227/28288)\n",
            "Epoch: 118 | Batch_idx: 230 |  Loss: (0.0094) | Acc: (99.78%) (29503/29568)\n",
            "Epoch: 118 | Batch_idx: 240 |  Loss: (0.0095) | Acc: (99.78%) (30779/30848)\n",
            "Epoch: 118 | Batch_idx: 250 |  Loss: (0.0096) | Acc: (99.78%) (32058/32128)\n",
            "Epoch: 118 | Batch_idx: 260 |  Loss: (0.0096) | Acc: (99.78%) (33335/33408)\n",
            "Epoch: 118 | Batch_idx: 270 |  Loss: (0.0096) | Acc: (99.78%) (34612/34688)\n",
            "Epoch: 118 | Batch_idx: 280 |  Loss: (0.0098) | Acc: (99.77%) (35886/35968)\n",
            "Epoch: 118 | Batch_idx: 290 |  Loss: (0.0098) | Acc: (99.77%) (37164/37248)\n",
            "Epoch: 118 | Batch_idx: 300 |  Loss: (0.0099) | Acc: (99.76%) (38436/38528)\n",
            "Epoch: 118 | Batch_idx: 310 |  Loss: (0.0100) | Acc: (99.76%) (39712/39808)\n",
            "Epoch: 118 | Batch_idx: 320 |  Loss: (0.0099) | Acc: (99.76%) (40991/41088)\n",
            "Epoch: 118 | Batch_idx: 330 |  Loss: (0.0098) | Acc: (99.77%) (42270/42368)\n",
            "Epoch: 118 | Batch_idx: 340 |  Loss: (0.0098) | Acc: (99.77%) (43547/43648)\n",
            "Epoch: 118 | Batch_idx: 350 |  Loss: (0.0098) | Acc: (99.77%) (44825/44928)\n",
            "Epoch: 118 | Batch_idx: 360 |  Loss: (0.0097) | Acc: (99.77%) (46103/46208)\n",
            "Epoch: 118 | Batch_idx: 370 |  Loss: (0.0098) | Acc: (99.77%) (47378/47488)\n",
            "Epoch: 118 | Batch_idx: 380 |  Loss: (0.0099) | Acc: (99.77%) (48654/48768)\n",
            "Epoch: 118 | Batch_idx: 390 |  Loss: (0.0098) | Acc: (99.77%) (49884/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3741) | Acc: (92.24%) (9224/10000)\n",
            "Epoch: 119 | Batch_idx: 0 |  Loss: (0.0116) | Acc: (100.00%) (128/128)\n",
            "Epoch: 119 | Batch_idx: 10 |  Loss: (0.0128) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 119 | Batch_idx: 20 |  Loss: (0.0114) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 119 | Batch_idx: 30 |  Loss: (0.0088) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 119 | Batch_idx: 40 |  Loss: (0.0095) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 119 | Batch_idx: 50 |  Loss: (0.0095) | Acc: (99.77%) (6513/6528)\n",
            "Epoch: 119 | Batch_idx: 60 |  Loss: (0.0088) | Acc: (99.81%) (7793/7808)\n",
            "Epoch: 119 | Batch_idx: 70 |  Loss: (0.0096) | Acc: (99.77%) (9067/9088)\n",
            "Epoch: 119 | Batch_idx: 80 |  Loss: (0.0098) | Acc: (99.76%) (10343/10368)\n",
            "Epoch: 119 | Batch_idx: 90 |  Loss: (0.0097) | Acc: (99.76%) (11620/11648)\n",
            "Epoch: 119 | Batch_idx: 100 |  Loss: (0.0093) | Acc: (99.78%) (12899/12928)\n",
            "Epoch: 119 | Batch_idx: 110 |  Loss: (0.0095) | Acc: (99.77%) (14175/14208)\n",
            "Epoch: 119 | Batch_idx: 120 |  Loss: (0.0093) | Acc: (99.78%) (15454/15488)\n",
            "Epoch: 119 | Batch_idx: 130 |  Loss: (0.0091) | Acc: (99.79%) (16733/16768)\n",
            "Epoch: 119 | Batch_idx: 140 |  Loss: (0.0093) | Acc: (99.79%) (18010/18048)\n",
            "Epoch: 119 | Batch_idx: 150 |  Loss: (0.0096) | Acc: (99.77%) (19284/19328)\n",
            "Epoch: 119 | Batch_idx: 160 |  Loss: (0.0097) | Acc: (99.77%) (20560/20608)\n",
            "Epoch: 119 | Batch_idx: 170 |  Loss: (0.0098) | Acc: (99.76%) (21836/21888)\n",
            "Epoch: 119 | Batch_idx: 180 |  Loss: (0.0097) | Acc: (99.76%) (23112/23168)\n",
            "Epoch: 119 | Batch_idx: 190 |  Loss: (0.0097) | Acc: (99.77%) (24391/24448)\n",
            "Epoch: 119 | Batch_idx: 200 |  Loss: (0.0096) | Acc: (99.77%) (25668/25728)\n",
            "Epoch: 119 | Batch_idx: 210 |  Loss: (0.0095) | Acc: (99.77%) (26945/27008)\n",
            "Epoch: 119 | Batch_idx: 220 |  Loss: (0.0096) | Acc: (99.76%) (28220/28288)\n",
            "Epoch: 119 | Batch_idx: 230 |  Loss: (0.0096) | Acc: (99.76%) (29497/29568)\n",
            "Epoch: 119 | Batch_idx: 240 |  Loss: (0.0096) | Acc: (99.77%) (30776/30848)\n",
            "Epoch: 119 | Batch_idx: 250 |  Loss: (0.0097) | Acc: (99.76%) (32050/32128)\n",
            "Epoch: 119 | Batch_idx: 260 |  Loss: (0.0098) | Acc: (99.75%) (33324/33408)\n",
            "Epoch: 119 | Batch_idx: 270 |  Loss: (0.0098) | Acc: (99.75%) (34600/34688)\n",
            "Epoch: 119 | Batch_idx: 280 |  Loss: (0.0097) | Acc: (99.75%) (35879/35968)\n",
            "Epoch: 119 | Batch_idx: 290 |  Loss: (0.0096) | Acc: (99.76%) (37157/37248)\n",
            "Epoch: 119 | Batch_idx: 300 |  Loss: (0.0097) | Acc: (99.75%) (38433/38528)\n",
            "Epoch: 119 | Batch_idx: 310 |  Loss: (0.0098) | Acc: (99.75%) (39708/39808)\n",
            "Epoch: 119 | Batch_idx: 320 |  Loss: (0.0097) | Acc: (99.75%) (40987/41088)\n",
            "Epoch: 119 | Batch_idx: 330 |  Loss: (0.0098) | Acc: (99.75%) (42263/42368)\n",
            "Epoch: 119 | Batch_idx: 340 |  Loss: (0.0098) | Acc: (99.75%) (43538/43648)\n",
            "Epoch: 119 | Batch_idx: 350 |  Loss: (0.0097) | Acc: (99.75%) (44815/44928)\n",
            "Epoch: 119 | Batch_idx: 360 |  Loss: (0.0099) | Acc: (99.74%) (46089/46208)\n",
            "Epoch: 119 | Batch_idx: 370 |  Loss: (0.0099) | Acc: (99.75%) (47367/47488)\n",
            "Epoch: 119 | Batch_idx: 380 |  Loss: (0.0099) | Acc: (99.75%) (48644/48768)\n",
            "Epoch: 119 | Batch_idx: 390 |  Loss: (0.0098) | Acc: (99.74%) (49872/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3610) | Acc: (92.42%) (9242/10000)\n",
            "Epoch: 120 | Batch_idx: 0 |  Loss: (0.0127) | Acc: (99.22%) (127/128)\n",
            "Epoch: 120 | Batch_idx: 10 |  Loss: (0.0134) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 120 | Batch_idx: 20 |  Loss: (0.0140) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 120 | Batch_idx: 30 |  Loss: (0.0122) | Acc: (99.62%) (3953/3968)\n",
            "Epoch: 120 | Batch_idx: 40 |  Loss: (0.0115) | Acc: (99.66%) (5230/5248)\n",
            "Epoch: 120 | Batch_idx: 50 |  Loss: (0.0123) | Acc: (99.65%) (6505/6528)\n",
            "Epoch: 120 | Batch_idx: 60 |  Loss: (0.0118) | Acc: (99.69%) (7784/7808)\n",
            "Epoch: 120 | Batch_idx: 70 |  Loss: (0.0114) | Acc: (99.72%) (9063/9088)\n",
            "Epoch: 120 | Batch_idx: 80 |  Loss: (0.0110) | Acc: (99.75%) (10342/10368)\n",
            "Epoch: 120 | Batch_idx: 90 |  Loss: (0.0110) | Acc: (99.74%) (11618/11648)\n",
            "Epoch: 120 | Batch_idx: 100 |  Loss: (0.0116) | Acc: (99.71%) (12891/12928)\n",
            "Epoch: 120 | Batch_idx: 110 |  Loss: (0.0112) | Acc: (99.72%) (14168/14208)\n",
            "Epoch: 120 | Batch_idx: 120 |  Loss: (0.0111) | Acc: (99.72%) (15444/15488)\n",
            "Epoch: 120 | Batch_idx: 130 |  Loss: (0.0109) | Acc: (99.72%) (16721/16768)\n",
            "Epoch: 120 | Batch_idx: 140 |  Loss: (0.0107) | Acc: (99.73%) (17999/18048)\n",
            "Epoch: 120 | Batch_idx: 150 |  Loss: (0.0106) | Acc: (99.73%) (19275/19328)\n",
            "Epoch: 120 | Batch_idx: 160 |  Loss: (0.0105) | Acc: (99.73%) (20552/20608)\n",
            "Epoch: 120 | Batch_idx: 170 |  Loss: (0.0103) | Acc: (99.73%) (21829/21888)\n",
            "Epoch: 120 | Batch_idx: 180 |  Loss: (0.0101) | Acc: (99.73%) (23105/23168)\n",
            "Epoch: 120 | Batch_idx: 190 |  Loss: (0.0100) | Acc: (99.73%) (24383/24448)\n",
            "Epoch: 120 | Batch_idx: 200 |  Loss: (0.0100) | Acc: (99.74%) (25660/25728)\n",
            "Epoch: 120 | Batch_idx: 210 |  Loss: (0.0097) | Acc: (99.75%) (26940/27008)\n",
            "Epoch: 120 | Batch_idx: 220 |  Loss: (0.0096) | Acc: (99.75%) (28218/28288)\n",
            "Epoch: 120 | Batch_idx: 230 |  Loss: (0.0095) | Acc: (99.76%) (29496/29568)\n",
            "Epoch: 120 | Batch_idx: 240 |  Loss: (0.0096) | Acc: (99.75%) (30772/30848)\n",
            "Epoch: 120 | Batch_idx: 250 |  Loss: (0.0094) | Acc: (99.76%) (32052/32128)\n",
            "Epoch: 120 | Batch_idx: 260 |  Loss: (0.0093) | Acc: (99.77%) (33331/33408)\n",
            "Epoch: 120 | Batch_idx: 270 |  Loss: (0.0091) | Acc: (99.77%) (34609/34688)\n",
            "Epoch: 120 | Batch_idx: 280 |  Loss: (0.0091) | Acc: (99.77%) (35886/35968)\n",
            "Epoch: 120 | Batch_idx: 290 |  Loss: (0.0092) | Acc: (99.77%) (37162/37248)\n",
            "Epoch: 120 | Batch_idx: 300 |  Loss: (0.0091) | Acc: (99.77%) (38440/38528)\n",
            "Epoch: 120 | Batch_idx: 310 |  Loss: (0.0090) | Acc: (99.77%) (39718/39808)\n",
            "Epoch: 120 | Batch_idx: 320 |  Loss: (0.0090) | Acc: (99.78%) (40996/41088)\n",
            "Epoch: 120 | Batch_idx: 330 |  Loss: (0.0089) | Acc: (99.78%) (42276/42368)\n",
            "Epoch: 120 | Batch_idx: 340 |  Loss: (0.0088) | Acc: (99.79%) (43556/43648)\n",
            "Epoch: 120 | Batch_idx: 350 |  Loss: (0.0088) | Acc: (99.79%) (44833/44928)\n",
            "Epoch: 120 | Batch_idx: 360 |  Loss: (0.0087) | Acc: (99.79%) (46111/46208)\n",
            "Epoch: 120 | Batch_idx: 370 |  Loss: (0.0088) | Acc: (99.79%) (47388/47488)\n",
            "Epoch: 120 | Batch_idx: 380 |  Loss: (0.0088) | Acc: (99.79%) (48665/48768)\n",
            "Epoch: 120 | Batch_idx: 390 |  Loss: (0.0087) | Acc: (99.79%) (49896/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3518) | Acc: (92.54%) (9254/10000)\n",
            "Epoch: 121 | Batch_idx: 0 |  Loss: (0.0169) | Acc: (99.22%) (127/128)\n",
            "Epoch: 121 | Batch_idx: 10 |  Loss: (0.0087) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 121 | Batch_idx: 20 |  Loss: (0.0088) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 121 | Batch_idx: 30 |  Loss: (0.0081) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 121 | Batch_idx: 40 |  Loss: (0.0078) | Acc: (99.79%) (5237/5248)\n",
            "Epoch: 121 | Batch_idx: 50 |  Loss: (0.0078) | Acc: (99.82%) (6516/6528)\n",
            "Epoch: 121 | Batch_idx: 60 |  Loss: (0.0082) | Acc: (99.78%) (7791/7808)\n",
            "Epoch: 121 | Batch_idx: 70 |  Loss: (0.0083) | Acc: (99.77%) (9067/9088)\n",
            "Epoch: 121 | Batch_idx: 80 |  Loss: (0.0084) | Acc: (99.78%) (10345/10368)\n",
            "Epoch: 121 | Batch_idx: 90 |  Loss: (0.0086) | Acc: (99.79%) (11623/11648)\n",
            "Epoch: 121 | Batch_idx: 100 |  Loss: (0.0085) | Acc: (99.80%) (12902/12928)\n",
            "Epoch: 121 | Batch_idx: 110 |  Loss: (0.0083) | Acc: (99.80%) (14180/14208)\n",
            "Epoch: 121 | Batch_idx: 120 |  Loss: (0.0083) | Acc: (99.81%) (15459/15488)\n",
            "Epoch: 121 | Batch_idx: 130 |  Loss: (0.0081) | Acc: (99.83%) (16739/16768)\n",
            "Epoch: 121 | Batch_idx: 140 |  Loss: (0.0079) | Acc: (99.83%) (18018/18048)\n",
            "Epoch: 121 | Batch_idx: 150 |  Loss: (0.0081) | Acc: (99.83%) (19295/19328)\n",
            "Epoch: 121 | Batch_idx: 160 |  Loss: (0.0080) | Acc: (99.83%) (20573/20608)\n",
            "Epoch: 121 | Batch_idx: 170 |  Loss: (0.0080) | Acc: (99.83%) (21851/21888)\n",
            "Epoch: 121 | Batch_idx: 180 |  Loss: (0.0081) | Acc: (99.82%) (23126/23168)\n",
            "Epoch: 121 | Batch_idx: 190 |  Loss: (0.0079) | Acc: (99.83%) (24406/24448)\n",
            "Epoch: 121 | Batch_idx: 200 |  Loss: (0.0077) | Acc: (99.84%) (25686/25728)\n",
            "Epoch: 121 | Batch_idx: 210 |  Loss: (0.0077) | Acc: (99.84%) (26964/27008)\n",
            "Epoch: 121 | Batch_idx: 220 |  Loss: (0.0078) | Acc: (99.83%) (28239/28288)\n",
            "Epoch: 121 | Batch_idx: 230 |  Loss: (0.0077) | Acc: (99.83%) (29518/29568)\n",
            "Epoch: 121 | Batch_idx: 240 |  Loss: (0.0077) | Acc: (99.83%) (30795/30848)\n",
            "Epoch: 121 | Batch_idx: 250 |  Loss: (0.0077) | Acc: (99.83%) (32074/32128)\n",
            "Epoch: 121 | Batch_idx: 260 |  Loss: (0.0076) | Acc: (99.83%) (33351/33408)\n",
            "Epoch: 121 | Batch_idx: 270 |  Loss: (0.0076) | Acc: (99.83%) (34629/34688)\n",
            "Epoch: 121 | Batch_idx: 280 |  Loss: (0.0075) | Acc: (99.83%) (35908/35968)\n",
            "Epoch: 121 | Batch_idx: 290 |  Loss: (0.0075) | Acc: (99.84%) (37187/37248)\n",
            "Epoch: 121 | Batch_idx: 300 |  Loss: (0.0076) | Acc: (99.83%) (38464/38528)\n",
            "Epoch: 121 | Batch_idx: 310 |  Loss: (0.0076) | Acc: (99.83%) (39742/39808)\n",
            "Epoch: 121 | Batch_idx: 320 |  Loss: (0.0075) | Acc: (99.83%) (41020/41088)\n",
            "Epoch: 121 | Batch_idx: 330 |  Loss: (0.0075) | Acc: (99.84%) (42299/42368)\n",
            "Epoch: 121 | Batch_idx: 340 |  Loss: (0.0074) | Acc: (99.84%) (43578/43648)\n",
            "Epoch: 121 | Batch_idx: 350 |  Loss: (0.0073) | Acc: (99.84%) (44856/44928)\n",
            "Epoch: 121 | Batch_idx: 360 |  Loss: (0.0073) | Acc: (99.84%) (46136/46208)\n",
            "Epoch: 121 | Batch_idx: 370 |  Loss: (0.0072) | Acc: (99.85%) (47416/47488)\n",
            "Epoch: 121 | Batch_idx: 380 |  Loss: (0.0073) | Acc: (99.85%) (48694/48768)\n",
            "Epoch: 121 | Batch_idx: 390 |  Loss: (0.0073) | Acc: (99.85%) (49923/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3520) | Acc: (92.57%) (9257/10000)\n",
            "Epoch: 122 | Batch_idx: 0 |  Loss: (0.0015) | Acc: (100.00%) (128/128)\n",
            "Epoch: 122 | Batch_idx: 10 |  Loss: (0.0045) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 122 | Batch_idx: 20 |  Loss: (0.0046) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 122 | Batch_idx: 30 |  Loss: (0.0048) | Acc: (99.95%) (3966/3968)\n",
            "Epoch: 122 | Batch_idx: 40 |  Loss: (0.0059) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 122 | Batch_idx: 50 |  Loss: (0.0058) | Acc: (99.89%) (6521/6528)\n",
            "Epoch: 122 | Batch_idx: 60 |  Loss: (0.0059) | Acc: (99.88%) (7799/7808)\n",
            "Epoch: 122 | Batch_idx: 70 |  Loss: (0.0069) | Acc: (99.82%) (9072/9088)\n",
            "Epoch: 122 | Batch_idx: 80 |  Loss: (0.0067) | Acc: (99.84%) (10351/10368)\n",
            "Epoch: 122 | Batch_idx: 90 |  Loss: (0.0068) | Acc: (99.85%) (11630/11648)\n",
            "Epoch: 122 | Batch_idx: 100 |  Loss: (0.0070) | Acc: (99.83%) (12906/12928)\n",
            "Epoch: 122 | Batch_idx: 110 |  Loss: (0.0070) | Acc: (99.84%) (14185/14208)\n",
            "Epoch: 122 | Batch_idx: 120 |  Loss: (0.0078) | Acc: (99.81%) (15459/15488)\n",
            "Epoch: 122 | Batch_idx: 130 |  Loss: (0.0076) | Acc: (99.82%) (16738/16768)\n",
            "Epoch: 122 | Batch_idx: 140 |  Loss: (0.0075) | Acc: (99.83%) (18018/18048)\n",
            "Epoch: 122 | Batch_idx: 150 |  Loss: (0.0073) | Acc: (99.84%) (19297/19328)\n",
            "Epoch: 122 | Batch_idx: 160 |  Loss: (0.0071) | Acc: (99.85%) (20577/20608)\n",
            "Epoch: 122 | Batch_idx: 170 |  Loss: (0.0070) | Acc: (99.86%) (21857/21888)\n",
            "Epoch: 122 | Batch_idx: 180 |  Loss: (0.0071) | Acc: (99.86%) (23135/23168)\n",
            "Epoch: 122 | Batch_idx: 190 |  Loss: (0.0071) | Acc: (99.85%) (24412/24448)\n",
            "Epoch: 122 | Batch_idx: 200 |  Loss: (0.0072) | Acc: (99.85%) (25689/25728)\n",
            "Epoch: 122 | Batch_idx: 210 |  Loss: (0.0070) | Acc: (99.85%) (26968/27008)\n",
            "Epoch: 122 | Batch_idx: 220 |  Loss: (0.0068) | Acc: (99.86%) (28248/28288)\n",
            "Epoch: 122 | Batch_idx: 230 |  Loss: (0.0069) | Acc: (99.86%) (29527/29568)\n",
            "Epoch: 122 | Batch_idx: 240 |  Loss: (0.0069) | Acc: (99.86%) (30804/30848)\n",
            "Epoch: 122 | Batch_idx: 250 |  Loss: (0.0068) | Acc: (99.86%) (32084/32128)\n",
            "Epoch: 122 | Batch_idx: 260 |  Loss: (0.0068) | Acc: (99.86%) (33362/33408)\n",
            "Epoch: 122 | Batch_idx: 270 |  Loss: (0.0068) | Acc: (99.86%) (34640/34688)\n",
            "Epoch: 122 | Batch_idx: 280 |  Loss: (0.0068) | Acc: (99.87%) (35920/35968)\n",
            "Epoch: 122 | Batch_idx: 290 |  Loss: (0.0067) | Acc: (99.87%) (37200/37248)\n",
            "Epoch: 122 | Batch_idx: 300 |  Loss: (0.0068) | Acc: (99.87%) (38476/38528)\n",
            "Epoch: 122 | Batch_idx: 310 |  Loss: (0.0068) | Acc: (99.86%) (39751/39808)\n",
            "Epoch: 122 | Batch_idx: 320 |  Loss: (0.0068) | Acc: (99.86%) (41029/41088)\n",
            "Epoch: 122 | Batch_idx: 330 |  Loss: (0.0069) | Acc: (99.85%) (42306/42368)\n",
            "Epoch: 122 | Batch_idx: 340 |  Loss: (0.0069) | Acc: (99.86%) (43585/43648)\n",
            "Epoch: 122 | Batch_idx: 350 |  Loss: (0.0069) | Acc: (99.86%) (44863/44928)\n",
            "Epoch: 122 | Batch_idx: 360 |  Loss: (0.0069) | Acc: (99.85%) (46140/46208)\n",
            "Epoch: 122 | Batch_idx: 370 |  Loss: (0.0069) | Acc: (99.85%) (47419/47488)\n",
            "Epoch: 122 | Batch_idx: 380 |  Loss: (0.0068) | Acc: (99.86%) (48698/48768)\n",
            "Epoch: 122 | Batch_idx: 390 |  Loss: (0.0069) | Acc: (99.85%) (49926/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3549) | Acc: (92.53%) (9253/10000)\n",
            "Epoch: 123 | Batch_idx: 0 |  Loss: (0.0037) | Acc: (100.00%) (128/128)\n",
            "Epoch: 123 | Batch_idx: 10 |  Loss: (0.0045) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 123 | Batch_idx: 20 |  Loss: (0.0043) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 123 | Batch_idx: 30 |  Loss: (0.0049) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 123 | Batch_idx: 40 |  Loss: (0.0059) | Acc: (99.87%) (5241/5248)\n",
            "Epoch: 123 | Batch_idx: 50 |  Loss: (0.0062) | Acc: (99.85%) (6518/6528)\n",
            "Epoch: 123 | Batch_idx: 60 |  Loss: (0.0064) | Acc: (99.83%) (7795/7808)\n",
            "Epoch: 123 | Batch_idx: 70 |  Loss: (0.0070) | Acc: (99.79%) (9069/9088)\n",
            "Epoch: 123 | Batch_idx: 80 |  Loss: (0.0068) | Acc: (99.80%) (10347/10368)\n",
            "Epoch: 123 | Batch_idx: 90 |  Loss: (0.0068) | Acc: (99.81%) (11626/11648)\n",
            "Epoch: 123 | Batch_idx: 100 |  Loss: (0.0066) | Acc: (99.82%) (12905/12928)\n",
            "Epoch: 123 | Batch_idx: 110 |  Loss: (0.0067) | Acc: (99.81%) (14181/14208)\n",
            "Epoch: 123 | Batch_idx: 120 |  Loss: (0.0066) | Acc: (99.83%) (15461/15488)\n",
            "Epoch: 123 | Batch_idx: 130 |  Loss: (0.0065) | Acc: (99.83%) (16739/16768)\n",
            "Epoch: 123 | Batch_idx: 140 |  Loss: (0.0064) | Acc: (99.83%) (18018/18048)\n",
            "Epoch: 123 | Batch_idx: 150 |  Loss: (0.0062) | Acc: (99.84%) (19298/19328)\n",
            "Epoch: 123 | Batch_idx: 160 |  Loss: (0.0066) | Acc: (99.84%) (20575/20608)\n",
            "Epoch: 123 | Batch_idx: 170 |  Loss: (0.0066) | Acc: (99.83%) (21851/21888)\n",
            "Epoch: 123 | Batch_idx: 180 |  Loss: (0.0065) | Acc: (99.84%) (23130/23168)\n",
            "Epoch: 123 | Batch_idx: 190 |  Loss: (0.0064) | Acc: (99.84%) (24410/24448)\n",
            "Epoch: 123 | Batch_idx: 200 |  Loss: (0.0062) | Acc: (99.85%) (25690/25728)\n",
            "Epoch: 123 | Batch_idx: 210 |  Loss: (0.0063) | Acc: (99.85%) (26968/27008)\n",
            "Epoch: 123 | Batch_idx: 220 |  Loss: (0.0063) | Acc: (99.85%) (28246/28288)\n",
            "Epoch: 123 | Batch_idx: 230 |  Loss: (0.0064) | Acc: (99.85%) (29525/29568)\n",
            "Epoch: 123 | Batch_idx: 240 |  Loss: (0.0064) | Acc: (99.85%) (30802/30848)\n",
            "Epoch: 123 | Batch_idx: 250 |  Loss: (0.0063) | Acc: (99.86%) (32082/32128)\n",
            "Epoch: 123 | Batch_idx: 260 |  Loss: (0.0063) | Acc: (99.85%) (33358/33408)\n",
            "Epoch: 123 | Batch_idx: 270 |  Loss: (0.0063) | Acc: (99.85%) (34636/34688)\n",
            "Epoch: 123 | Batch_idx: 280 |  Loss: (0.0064) | Acc: (99.85%) (35915/35968)\n",
            "Epoch: 123 | Batch_idx: 290 |  Loss: (0.0063) | Acc: (99.86%) (37194/37248)\n",
            "Epoch: 123 | Batch_idx: 300 |  Loss: (0.0063) | Acc: (99.85%) (38471/38528)\n",
            "Epoch: 123 | Batch_idx: 310 |  Loss: (0.0062) | Acc: (99.86%) (39751/39808)\n",
            "Epoch: 123 | Batch_idx: 320 |  Loss: (0.0063) | Acc: (99.85%) (41027/41088)\n",
            "Epoch: 123 | Batch_idx: 330 |  Loss: (0.0063) | Acc: (99.85%) (42306/42368)\n",
            "Epoch: 123 | Batch_idx: 340 |  Loss: (0.0063) | Acc: (99.85%) (43581/43648)\n",
            "Epoch: 123 | Batch_idx: 350 |  Loss: (0.0063) | Acc: (99.85%) (44861/44928)\n",
            "Epoch: 123 | Batch_idx: 360 |  Loss: (0.0064) | Acc: (99.84%) (46136/46208)\n",
            "Epoch: 123 | Batch_idx: 370 |  Loss: (0.0064) | Acc: (99.84%) (47414/47488)\n",
            "Epoch: 123 | Batch_idx: 380 |  Loss: (0.0064) | Acc: (99.84%) (48691/48768)\n",
            "Epoch: 123 | Batch_idx: 390 |  Loss: (0.0064) | Acc: (99.84%) (49922/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3495) | Acc: (92.61%) (9261/10000)\n",
            "Epoch: 124 | Batch_idx: 0 |  Loss: (0.0048) | Acc: (100.00%) (128/128)\n",
            "Epoch: 124 | Batch_idx: 10 |  Loss: (0.0098) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 124 | Batch_idx: 20 |  Loss: (0.0072) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 124 | Batch_idx: 30 |  Loss: (0.0084) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 124 | Batch_idx: 40 |  Loss: (0.0077) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 124 | Batch_idx: 50 |  Loss: (0.0072) | Acc: (99.79%) (6514/6528)\n",
            "Epoch: 124 | Batch_idx: 60 |  Loss: (0.0068) | Acc: (99.82%) (7794/7808)\n",
            "Epoch: 124 | Batch_idx: 70 |  Loss: (0.0065) | Acc: (99.83%) (9073/9088)\n",
            "Epoch: 124 | Batch_idx: 80 |  Loss: (0.0062) | Acc: (99.86%) (10353/10368)\n",
            "Epoch: 124 | Batch_idx: 90 |  Loss: (0.0061) | Acc: (99.85%) (11631/11648)\n",
            "Epoch: 124 | Batch_idx: 100 |  Loss: (0.0060) | Acc: (99.86%) (12910/12928)\n",
            "Epoch: 124 | Batch_idx: 110 |  Loss: (0.0060) | Acc: (99.86%) (14188/14208)\n",
            "Epoch: 124 | Batch_idx: 120 |  Loss: (0.0061) | Acc: (99.86%) (15466/15488)\n",
            "Epoch: 124 | Batch_idx: 130 |  Loss: (0.0061) | Acc: (99.87%) (16746/16768)\n",
            "Epoch: 124 | Batch_idx: 140 |  Loss: (0.0063) | Acc: (99.87%) (18025/18048)\n",
            "Epoch: 124 | Batch_idx: 150 |  Loss: (0.0063) | Acc: (99.87%) (19302/19328)\n",
            "Epoch: 124 | Batch_idx: 160 |  Loss: (0.0064) | Acc: (99.85%) (20578/20608)\n",
            "Epoch: 124 | Batch_idx: 170 |  Loss: (0.0063) | Acc: (99.86%) (21857/21888)\n",
            "Epoch: 124 | Batch_idx: 180 |  Loss: (0.0062) | Acc: (99.87%) (23137/23168)\n",
            "Epoch: 124 | Batch_idx: 190 |  Loss: (0.0064) | Acc: (99.85%) (24412/24448)\n",
            "Epoch: 124 | Batch_idx: 200 |  Loss: (0.0063) | Acc: (99.86%) (25691/25728)\n",
            "Epoch: 124 | Batch_idx: 210 |  Loss: (0.0064) | Acc: (99.85%) (26968/27008)\n",
            "Epoch: 124 | Batch_idx: 220 |  Loss: (0.0063) | Acc: (99.86%) (28247/28288)\n",
            "Epoch: 124 | Batch_idx: 230 |  Loss: (0.0064) | Acc: (99.85%) (29525/29568)\n",
            "Epoch: 124 | Batch_idx: 240 |  Loss: (0.0065) | Acc: (99.84%) (30799/30848)\n",
            "Epoch: 124 | Batch_idx: 250 |  Loss: (0.0065) | Acc: (99.84%) (32078/32128)\n",
            "Epoch: 124 | Batch_idx: 260 |  Loss: (0.0065) | Acc: (99.84%) (33356/33408)\n",
            "Epoch: 124 | Batch_idx: 270 |  Loss: (0.0066) | Acc: (99.84%) (34633/34688)\n",
            "Epoch: 124 | Batch_idx: 280 |  Loss: (0.0065) | Acc: (99.84%) (35912/35968)\n",
            "Epoch: 124 | Batch_idx: 290 |  Loss: (0.0065) | Acc: (99.84%) (37188/37248)\n",
            "Epoch: 124 | Batch_idx: 300 |  Loss: (0.0065) | Acc: (99.84%) (38468/38528)\n",
            "Epoch: 124 | Batch_idx: 310 |  Loss: (0.0065) | Acc: (99.84%) (39745/39808)\n",
            "Epoch: 124 | Batch_idx: 320 |  Loss: (0.0065) | Acc: (99.84%) (41024/41088)\n",
            "Epoch: 124 | Batch_idx: 330 |  Loss: (0.0067) | Acc: (99.84%) (42299/42368)\n",
            "Epoch: 124 | Batch_idx: 340 |  Loss: (0.0068) | Acc: (99.83%) (43574/43648)\n",
            "Epoch: 124 | Batch_idx: 350 |  Loss: (0.0067) | Acc: (99.84%) (44854/44928)\n",
            "Epoch: 124 | Batch_idx: 360 |  Loss: (0.0066) | Acc: (99.84%) (46133/46208)\n",
            "Epoch: 124 | Batch_idx: 370 |  Loss: (0.0068) | Acc: (99.84%) (47410/47488)\n",
            "Epoch: 124 | Batch_idx: 380 |  Loss: (0.0068) | Acc: (99.84%) (48689/48768)\n",
            "Epoch: 124 | Batch_idx: 390 |  Loss: (0.0068) | Acc: (99.84%) (49919/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3476) | Acc: (92.61%) (9261/10000)\n",
            "Epoch: 125 | Batch_idx: 0 |  Loss: (0.0073) | Acc: (100.00%) (128/128)\n",
            "Epoch: 125 | Batch_idx: 10 |  Loss: (0.0034) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 125 | Batch_idx: 20 |  Loss: (0.0049) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 125 | Batch_idx: 30 |  Loss: (0.0055) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 125 | Batch_idx: 40 |  Loss: (0.0055) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 125 | Batch_idx: 50 |  Loss: (0.0053) | Acc: (99.91%) (6522/6528)\n",
            "Epoch: 125 | Batch_idx: 60 |  Loss: (0.0053) | Acc: (99.91%) (7801/7808)\n",
            "Epoch: 125 | Batch_idx: 70 |  Loss: (0.0051) | Acc: (99.92%) (9081/9088)\n",
            "Epoch: 125 | Batch_idx: 80 |  Loss: (0.0051) | Acc: (99.93%) (10361/10368)\n",
            "Epoch: 125 | Batch_idx: 90 |  Loss: (0.0053) | Acc: (99.93%) (11640/11648)\n",
            "Epoch: 125 | Batch_idx: 100 |  Loss: (0.0055) | Acc: (99.91%) (12916/12928)\n",
            "Epoch: 125 | Batch_idx: 110 |  Loss: (0.0057) | Acc: (99.89%) (14193/14208)\n",
            "Epoch: 125 | Batch_idx: 120 |  Loss: (0.0057) | Acc: (99.90%) (15472/15488)\n",
            "Epoch: 125 | Batch_idx: 130 |  Loss: (0.0056) | Acc: (99.90%) (16752/16768)\n",
            "Epoch: 125 | Batch_idx: 140 |  Loss: (0.0058) | Acc: (99.90%) (18030/18048)\n",
            "Epoch: 125 | Batch_idx: 150 |  Loss: (0.0058) | Acc: (99.91%) (19310/19328)\n",
            "Epoch: 125 | Batch_idx: 160 |  Loss: (0.0059) | Acc: (99.90%) (20588/20608)\n",
            "Epoch: 125 | Batch_idx: 170 |  Loss: (0.0060) | Acc: (99.90%) (21866/21888)\n",
            "Epoch: 125 | Batch_idx: 180 |  Loss: (0.0058) | Acc: (99.91%) (23146/23168)\n",
            "Epoch: 125 | Batch_idx: 190 |  Loss: (0.0058) | Acc: (99.91%) (24425/24448)\n",
            "Epoch: 125 | Batch_idx: 200 |  Loss: (0.0061) | Acc: (99.90%) (25701/25728)\n",
            "Epoch: 125 | Batch_idx: 210 |  Loss: (0.0060) | Acc: (99.90%) (26980/27008)\n",
            "Epoch: 125 | Batch_idx: 220 |  Loss: (0.0061) | Acc: (99.89%) (28258/28288)\n",
            "Epoch: 125 | Batch_idx: 230 |  Loss: (0.0060) | Acc: (99.90%) (29537/29568)\n",
            "Epoch: 125 | Batch_idx: 240 |  Loss: (0.0059) | Acc: (99.89%) (30814/30848)\n",
            "Epoch: 125 | Batch_idx: 250 |  Loss: (0.0060) | Acc: (99.89%) (32092/32128)\n",
            "Epoch: 125 | Batch_idx: 260 |  Loss: (0.0060) | Acc: (99.89%) (33371/33408)\n",
            "Epoch: 125 | Batch_idx: 270 |  Loss: (0.0059) | Acc: (99.89%) (34650/34688)\n",
            "Epoch: 125 | Batch_idx: 280 |  Loss: (0.0059) | Acc: (99.89%) (35927/35968)\n",
            "Epoch: 125 | Batch_idx: 290 |  Loss: (0.0059) | Acc: (99.88%) (37205/37248)\n",
            "Epoch: 125 | Batch_idx: 300 |  Loss: (0.0060) | Acc: (99.88%) (38481/38528)\n",
            "Epoch: 125 | Batch_idx: 310 |  Loss: (0.0060) | Acc: (99.88%) (39760/39808)\n",
            "Epoch: 125 | Batch_idx: 320 |  Loss: (0.0059) | Acc: (99.88%) (41038/41088)\n",
            "Epoch: 125 | Batch_idx: 330 |  Loss: (0.0059) | Acc: (99.88%) (42318/42368)\n",
            "Epoch: 125 | Batch_idx: 340 |  Loss: (0.0059) | Acc: (99.88%) (43597/43648)\n",
            "Epoch: 125 | Batch_idx: 350 |  Loss: (0.0058) | Acc: (99.89%) (44877/44928)\n",
            "Epoch: 125 | Batch_idx: 360 |  Loss: (0.0058) | Acc: (99.89%) (46157/46208)\n",
            "Epoch: 125 | Batch_idx: 370 |  Loss: (0.0058) | Acc: (99.89%) (47435/47488)\n",
            "Epoch: 125 | Batch_idx: 380 |  Loss: (0.0058) | Acc: (99.89%) (48715/48768)\n",
            "Epoch: 125 | Batch_idx: 390 |  Loss: (0.0059) | Acc: (99.89%) (49943/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3516) | Acc: (92.62%) (9262/10000)\n",
            "Epoch: 126 | Batch_idx: 0 |  Loss: (0.0152) | Acc: (99.22%) (127/128)\n",
            "Epoch: 126 | Batch_idx: 10 |  Loss: (0.0061) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 126 | Batch_idx: 20 |  Loss: (0.0068) | Acc: (99.81%) (2683/2688)\n",
            "Epoch: 126 | Batch_idx: 30 |  Loss: (0.0061) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 126 | Batch_idx: 40 |  Loss: (0.0062) | Acc: (99.85%) (5240/5248)\n",
            "Epoch: 126 | Batch_idx: 50 |  Loss: (0.0059) | Acc: (99.86%) (6519/6528)\n",
            "Epoch: 126 | Batch_idx: 60 |  Loss: (0.0062) | Acc: (99.86%) (7797/7808)\n",
            "Epoch: 126 | Batch_idx: 70 |  Loss: (0.0062) | Acc: (99.86%) (9075/9088)\n",
            "Epoch: 126 | Batch_idx: 80 |  Loss: (0.0064) | Acc: (99.85%) (10352/10368)\n",
            "Epoch: 126 | Batch_idx: 90 |  Loss: (0.0063) | Acc: (99.85%) (11630/11648)\n",
            "Epoch: 126 | Batch_idx: 100 |  Loss: (0.0063) | Acc: (99.85%) (12909/12928)\n",
            "Epoch: 126 | Batch_idx: 110 |  Loss: (0.0063) | Acc: (99.85%) (14187/14208)\n",
            "Epoch: 126 | Batch_idx: 120 |  Loss: (0.0062) | Acc: (99.86%) (15466/15488)\n",
            "Epoch: 126 | Batch_idx: 130 |  Loss: (0.0064) | Acc: (99.84%) (16742/16768)\n",
            "Epoch: 126 | Batch_idx: 140 |  Loss: (0.0064) | Acc: (99.85%) (18021/18048)\n",
            "Epoch: 126 | Batch_idx: 150 |  Loss: (0.0066) | Acc: (99.84%) (19298/19328)\n",
            "Epoch: 126 | Batch_idx: 160 |  Loss: (0.0066) | Acc: (99.85%) (20577/20608)\n",
            "Epoch: 126 | Batch_idx: 170 |  Loss: (0.0067) | Acc: (99.85%) (21855/21888)\n",
            "Epoch: 126 | Batch_idx: 180 |  Loss: (0.0066) | Acc: (99.86%) (23135/23168)\n",
            "Epoch: 126 | Batch_idx: 190 |  Loss: (0.0064) | Acc: (99.87%) (24415/24448)\n",
            "Epoch: 126 | Batch_idx: 200 |  Loss: (0.0065) | Acc: (99.86%) (25693/25728)\n",
            "Epoch: 126 | Batch_idx: 210 |  Loss: (0.0063) | Acc: (99.87%) (26973/27008)\n",
            "Epoch: 126 | Batch_idx: 220 |  Loss: (0.0064) | Acc: (99.87%) (28250/28288)\n",
            "Epoch: 126 | Batch_idx: 230 |  Loss: (0.0063) | Acc: (99.87%) (29529/29568)\n",
            "Epoch: 126 | Batch_idx: 240 |  Loss: (0.0063) | Acc: (99.87%) (30808/30848)\n",
            "Epoch: 126 | Batch_idx: 250 |  Loss: (0.0062) | Acc: (99.87%) (32086/32128)\n",
            "Epoch: 126 | Batch_idx: 260 |  Loss: (0.0062) | Acc: (99.87%) (33364/33408)\n",
            "Epoch: 126 | Batch_idx: 270 |  Loss: (0.0062) | Acc: (99.87%) (34643/34688)\n",
            "Epoch: 126 | Batch_idx: 280 |  Loss: (0.0064) | Acc: (99.86%) (35917/35968)\n",
            "Epoch: 126 | Batch_idx: 290 |  Loss: (0.0063) | Acc: (99.86%) (37197/37248)\n",
            "Epoch: 126 | Batch_idx: 300 |  Loss: (0.0063) | Acc: (99.86%) (38475/38528)\n",
            "Epoch: 126 | Batch_idx: 310 |  Loss: (0.0063) | Acc: (99.86%) (39751/39808)\n",
            "Epoch: 126 | Batch_idx: 320 |  Loss: (0.0064) | Acc: (99.85%) (41026/41088)\n",
            "Epoch: 126 | Batch_idx: 330 |  Loss: (0.0064) | Acc: (99.85%) (42305/42368)\n",
            "Epoch: 126 | Batch_idx: 340 |  Loss: (0.0065) | Acc: (99.84%) (43580/43648)\n",
            "Epoch: 126 | Batch_idx: 350 |  Loss: (0.0065) | Acc: (99.84%) (44858/44928)\n",
            "Epoch: 126 | Batch_idx: 360 |  Loss: (0.0064) | Acc: (99.85%) (46138/46208)\n",
            "Epoch: 126 | Batch_idx: 370 |  Loss: (0.0063) | Acc: (99.85%) (47418/47488)\n",
            "Epoch: 126 | Batch_idx: 380 |  Loss: (0.0064) | Acc: (99.85%) (48696/48768)\n",
            "Epoch: 126 | Batch_idx: 390 |  Loss: (0.0065) | Acc: (99.85%) (49924/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3512) | Acc: (92.71%) (9271/10000)\n",
            "Epoch: 127 | Batch_idx: 0 |  Loss: (0.0143) | Acc: (99.22%) (127/128)\n",
            "Epoch: 127 | Batch_idx: 10 |  Loss: (0.0063) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 127 | Batch_idx: 20 |  Loss: (0.0055) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 127 | Batch_idx: 30 |  Loss: (0.0065) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 127 | Batch_idx: 40 |  Loss: (0.0059) | Acc: (99.87%) (5241/5248)\n",
            "Epoch: 127 | Batch_idx: 50 |  Loss: (0.0060) | Acc: (99.85%) (6518/6528)\n",
            "Epoch: 127 | Batch_idx: 60 |  Loss: (0.0058) | Acc: (99.86%) (7797/7808)\n",
            "Epoch: 127 | Batch_idx: 70 |  Loss: (0.0055) | Acc: (99.88%) (9077/9088)\n",
            "Epoch: 127 | Batch_idx: 80 |  Loss: (0.0056) | Acc: (99.88%) (10356/10368)\n",
            "Epoch: 127 | Batch_idx: 90 |  Loss: (0.0058) | Acc: (99.88%) (11634/11648)\n",
            "Epoch: 127 | Batch_idx: 100 |  Loss: (0.0056) | Acc: (99.88%) (12913/12928)\n",
            "Epoch: 127 | Batch_idx: 110 |  Loss: (0.0056) | Acc: (99.89%) (14192/14208)\n",
            "Epoch: 127 | Batch_idx: 120 |  Loss: (0.0054) | Acc: (99.90%) (15472/15488)\n",
            "Epoch: 127 | Batch_idx: 130 |  Loss: (0.0053) | Acc: (99.90%) (16752/16768)\n",
            "Epoch: 127 | Batch_idx: 140 |  Loss: (0.0054) | Acc: (99.89%) (18029/18048)\n",
            "Epoch: 127 | Batch_idx: 150 |  Loss: (0.0054) | Acc: (99.90%) (19308/19328)\n",
            "Epoch: 127 | Batch_idx: 160 |  Loss: (0.0053) | Acc: (99.90%) (20587/20608)\n",
            "Epoch: 127 | Batch_idx: 170 |  Loss: (0.0053) | Acc: (99.90%) (21867/21888)\n",
            "Epoch: 127 | Batch_idx: 180 |  Loss: (0.0053) | Acc: (99.90%) (23145/23168)\n",
            "Epoch: 127 | Batch_idx: 190 |  Loss: (0.0053) | Acc: (99.90%) (24424/24448)\n",
            "Epoch: 127 | Batch_idx: 200 |  Loss: (0.0054) | Acc: (99.89%) (25700/25728)\n",
            "Epoch: 127 | Batch_idx: 210 |  Loss: (0.0053) | Acc: (99.90%) (26980/27008)\n",
            "Epoch: 127 | Batch_idx: 220 |  Loss: (0.0053) | Acc: (99.90%) (28259/28288)\n",
            "Epoch: 127 | Batch_idx: 230 |  Loss: (0.0054) | Acc: (99.90%) (29537/29568)\n",
            "Epoch: 127 | Batch_idx: 240 |  Loss: (0.0055) | Acc: (99.89%) (30815/30848)\n",
            "Epoch: 127 | Batch_idx: 250 |  Loss: (0.0055) | Acc: (99.89%) (32094/32128)\n",
            "Epoch: 127 | Batch_idx: 260 |  Loss: (0.0055) | Acc: (99.89%) (33372/33408)\n",
            "Epoch: 127 | Batch_idx: 270 |  Loss: (0.0055) | Acc: (99.89%) (34651/34688)\n",
            "Epoch: 127 | Batch_idx: 280 |  Loss: (0.0055) | Acc: (99.90%) (35931/35968)\n",
            "Epoch: 127 | Batch_idx: 290 |  Loss: (0.0054) | Acc: (99.90%) (37210/37248)\n",
            "Epoch: 127 | Batch_idx: 300 |  Loss: (0.0054) | Acc: (99.90%) (38489/38528)\n",
            "Epoch: 127 | Batch_idx: 310 |  Loss: (0.0053) | Acc: (99.90%) (39769/39808)\n",
            "Epoch: 127 | Batch_idx: 320 |  Loss: (0.0054) | Acc: (99.90%) (41046/41088)\n",
            "Epoch: 127 | Batch_idx: 330 |  Loss: (0.0054) | Acc: (99.90%) (42325/42368)\n",
            "Epoch: 127 | Batch_idx: 340 |  Loss: (0.0055) | Acc: (99.90%) (43603/43648)\n",
            "Epoch: 127 | Batch_idx: 350 |  Loss: (0.0055) | Acc: (99.90%) (44882/44928)\n",
            "Epoch: 127 | Batch_idx: 360 |  Loss: (0.0055) | Acc: (99.89%) (46159/46208)\n",
            "Epoch: 127 | Batch_idx: 370 |  Loss: (0.0056) | Acc: (99.89%) (47436/47488)\n",
            "Epoch: 127 | Batch_idx: 380 |  Loss: (0.0055) | Acc: (99.89%) (48714/48768)\n",
            "Epoch: 127 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.89%) (49946/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3505) | Acc: (92.64%) (9264/10000)\n",
            "Epoch: 128 | Batch_idx: 0 |  Loss: (0.0073) | Acc: (100.00%) (128/128)\n",
            "Epoch: 128 | Batch_idx: 10 |  Loss: (0.0048) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 128 | Batch_idx: 20 |  Loss: (0.0055) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 128 | Batch_idx: 30 |  Loss: (0.0056) | Acc: (99.95%) (3966/3968)\n",
            "Epoch: 128 | Batch_idx: 40 |  Loss: (0.0054) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 128 | Batch_idx: 50 |  Loss: (0.0054) | Acc: (99.94%) (6524/6528)\n",
            "Epoch: 128 | Batch_idx: 60 |  Loss: (0.0050) | Acc: (99.94%) (7803/7808)\n",
            "Epoch: 128 | Batch_idx: 70 |  Loss: (0.0050) | Acc: (99.93%) (9082/9088)\n",
            "Epoch: 128 | Batch_idx: 80 |  Loss: (0.0051) | Acc: (99.91%) (10359/10368)\n",
            "Epoch: 128 | Batch_idx: 90 |  Loss: (0.0050) | Acc: (99.92%) (11639/11648)\n",
            "Epoch: 128 | Batch_idx: 100 |  Loss: (0.0051) | Acc: (99.92%) (12918/12928)\n",
            "Epoch: 128 | Batch_idx: 110 |  Loss: (0.0053) | Acc: (99.90%) (14194/14208)\n",
            "Epoch: 128 | Batch_idx: 120 |  Loss: (0.0052) | Acc: (99.90%) (15472/15488)\n",
            "Epoch: 128 | Batch_idx: 130 |  Loss: (0.0051) | Acc: (99.90%) (16752/16768)\n",
            "Epoch: 128 | Batch_idx: 140 |  Loss: (0.0052) | Acc: (99.90%) (18030/18048)\n",
            "Epoch: 128 | Batch_idx: 150 |  Loss: (0.0052) | Acc: (99.90%) (19309/19328)\n",
            "Epoch: 128 | Batch_idx: 160 |  Loss: (0.0052) | Acc: (99.90%) (20587/20608)\n",
            "Epoch: 128 | Batch_idx: 170 |  Loss: (0.0052) | Acc: (99.90%) (21867/21888)\n",
            "Epoch: 128 | Batch_idx: 180 |  Loss: (0.0052) | Acc: (99.91%) (23146/23168)\n",
            "Epoch: 128 | Batch_idx: 190 |  Loss: (0.0053) | Acc: (99.90%) (24424/24448)\n",
            "Epoch: 128 | Batch_idx: 200 |  Loss: (0.0053) | Acc: (99.90%) (25703/25728)\n",
            "Epoch: 128 | Batch_idx: 210 |  Loss: (0.0052) | Acc: (99.90%) (26982/27008)\n",
            "Epoch: 128 | Batch_idx: 220 |  Loss: (0.0052) | Acc: (99.91%) (28262/28288)\n",
            "Epoch: 128 | Batch_idx: 230 |  Loss: (0.0051) | Acc: (99.91%) (29542/29568)\n",
            "Epoch: 128 | Batch_idx: 240 |  Loss: (0.0051) | Acc: (99.91%) (30821/30848)\n",
            "Epoch: 128 | Batch_idx: 250 |  Loss: (0.0051) | Acc: (99.91%) (32100/32128)\n",
            "Epoch: 128 | Batch_idx: 260 |  Loss: (0.0051) | Acc: (99.91%) (33379/33408)\n",
            "Epoch: 128 | Batch_idx: 270 |  Loss: (0.0052) | Acc: (99.91%) (34658/34688)\n",
            "Epoch: 128 | Batch_idx: 280 |  Loss: (0.0054) | Acc: (99.91%) (35936/35968)\n",
            "Epoch: 128 | Batch_idx: 290 |  Loss: (0.0054) | Acc: (99.91%) (37215/37248)\n",
            "Epoch: 128 | Batch_idx: 300 |  Loss: (0.0054) | Acc: (99.91%) (38495/38528)\n",
            "Epoch: 128 | Batch_idx: 310 |  Loss: (0.0054) | Acc: (99.91%) (39774/39808)\n",
            "Epoch: 128 | Batch_idx: 320 |  Loss: (0.0054) | Acc: (99.91%) (41053/41088)\n",
            "Epoch: 128 | Batch_idx: 330 |  Loss: (0.0054) | Acc: (99.92%) (42333/42368)\n",
            "Epoch: 128 | Batch_idx: 340 |  Loss: (0.0053) | Acc: (99.92%) (43612/43648)\n",
            "Epoch: 128 | Batch_idx: 350 |  Loss: (0.0053) | Acc: (99.92%) (44891/44928)\n",
            "Epoch: 128 | Batch_idx: 360 |  Loss: (0.0053) | Acc: (99.91%) (46168/46208)\n",
            "Epoch: 128 | Batch_idx: 370 |  Loss: (0.0053) | Acc: (99.91%) (47447/47488)\n",
            "Epoch: 128 | Batch_idx: 380 |  Loss: (0.0054) | Acc: (99.91%) (48723/48768)\n",
            "Epoch: 128 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.90%) (49951/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3568) | Acc: (92.65%) (9265/10000)\n",
            "Epoch: 129 | Batch_idx: 0 |  Loss: (0.0273) | Acc: (98.44%) (126/128)\n",
            "Epoch: 129 | Batch_idx: 10 |  Loss: (0.0076) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 129 | Batch_idx: 20 |  Loss: (0.0061) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 129 | Batch_idx: 30 |  Loss: (0.0056) | Acc: (99.90%) (3964/3968)\n",
            "Epoch: 129 | Batch_idx: 40 |  Loss: (0.0057) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 129 | Batch_idx: 50 |  Loss: (0.0061) | Acc: (99.88%) (6520/6528)\n",
            "Epoch: 129 | Batch_idx: 60 |  Loss: (0.0061) | Acc: (99.88%) (7799/7808)\n",
            "Epoch: 129 | Batch_idx: 70 |  Loss: (0.0060) | Acc: (99.88%) (9077/9088)\n",
            "Epoch: 129 | Batch_idx: 80 |  Loss: (0.0059) | Acc: (99.88%) (10356/10368)\n",
            "Epoch: 129 | Batch_idx: 90 |  Loss: (0.0059) | Acc: (99.90%) (11636/11648)\n",
            "Epoch: 129 | Batch_idx: 100 |  Loss: (0.0061) | Acc: (99.89%) (12914/12928)\n",
            "Epoch: 129 | Batch_idx: 110 |  Loss: (0.0062) | Acc: (99.88%) (14191/14208)\n",
            "Epoch: 129 | Batch_idx: 120 |  Loss: (0.0061) | Acc: (99.88%) (15470/15488)\n",
            "Epoch: 129 | Batch_idx: 130 |  Loss: (0.0061) | Acc: (99.88%) (16748/16768)\n",
            "Epoch: 129 | Batch_idx: 140 |  Loss: (0.0058) | Acc: (99.89%) (18028/18048)\n",
            "Epoch: 129 | Batch_idx: 150 |  Loss: (0.0058) | Acc: (99.89%) (19307/19328)\n",
            "Epoch: 129 | Batch_idx: 160 |  Loss: (0.0059) | Acc: (99.89%) (20586/20608)\n",
            "Epoch: 129 | Batch_idx: 170 |  Loss: (0.0058) | Acc: (99.89%) (21865/21888)\n",
            "Epoch: 129 | Batch_idx: 180 |  Loss: (0.0058) | Acc: (99.90%) (23144/23168)\n",
            "Epoch: 129 | Batch_idx: 190 |  Loss: (0.0057) | Acc: (99.90%) (24424/24448)\n",
            "Epoch: 129 | Batch_idx: 200 |  Loss: (0.0057) | Acc: (99.90%) (25703/25728)\n",
            "Epoch: 129 | Batch_idx: 210 |  Loss: (0.0057) | Acc: (99.90%) (26982/27008)\n",
            "Epoch: 129 | Batch_idx: 220 |  Loss: (0.0058) | Acc: (99.90%) (28260/28288)\n",
            "Epoch: 129 | Batch_idx: 230 |  Loss: (0.0058) | Acc: (99.90%) (29537/29568)\n",
            "Epoch: 129 | Batch_idx: 240 |  Loss: (0.0058) | Acc: (99.89%) (30815/30848)\n",
            "Epoch: 129 | Batch_idx: 250 |  Loss: (0.0057) | Acc: (99.89%) (32094/32128)\n",
            "Epoch: 129 | Batch_idx: 260 |  Loss: (0.0056) | Acc: (99.90%) (33374/33408)\n",
            "Epoch: 129 | Batch_idx: 270 |  Loss: (0.0056) | Acc: (99.90%) (34653/34688)\n",
            "Epoch: 129 | Batch_idx: 280 |  Loss: (0.0055) | Acc: (99.90%) (35932/35968)\n",
            "Epoch: 129 | Batch_idx: 290 |  Loss: (0.0055) | Acc: (99.90%) (37212/37248)\n",
            "Epoch: 129 | Batch_idx: 300 |  Loss: (0.0055) | Acc: (99.90%) (38491/38528)\n",
            "Epoch: 129 | Batch_idx: 310 |  Loss: (0.0054) | Acc: (99.90%) (39770/39808)\n",
            "Epoch: 129 | Batch_idx: 320 |  Loss: (0.0054) | Acc: (99.91%) (41049/41088)\n",
            "Epoch: 129 | Batch_idx: 330 |  Loss: (0.0055) | Acc: (99.90%) (42327/42368)\n",
            "Epoch: 129 | Batch_idx: 340 |  Loss: (0.0054) | Acc: (99.90%) (43606/43648)\n",
            "Epoch: 129 | Batch_idx: 350 |  Loss: (0.0054) | Acc: (99.90%) (44884/44928)\n",
            "Epoch: 129 | Batch_idx: 360 |  Loss: (0.0055) | Acc: (99.90%) (46161/46208)\n",
            "Epoch: 129 | Batch_idx: 370 |  Loss: (0.0055) | Acc: (99.90%) (47440/47488)\n",
            "Epoch: 129 | Batch_idx: 380 |  Loss: (0.0055) | Acc: (99.90%) (48718/48768)\n",
            "Epoch: 129 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.90%) (49949/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3500) | Acc: (92.71%) (9271/10000)\n",
            "Epoch: 130 | Batch_idx: 0 |  Loss: (0.0090) | Acc: (100.00%) (128/128)\n",
            "Epoch: 130 | Batch_idx: 10 |  Loss: (0.0041) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 130 | Batch_idx: 20 |  Loss: (0.0040) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 130 | Batch_idx: 30 |  Loss: (0.0046) | Acc: (99.95%) (3966/3968)\n",
            "Epoch: 130 | Batch_idx: 40 |  Loss: (0.0050) | Acc: (99.90%) (5243/5248)\n",
            "Epoch: 130 | Batch_idx: 50 |  Loss: (0.0050) | Acc: (99.91%) (6522/6528)\n",
            "Epoch: 130 | Batch_idx: 60 |  Loss: (0.0049) | Acc: (99.92%) (7802/7808)\n",
            "Epoch: 130 | Batch_idx: 70 |  Loss: (0.0051) | Acc: (99.91%) (9080/9088)\n",
            "Epoch: 130 | Batch_idx: 80 |  Loss: (0.0047) | Acc: (99.92%) (10360/10368)\n",
            "Epoch: 130 | Batch_idx: 90 |  Loss: (0.0047) | Acc: (99.92%) (11639/11648)\n",
            "Epoch: 130 | Batch_idx: 100 |  Loss: (0.0048) | Acc: (99.91%) (12917/12928)\n",
            "Epoch: 130 | Batch_idx: 110 |  Loss: (0.0051) | Acc: (99.90%) (14194/14208)\n",
            "Epoch: 130 | Batch_idx: 120 |  Loss: (0.0051) | Acc: (99.90%) (15473/15488)\n",
            "Epoch: 130 | Batch_idx: 130 |  Loss: (0.0051) | Acc: (99.90%) (16751/16768)\n",
            "Epoch: 130 | Batch_idx: 140 |  Loss: (0.0053) | Acc: (99.89%) (18029/18048)\n",
            "Epoch: 130 | Batch_idx: 150 |  Loss: (0.0052) | Acc: (99.90%) (19308/19328)\n",
            "Epoch: 130 | Batch_idx: 160 |  Loss: (0.0052) | Acc: (99.89%) (20586/20608)\n",
            "Epoch: 130 | Batch_idx: 170 |  Loss: (0.0052) | Acc: (99.89%) (21865/21888)\n",
            "Epoch: 130 | Batch_idx: 180 |  Loss: (0.0054) | Acc: (99.89%) (23143/23168)\n",
            "Epoch: 130 | Batch_idx: 190 |  Loss: (0.0054) | Acc: (99.89%) (24421/24448)\n",
            "Epoch: 130 | Batch_idx: 200 |  Loss: (0.0053) | Acc: (99.89%) (25700/25728)\n",
            "Epoch: 130 | Batch_idx: 210 |  Loss: (0.0053) | Acc: (99.90%) (26980/27008)\n",
            "Epoch: 130 | Batch_idx: 220 |  Loss: (0.0053) | Acc: (99.90%) (28259/28288)\n",
            "Epoch: 130 | Batch_idx: 230 |  Loss: (0.0052) | Acc: (99.90%) (29539/29568)\n",
            "Epoch: 130 | Batch_idx: 240 |  Loss: (0.0051) | Acc: (99.90%) (30818/30848)\n",
            "Epoch: 130 | Batch_idx: 250 |  Loss: (0.0051) | Acc: (99.90%) (32097/32128)\n",
            "Epoch: 130 | Batch_idx: 260 |  Loss: (0.0051) | Acc: (99.90%) (33376/33408)\n",
            "Epoch: 130 | Batch_idx: 270 |  Loss: (0.0051) | Acc: (99.91%) (34656/34688)\n",
            "Epoch: 130 | Batch_idx: 280 |  Loss: (0.0051) | Acc: (99.91%) (35936/35968)\n",
            "Epoch: 130 | Batch_idx: 290 |  Loss: (0.0051) | Acc: (99.91%) (37213/37248)\n",
            "Epoch: 130 | Batch_idx: 300 |  Loss: (0.0052) | Acc: (99.90%) (38490/38528)\n",
            "Epoch: 130 | Batch_idx: 310 |  Loss: (0.0051) | Acc: (99.90%) (39770/39808)\n",
            "Epoch: 130 | Batch_idx: 320 |  Loss: (0.0051) | Acc: (99.91%) (41049/41088)\n",
            "Epoch: 130 | Batch_idx: 330 |  Loss: (0.0051) | Acc: (99.91%) (42328/42368)\n",
            "Epoch: 130 | Batch_idx: 340 |  Loss: (0.0051) | Acc: (99.91%) (43608/43648)\n",
            "Epoch: 130 | Batch_idx: 350 |  Loss: (0.0051) | Acc: (99.91%) (44887/44928)\n",
            "Epoch: 130 | Batch_idx: 360 |  Loss: (0.0050) | Acc: (99.91%) (46167/46208)\n",
            "Epoch: 130 | Batch_idx: 370 |  Loss: (0.0050) | Acc: (99.91%) (47446/47488)\n",
            "Epoch: 130 | Batch_idx: 380 |  Loss: (0.0051) | Acc: (99.91%) (48723/48768)\n",
            "Epoch: 130 | Batch_idx: 390 |  Loss: (0.0051) | Acc: (99.91%) (49953/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3556) | Acc: (92.76%) (9276/10000)\n",
            "Epoch: 131 | Batch_idx: 0 |  Loss: (0.0013) | Acc: (100.00%) (128/128)\n",
            "Epoch: 131 | Batch_idx: 10 |  Loss: (0.0049) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 131 | Batch_idx: 20 |  Loss: (0.0048) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 131 | Batch_idx: 30 |  Loss: (0.0053) | Acc: (99.90%) (3964/3968)\n",
            "Epoch: 131 | Batch_idx: 40 |  Loss: (0.0057) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 131 | Batch_idx: 50 |  Loss: (0.0057) | Acc: (99.89%) (6521/6528)\n",
            "Epoch: 131 | Batch_idx: 60 |  Loss: (0.0054) | Acc: (99.91%) (7801/7808)\n",
            "Epoch: 131 | Batch_idx: 70 |  Loss: (0.0053) | Acc: (99.91%) (9080/9088)\n",
            "Epoch: 131 | Batch_idx: 80 |  Loss: (0.0053) | Acc: (99.91%) (10359/10368)\n",
            "Epoch: 131 | Batch_idx: 90 |  Loss: (0.0051) | Acc: (99.91%) (11638/11648)\n",
            "Epoch: 131 | Batch_idx: 100 |  Loss: (0.0055) | Acc: (99.90%) (12915/12928)\n",
            "Epoch: 131 | Batch_idx: 110 |  Loss: (0.0055) | Acc: (99.90%) (14194/14208)\n",
            "Epoch: 131 | Batch_idx: 120 |  Loss: (0.0056) | Acc: (99.90%) (15473/15488)\n",
            "Epoch: 131 | Batch_idx: 130 |  Loss: (0.0055) | Acc: (99.91%) (16753/16768)\n",
            "Epoch: 131 | Batch_idx: 140 |  Loss: (0.0055) | Acc: (99.91%) (18031/18048)\n",
            "Epoch: 131 | Batch_idx: 150 |  Loss: (0.0055) | Acc: (99.91%) (19310/19328)\n",
            "Epoch: 131 | Batch_idx: 160 |  Loss: (0.0056) | Acc: (99.90%) (20588/20608)\n",
            "Epoch: 131 | Batch_idx: 170 |  Loss: (0.0056) | Acc: (99.89%) (21865/21888)\n",
            "Epoch: 131 | Batch_idx: 180 |  Loss: (0.0056) | Acc: (99.90%) (23144/23168)\n",
            "Epoch: 131 | Batch_idx: 190 |  Loss: (0.0056) | Acc: (99.89%) (24421/24448)\n",
            "Epoch: 131 | Batch_idx: 200 |  Loss: (0.0056) | Acc: (99.89%) (25700/25728)\n",
            "Epoch: 131 | Batch_idx: 210 |  Loss: (0.0057) | Acc: (99.89%) (26979/27008)\n",
            "Epoch: 131 | Batch_idx: 220 |  Loss: (0.0058) | Acc: (99.89%) (28256/28288)\n",
            "Epoch: 131 | Batch_idx: 230 |  Loss: (0.0057) | Acc: (99.89%) (29535/29568)\n",
            "Epoch: 131 | Batch_idx: 240 |  Loss: (0.0057) | Acc: (99.89%) (30814/30848)\n",
            "Epoch: 131 | Batch_idx: 250 |  Loss: (0.0057) | Acc: (99.89%) (32094/32128)\n",
            "Epoch: 131 | Batch_idx: 260 |  Loss: (0.0056) | Acc: (99.90%) (33374/33408)\n",
            "Epoch: 131 | Batch_idx: 270 |  Loss: (0.0056) | Acc: (99.90%) (34652/34688)\n",
            "Epoch: 131 | Batch_idx: 280 |  Loss: (0.0056) | Acc: (99.90%) (35931/35968)\n",
            "Epoch: 131 | Batch_idx: 290 |  Loss: (0.0056) | Acc: (99.89%) (37208/37248)\n",
            "Epoch: 131 | Batch_idx: 300 |  Loss: (0.0056) | Acc: (99.89%) (38487/38528)\n",
            "Epoch: 131 | Batch_idx: 310 |  Loss: (0.0057) | Acc: (99.89%) (39764/39808)\n",
            "Epoch: 131 | Batch_idx: 320 |  Loss: (0.0056) | Acc: (99.89%) (41042/41088)\n",
            "Epoch: 131 | Batch_idx: 330 |  Loss: (0.0056) | Acc: (99.89%) (42322/42368)\n",
            "Epoch: 131 | Batch_idx: 340 |  Loss: (0.0056) | Acc: (99.89%) (43602/43648)\n",
            "Epoch: 131 | Batch_idx: 350 |  Loss: (0.0056) | Acc: (99.90%) (44882/44928)\n",
            "Epoch: 131 | Batch_idx: 360 |  Loss: (0.0055) | Acc: (99.90%) (46161/46208)\n",
            "Epoch: 131 | Batch_idx: 370 |  Loss: (0.0055) | Acc: (99.90%) (47440/47488)\n",
            "Epoch: 131 | Batch_idx: 380 |  Loss: (0.0055) | Acc: (99.89%) (48716/48768)\n",
            "Epoch: 131 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.89%) (49947/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3528) | Acc: (92.67%) (9267/10000)\n",
            "Epoch: 132 | Batch_idx: 0 |  Loss: (0.0061) | Acc: (100.00%) (128/128)\n",
            "Epoch: 132 | Batch_idx: 10 |  Loss: (0.0040) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 132 | Batch_idx: 20 |  Loss: (0.0051) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 132 | Batch_idx: 30 |  Loss: (0.0052) | Acc: (99.95%) (3966/3968)\n",
            "Epoch: 132 | Batch_idx: 40 |  Loss: (0.0054) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 132 | Batch_idx: 50 |  Loss: (0.0055) | Acc: (99.94%) (6524/6528)\n",
            "Epoch: 132 | Batch_idx: 60 |  Loss: (0.0058) | Acc: (99.95%) (7804/7808)\n",
            "Epoch: 132 | Batch_idx: 70 |  Loss: (0.0060) | Acc: (99.93%) (9082/9088)\n",
            "Epoch: 132 | Batch_idx: 80 |  Loss: (0.0061) | Acc: (99.92%) (10360/10368)\n",
            "Epoch: 132 | Batch_idx: 90 |  Loss: (0.0060) | Acc: (99.91%) (11638/11648)\n",
            "Epoch: 132 | Batch_idx: 100 |  Loss: (0.0059) | Acc: (99.92%) (12918/12928)\n",
            "Epoch: 132 | Batch_idx: 110 |  Loss: (0.0057) | Acc: (99.93%) (14198/14208)\n",
            "Epoch: 132 | Batch_idx: 120 |  Loss: (0.0056) | Acc: (99.93%) (15477/15488)\n",
            "Epoch: 132 | Batch_idx: 130 |  Loss: (0.0056) | Acc: (99.92%) (16755/16768)\n",
            "Epoch: 132 | Batch_idx: 140 |  Loss: (0.0056) | Acc: (99.92%) (18034/18048)\n",
            "Epoch: 132 | Batch_idx: 150 |  Loss: (0.0055) | Acc: (99.92%) (19312/19328)\n",
            "Epoch: 132 | Batch_idx: 160 |  Loss: (0.0054) | Acc: (99.92%) (20591/20608)\n",
            "Epoch: 132 | Batch_idx: 170 |  Loss: (0.0057) | Acc: (99.91%) (21868/21888)\n",
            "Epoch: 132 | Batch_idx: 180 |  Loss: (0.0057) | Acc: (99.91%) (23146/23168)\n",
            "Epoch: 132 | Batch_idx: 190 |  Loss: (0.0056) | Acc: (99.91%) (24426/24448)\n",
            "Epoch: 132 | Batch_idx: 200 |  Loss: (0.0056) | Acc: (99.90%) (25703/25728)\n",
            "Epoch: 132 | Batch_idx: 210 |  Loss: (0.0056) | Acc: (99.90%) (26981/27008)\n",
            "Epoch: 132 | Batch_idx: 220 |  Loss: (0.0055) | Acc: (99.90%) (28260/28288)\n",
            "Epoch: 132 | Batch_idx: 230 |  Loss: (0.0055) | Acc: (99.91%) (29540/29568)\n",
            "Epoch: 132 | Batch_idx: 240 |  Loss: (0.0054) | Acc: (99.91%) (30819/30848)\n",
            "Epoch: 132 | Batch_idx: 250 |  Loss: (0.0054) | Acc: (99.91%) (32098/32128)\n",
            "Epoch: 132 | Batch_idx: 260 |  Loss: (0.0054) | Acc: (99.90%) (33376/33408)\n",
            "Epoch: 132 | Batch_idx: 270 |  Loss: (0.0055) | Acc: (99.90%) (34655/34688)\n",
            "Epoch: 132 | Batch_idx: 280 |  Loss: (0.0054) | Acc: (99.91%) (35934/35968)\n",
            "Epoch: 132 | Batch_idx: 290 |  Loss: (0.0053) | Acc: (99.91%) (37214/37248)\n",
            "Epoch: 132 | Batch_idx: 300 |  Loss: (0.0053) | Acc: (99.91%) (38494/38528)\n",
            "Epoch: 132 | Batch_idx: 310 |  Loss: (0.0052) | Acc: (99.91%) (39774/39808)\n",
            "Epoch: 132 | Batch_idx: 320 |  Loss: (0.0053) | Acc: (99.91%) (41052/41088)\n",
            "Epoch: 132 | Batch_idx: 330 |  Loss: (0.0053) | Acc: (99.91%) (42330/42368)\n",
            "Epoch: 132 | Batch_idx: 340 |  Loss: (0.0053) | Acc: (99.91%) (43609/43648)\n",
            "Epoch: 132 | Batch_idx: 350 |  Loss: (0.0053) | Acc: (99.91%) (44888/44928)\n",
            "Epoch: 132 | Batch_idx: 360 |  Loss: (0.0054) | Acc: (99.90%) (46164/46208)\n",
            "Epoch: 132 | Batch_idx: 370 |  Loss: (0.0054) | Acc: (99.91%) (47443/47488)\n",
            "Epoch: 132 | Batch_idx: 380 |  Loss: (0.0054) | Acc: (99.91%) (48722/48768)\n",
            "Epoch: 132 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.90%) (49951/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3567) | Acc: (92.70%) (9270/10000)\n",
            "Epoch: 133 | Batch_idx: 0 |  Loss: (0.0028) | Acc: (100.00%) (128/128)\n",
            "Epoch: 133 | Batch_idx: 10 |  Loss: (0.0068) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 133 | Batch_idx: 20 |  Loss: (0.0058) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 133 | Batch_idx: 30 |  Loss: (0.0057) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 133 | Batch_idx: 40 |  Loss: (0.0055) | Acc: (99.90%) (5243/5248)\n",
            "Epoch: 133 | Batch_idx: 50 |  Loss: (0.0052) | Acc: (99.92%) (6523/6528)\n",
            "Epoch: 133 | Batch_idx: 60 |  Loss: (0.0051) | Acc: (99.94%) (7803/7808)\n",
            "Epoch: 133 | Batch_idx: 70 |  Loss: (0.0049) | Acc: (99.94%) (9083/9088)\n",
            "Epoch: 133 | Batch_idx: 80 |  Loss: (0.0050) | Acc: (99.94%) (10362/10368)\n",
            "Epoch: 133 | Batch_idx: 90 |  Loss: (0.0054) | Acc: (99.92%) (11639/11648)\n",
            "Epoch: 133 | Batch_idx: 100 |  Loss: (0.0056) | Acc: (99.91%) (12916/12928)\n",
            "Epoch: 133 | Batch_idx: 110 |  Loss: (0.0055) | Acc: (99.91%) (14195/14208)\n",
            "Epoch: 133 | Batch_idx: 120 |  Loss: (0.0053) | Acc: (99.92%) (15475/15488)\n",
            "Epoch: 133 | Batch_idx: 130 |  Loss: (0.0051) | Acc: (99.92%) (16755/16768)\n",
            "Epoch: 133 | Batch_idx: 140 |  Loss: (0.0052) | Acc: (99.93%) (18035/18048)\n",
            "Epoch: 133 | Batch_idx: 150 |  Loss: (0.0053) | Acc: (99.92%) (19312/19328)\n",
            "Epoch: 133 | Batch_idx: 160 |  Loss: (0.0052) | Acc: (99.92%) (20591/20608)\n",
            "Epoch: 133 | Batch_idx: 170 |  Loss: (0.0052) | Acc: (99.91%) (21869/21888)\n",
            "Epoch: 133 | Batch_idx: 180 |  Loss: (0.0051) | Acc: (99.91%) (23148/23168)\n",
            "Epoch: 133 | Batch_idx: 190 |  Loss: (0.0052) | Acc: (99.91%) (24426/24448)\n",
            "Epoch: 133 | Batch_idx: 200 |  Loss: (0.0051) | Acc: (99.91%) (25706/25728)\n",
            "Epoch: 133 | Batch_idx: 210 |  Loss: (0.0051) | Acc: (99.91%) (26985/27008)\n",
            "Epoch: 133 | Batch_idx: 220 |  Loss: (0.0051) | Acc: (99.91%) (28262/28288)\n",
            "Epoch: 133 | Batch_idx: 230 |  Loss: (0.0051) | Acc: (99.91%) (29541/29568)\n",
            "Epoch: 133 | Batch_idx: 240 |  Loss: (0.0051) | Acc: (99.91%) (30820/30848)\n",
            "Epoch: 133 | Batch_idx: 250 |  Loss: (0.0052) | Acc: (99.90%) (32097/32128)\n",
            "Epoch: 133 | Batch_idx: 260 |  Loss: (0.0052) | Acc: (99.90%) (33376/33408)\n",
            "Epoch: 133 | Batch_idx: 270 |  Loss: (0.0051) | Acc: (99.91%) (34656/34688)\n",
            "Epoch: 133 | Batch_idx: 280 |  Loss: (0.0051) | Acc: (99.91%) (35934/35968)\n",
            "Epoch: 133 | Batch_idx: 290 |  Loss: (0.0051) | Acc: (99.91%) (37214/37248)\n",
            "Epoch: 133 | Batch_idx: 300 |  Loss: (0.0051) | Acc: (99.91%) (38493/38528)\n",
            "Epoch: 133 | Batch_idx: 310 |  Loss: (0.0050) | Acc: (99.91%) (39772/39808)\n",
            "Epoch: 133 | Batch_idx: 320 |  Loss: (0.0050) | Acc: (99.91%) (41052/41088)\n",
            "Epoch: 133 | Batch_idx: 330 |  Loss: (0.0050) | Acc: (99.92%) (42332/42368)\n",
            "Epoch: 133 | Batch_idx: 340 |  Loss: (0.0050) | Acc: (99.92%) (43611/43648)\n",
            "Epoch: 133 | Batch_idx: 350 |  Loss: (0.0050) | Acc: (99.92%) (44890/44928)\n",
            "Epoch: 133 | Batch_idx: 360 |  Loss: (0.0050) | Acc: (99.91%) (46168/46208)\n",
            "Epoch: 133 | Batch_idx: 370 |  Loss: (0.0049) | Acc: (99.91%) (47447/47488)\n",
            "Epoch: 133 | Batch_idx: 380 |  Loss: (0.0049) | Acc: (99.91%) (48726/48768)\n",
            "Epoch: 133 | Batch_idx: 390 |  Loss: (0.0049) | Acc: (99.92%) (49958/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3589) | Acc: (92.61%) (9261/10000)\n",
            "Epoch: 134 | Batch_idx: 0 |  Loss: (0.0118) | Acc: (100.00%) (128/128)\n",
            "Epoch: 134 | Batch_idx: 10 |  Loss: (0.0049) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 134 | Batch_idx: 20 |  Loss: (0.0051) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 134 | Batch_idx: 30 |  Loss: (0.0052) | Acc: (99.95%) (3966/3968)\n",
            "Epoch: 134 | Batch_idx: 40 |  Loss: (0.0054) | Acc: (99.92%) (5244/5248)\n",
            "Epoch: 134 | Batch_idx: 50 |  Loss: (0.0055) | Acc: (99.92%) (6523/6528)\n",
            "Epoch: 134 | Batch_idx: 60 |  Loss: (0.0053) | Acc: (99.94%) (7803/7808)\n",
            "Epoch: 134 | Batch_idx: 70 |  Loss: (0.0050) | Acc: (99.93%) (9082/9088)\n",
            "Epoch: 134 | Batch_idx: 80 |  Loss: (0.0050) | Acc: (99.93%) (10361/10368)\n",
            "Epoch: 134 | Batch_idx: 90 |  Loss: (0.0050) | Acc: (99.94%) (11641/11648)\n",
            "Epoch: 134 | Batch_idx: 100 |  Loss: (0.0051) | Acc: (99.94%) (12920/12928)\n",
            "Epoch: 134 | Batch_idx: 110 |  Loss: (0.0049) | Acc: (99.94%) (14200/14208)\n",
            "Epoch: 134 | Batch_idx: 120 |  Loss: (0.0049) | Acc: (99.94%) (15479/15488)\n",
            "Epoch: 134 | Batch_idx: 130 |  Loss: (0.0048) | Acc: (99.95%) (16759/16768)\n",
            "Epoch: 134 | Batch_idx: 140 |  Loss: (0.0049) | Acc: (99.94%) (18038/18048)\n",
            "Epoch: 134 | Batch_idx: 150 |  Loss: (0.0050) | Acc: (99.94%) (19317/19328)\n",
            "Epoch: 134 | Batch_idx: 160 |  Loss: (0.0051) | Acc: (99.93%) (20593/20608)\n",
            "Epoch: 134 | Batch_idx: 170 |  Loss: (0.0051) | Acc: (99.93%) (21872/21888)\n",
            "Epoch: 134 | Batch_idx: 180 |  Loss: (0.0051) | Acc: (99.93%) (23152/23168)\n",
            "Epoch: 134 | Batch_idx: 190 |  Loss: (0.0051) | Acc: (99.93%) (24431/24448)\n",
            "Epoch: 134 | Batch_idx: 200 |  Loss: (0.0051) | Acc: (99.93%) (25709/25728)\n",
            "Epoch: 134 | Batch_idx: 210 |  Loss: (0.0050) | Acc: (99.93%) (26989/27008)\n",
            "Epoch: 134 | Batch_idx: 220 |  Loss: (0.0050) | Acc: (99.93%) (28269/28288)\n",
            "Epoch: 134 | Batch_idx: 230 |  Loss: (0.0051) | Acc: (99.93%) (29546/29568)\n",
            "Epoch: 134 | Batch_idx: 240 |  Loss: (0.0052) | Acc: (99.92%) (30823/30848)\n",
            "Epoch: 134 | Batch_idx: 250 |  Loss: (0.0053) | Acc: (99.92%) (32101/32128)\n",
            "Epoch: 134 | Batch_idx: 260 |  Loss: (0.0053) | Acc: (99.91%) (33379/33408)\n",
            "Epoch: 134 | Batch_idx: 270 |  Loss: (0.0053) | Acc: (99.92%) (34659/34688)\n",
            "Epoch: 134 | Batch_idx: 280 |  Loss: (0.0053) | Acc: (99.91%) (35937/35968)\n",
            "Epoch: 134 | Batch_idx: 290 |  Loss: (0.0052) | Acc: (99.91%) (37216/37248)\n",
            "Epoch: 134 | Batch_idx: 300 |  Loss: (0.0053) | Acc: (99.91%) (38494/38528)\n",
            "Epoch: 134 | Batch_idx: 310 |  Loss: (0.0052) | Acc: (99.91%) (39774/39808)\n",
            "Epoch: 134 | Batch_idx: 320 |  Loss: (0.0051) | Acc: (99.91%) (41052/41088)\n",
            "Epoch: 134 | Batch_idx: 330 |  Loss: (0.0051) | Acc: (99.91%) (42330/42368)\n",
            "Epoch: 134 | Batch_idx: 340 |  Loss: (0.0052) | Acc: (99.91%) (43608/43648)\n",
            "Epoch: 134 | Batch_idx: 350 |  Loss: (0.0052) | Acc: (99.91%) (44887/44928)\n",
            "Epoch: 134 | Batch_idx: 360 |  Loss: (0.0052) | Acc: (99.91%) (46166/46208)\n",
            "Epoch: 134 | Batch_idx: 370 |  Loss: (0.0052) | Acc: (99.91%) (47446/47488)\n",
            "Epoch: 134 | Batch_idx: 380 |  Loss: (0.0051) | Acc: (99.91%) (48725/48768)\n",
            "Epoch: 134 | Batch_idx: 390 |  Loss: (0.0051) | Acc: (99.91%) (49957/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3562) | Acc: (92.70%) (9270/10000)\n",
            "Epoch: 135 | Batch_idx: 0 |  Loss: (0.0019) | Acc: (100.00%) (128/128)\n",
            "Epoch: 135 | Batch_idx: 10 |  Loss: (0.0052) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 135 | Batch_idx: 20 |  Loss: (0.0045) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 135 | Batch_idx: 30 |  Loss: (0.0045) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 135 | Batch_idx: 40 |  Loss: (0.0041) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 135 | Batch_idx: 50 |  Loss: (0.0040) | Acc: (99.95%) (6525/6528)\n",
            "Epoch: 135 | Batch_idx: 60 |  Loss: (0.0040) | Acc: (99.95%) (7804/7808)\n",
            "Epoch: 135 | Batch_idx: 70 |  Loss: (0.0045) | Acc: (99.93%) (9082/9088)\n",
            "Epoch: 135 | Batch_idx: 80 |  Loss: (0.0047) | Acc: (99.91%) (10359/10368)\n",
            "Epoch: 135 | Batch_idx: 90 |  Loss: (0.0048) | Acc: (99.91%) (11637/11648)\n",
            "Epoch: 135 | Batch_idx: 100 |  Loss: (0.0049) | Acc: (99.91%) (12916/12928)\n",
            "Epoch: 135 | Batch_idx: 110 |  Loss: (0.0049) | Acc: (99.91%) (14195/14208)\n",
            "Epoch: 135 | Batch_idx: 120 |  Loss: (0.0049) | Acc: (99.90%) (15473/15488)\n",
            "Epoch: 135 | Batch_idx: 130 |  Loss: (0.0049) | Acc: (99.90%) (16751/16768)\n",
            "Epoch: 135 | Batch_idx: 140 |  Loss: (0.0049) | Acc: (99.90%) (18030/18048)\n",
            "Epoch: 135 | Batch_idx: 150 |  Loss: (0.0049) | Acc: (99.90%) (19309/19328)\n",
            "Epoch: 135 | Batch_idx: 160 |  Loss: (0.0048) | Acc: (99.90%) (20588/20608)\n",
            "Epoch: 135 | Batch_idx: 170 |  Loss: (0.0048) | Acc: (99.90%) (21867/21888)\n",
            "Epoch: 135 | Batch_idx: 180 |  Loss: (0.0049) | Acc: (99.91%) (23146/23168)\n",
            "Epoch: 135 | Batch_idx: 190 |  Loss: (0.0048) | Acc: (99.91%) (24425/24448)\n",
            "Epoch: 135 | Batch_idx: 200 |  Loss: (0.0048) | Acc: (99.90%) (25703/25728)\n",
            "Epoch: 135 | Batch_idx: 210 |  Loss: (0.0049) | Acc: (99.90%) (26981/27008)\n",
            "Epoch: 135 | Batch_idx: 220 |  Loss: (0.0050) | Acc: (99.89%) (28258/28288)\n",
            "Epoch: 135 | Batch_idx: 230 |  Loss: (0.0050) | Acc: (99.90%) (29538/29568)\n",
            "Epoch: 135 | Batch_idx: 240 |  Loss: (0.0049) | Acc: (99.90%) (30818/30848)\n",
            "Epoch: 135 | Batch_idx: 250 |  Loss: (0.0049) | Acc: (99.90%) (32097/32128)\n",
            "Epoch: 135 | Batch_idx: 260 |  Loss: (0.0049) | Acc: (99.90%) (33375/33408)\n",
            "Epoch: 135 | Batch_idx: 270 |  Loss: (0.0050) | Acc: (99.90%) (34654/34688)\n",
            "Epoch: 135 | Batch_idx: 280 |  Loss: (0.0049) | Acc: (99.91%) (35934/35968)\n",
            "Epoch: 135 | Batch_idx: 290 |  Loss: (0.0049) | Acc: (99.91%) (37213/37248)\n",
            "Epoch: 135 | Batch_idx: 300 |  Loss: (0.0049) | Acc: (99.91%) (38493/38528)\n",
            "Epoch: 135 | Batch_idx: 310 |  Loss: (0.0049) | Acc: (99.91%) (39771/39808)\n",
            "Epoch: 135 | Batch_idx: 320 |  Loss: (0.0051) | Acc: (99.91%) (41049/41088)\n",
            "Epoch: 135 | Batch_idx: 330 |  Loss: (0.0052) | Acc: (99.90%) (42326/42368)\n",
            "Epoch: 135 | Batch_idx: 340 |  Loss: (0.0052) | Acc: (99.90%) (43604/43648)\n",
            "Epoch: 135 | Batch_idx: 350 |  Loss: (0.0052) | Acc: (99.90%) (44883/44928)\n",
            "Epoch: 135 | Batch_idx: 360 |  Loss: (0.0052) | Acc: (99.90%) (46161/46208)\n",
            "Epoch: 135 | Batch_idx: 370 |  Loss: (0.0052) | Acc: (99.90%) (47440/47488)\n",
            "Epoch: 135 | Batch_idx: 380 |  Loss: (0.0052) | Acc: (99.90%) (48717/48768)\n",
            "Epoch: 135 | Batch_idx: 390 |  Loss: (0.0053) | Acc: (99.89%) (49947/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3543) | Acc: (92.60%) (9260/10000)\n",
            "Epoch: 136 | Batch_idx: 0 |  Loss: (0.0022) | Acc: (100.00%) (128/128)\n",
            "Epoch: 136 | Batch_idx: 10 |  Loss: (0.0074) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 136 | Batch_idx: 20 |  Loss: (0.0069) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 136 | Batch_idx: 30 |  Loss: (0.0059) | Acc: (99.82%) (3961/3968)\n",
            "Epoch: 136 | Batch_idx: 40 |  Loss: (0.0055) | Acc: (99.87%) (5241/5248)\n",
            "Epoch: 136 | Batch_idx: 50 |  Loss: (0.0058) | Acc: (99.88%) (6520/6528)\n",
            "Epoch: 136 | Batch_idx: 60 |  Loss: (0.0059) | Acc: (99.86%) (7797/7808)\n",
            "Epoch: 136 | Batch_idx: 70 |  Loss: (0.0057) | Acc: (99.87%) (9076/9088)\n",
            "Epoch: 136 | Batch_idx: 80 |  Loss: (0.0058) | Acc: (99.86%) (10353/10368)\n",
            "Epoch: 136 | Batch_idx: 90 |  Loss: (0.0058) | Acc: (99.86%) (11632/11648)\n",
            "Epoch: 136 | Batch_idx: 100 |  Loss: (0.0056) | Acc: (99.87%) (12911/12928)\n",
            "Epoch: 136 | Batch_idx: 110 |  Loss: (0.0055) | Acc: (99.87%) (14189/14208)\n",
            "Epoch: 136 | Batch_idx: 120 |  Loss: (0.0059) | Acc: (99.86%) (15466/15488)\n",
            "Epoch: 136 | Batch_idx: 130 |  Loss: (0.0057) | Acc: (99.87%) (16746/16768)\n",
            "Epoch: 136 | Batch_idx: 140 |  Loss: (0.0055) | Acc: (99.88%) (18026/18048)\n",
            "Epoch: 136 | Batch_idx: 150 |  Loss: (0.0054) | Acc: (99.88%) (19304/19328)\n",
            "Epoch: 136 | Batch_idx: 160 |  Loss: (0.0053) | Acc: (99.88%) (20584/20608)\n",
            "Epoch: 136 | Batch_idx: 170 |  Loss: (0.0053) | Acc: (99.88%) (21862/21888)\n",
            "Epoch: 136 | Batch_idx: 180 |  Loss: (0.0053) | Acc: (99.89%) (23142/23168)\n",
            "Epoch: 136 | Batch_idx: 190 |  Loss: (0.0052) | Acc: (99.89%) (24421/24448)\n",
            "Epoch: 136 | Batch_idx: 200 |  Loss: (0.0054) | Acc: (99.88%) (25698/25728)\n",
            "Epoch: 136 | Batch_idx: 210 |  Loss: (0.0054) | Acc: (99.89%) (26977/27008)\n",
            "Epoch: 136 | Batch_idx: 220 |  Loss: (0.0054) | Acc: (99.89%) (28256/28288)\n",
            "Epoch: 136 | Batch_idx: 230 |  Loss: (0.0055) | Acc: (99.88%) (29532/29568)\n",
            "Epoch: 136 | Batch_idx: 240 |  Loss: (0.0054) | Acc: (99.88%) (30811/30848)\n",
            "Epoch: 136 | Batch_idx: 250 |  Loss: (0.0053) | Acc: (99.88%) (32091/32128)\n",
            "Epoch: 136 | Batch_idx: 260 |  Loss: (0.0053) | Acc: (99.88%) (33368/33408)\n",
            "Epoch: 136 | Batch_idx: 270 |  Loss: (0.0053) | Acc: (99.88%) (34646/34688)\n",
            "Epoch: 136 | Batch_idx: 280 |  Loss: (0.0053) | Acc: (99.88%) (35926/35968)\n",
            "Epoch: 136 | Batch_idx: 290 |  Loss: (0.0052) | Acc: (99.89%) (37206/37248)\n",
            "Epoch: 136 | Batch_idx: 300 |  Loss: (0.0052) | Acc: (99.89%) (38485/38528)\n",
            "Epoch: 136 | Batch_idx: 310 |  Loss: (0.0052) | Acc: (99.89%) (39765/39808)\n",
            "Epoch: 136 | Batch_idx: 320 |  Loss: (0.0052) | Acc: (99.89%) (41044/41088)\n",
            "Epoch: 136 | Batch_idx: 330 |  Loss: (0.0052) | Acc: (99.89%) (42322/42368)\n",
            "Epoch: 136 | Batch_idx: 340 |  Loss: (0.0051) | Acc: (99.89%) (43602/43648)\n",
            "Epoch: 136 | Batch_idx: 350 |  Loss: (0.0051) | Acc: (99.90%) (44882/44928)\n",
            "Epoch: 136 | Batch_idx: 360 |  Loss: (0.0051) | Acc: (99.90%) (46161/46208)\n",
            "Epoch: 136 | Batch_idx: 370 |  Loss: (0.0050) | Acc: (99.90%) (47441/47488)\n",
            "Epoch: 136 | Batch_idx: 380 |  Loss: (0.0051) | Acc: (99.90%) (48718/48768)\n",
            "Epoch: 136 | Batch_idx: 390 |  Loss: (0.0051) | Acc: (99.90%) (49950/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3560) | Acc: (92.61%) (9261/10000)\n",
            "Epoch: 137 | Batch_idx: 0 |  Loss: (0.0035) | Acc: (100.00%) (128/128)\n",
            "Epoch: 137 | Batch_idx: 10 |  Loss: (0.0039) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 137 | Batch_idx: 20 |  Loss: (0.0039) | Acc: (100.00%) (2688/2688)\n",
            "Epoch: 137 | Batch_idx: 30 |  Loss: (0.0039) | Acc: (99.97%) (3967/3968)\n",
            "Epoch: 137 | Batch_idx: 40 |  Loss: (0.0037) | Acc: (99.98%) (5247/5248)\n",
            "Epoch: 137 | Batch_idx: 50 |  Loss: (0.0037) | Acc: (99.98%) (6527/6528)\n",
            "Epoch: 137 | Batch_idx: 60 |  Loss: (0.0040) | Acc: (99.96%) (7805/7808)\n",
            "Epoch: 137 | Batch_idx: 70 |  Loss: (0.0040) | Acc: (99.97%) (9085/9088)\n",
            "Epoch: 137 | Batch_idx: 80 |  Loss: (0.0043) | Acc: (99.94%) (10362/10368)\n",
            "Epoch: 137 | Batch_idx: 90 |  Loss: (0.0043) | Acc: (99.95%) (11642/11648)\n",
            "Epoch: 137 | Batch_idx: 100 |  Loss: (0.0044) | Acc: (99.94%) (12920/12928)\n",
            "Epoch: 137 | Batch_idx: 110 |  Loss: (0.0044) | Acc: (99.94%) (14199/14208)\n",
            "Epoch: 137 | Batch_idx: 120 |  Loss: (0.0046) | Acc: (99.92%) (15475/15488)\n",
            "Epoch: 137 | Batch_idx: 130 |  Loss: (0.0047) | Acc: (99.92%) (16754/16768)\n",
            "Epoch: 137 | Batch_idx: 140 |  Loss: (0.0048) | Acc: (99.92%) (18033/18048)\n",
            "Epoch: 137 | Batch_idx: 150 |  Loss: (0.0048) | Acc: (99.92%) (19312/19328)\n",
            "Epoch: 137 | Batch_idx: 160 |  Loss: (0.0049) | Acc: (99.91%) (20590/20608)\n",
            "Epoch: 137 | Batch_idx: 170 |  Loss: (0.0049) | Acc: (99.92%) (21870/21888)\n",
            "Epoch: 137 | Batch_idx: 180 |  Loss: (0.0049) | Acc: (99.92%) (23149/23168)\n",
            "Epoch: 137 | Batch_idx: 190 |  Loss: (0.0049) | Acc: (99.92%) (24428/24448)\n",
            "Epoch: 137 | Batch_idx: 200 |  Loss: (0.0049) | Acc: (99.91%) (25706/25728)\n",
            "Epoch: 137 | Batch_idx: 210 |  Loss: (0.0049) | Acc: (99.91%) (26984/27008)\n",
            "Epoch: 137 | Batch_idx: 220 |  Loss: (0.0048) | Acc: (99.92%) (28264/28288)\n",
            "Epoch: 137 | Batch_idx: 230 |  Loss: (0.0049) | Acc: (99.91%) (29542/29568)\n",
            "Epoch: 137 | Batch_idx: 240 |  Loss: (0.0048) | Acc: (99.91%) (30821/30848)\n",
            "Epoch: 137 | Batch_idx: 250 |  Loss: (0.0048) | Acc: (99.91%) (32100/32128)\n",
            "Epoch: 137 | Batch_idx: 260 |  Loss: (0.0048) | Acc: (99.91%) (33379/33408)\n",
            "Epoch: 137 | Batch_idx: 270 |  Loss: (0.0048) | Acc: (99.92%) (34659/34688)\n",
            "Epoch: 137 | Batch_idx: 280 |  Loss: (0.0048) | Acc: (99.92%) (35938/35968)\n",
            "Epoch: 137 | Batch_idx: 290 |  Loss: (0.0048) | Acc: (99.92%) (37218/37248)\n",
            "Epoch: 137 | Batch_idx: 300 |  Loss: (0.0049) | Acc: (99.92%) (38496/38528)\n",
            "Epoch: 137 | Batch_idx: 310 |  Loss: (0.0048) | Acc: (99.92%) (39775/39808)\n",
            "Epoch: 137 | Batch_idx: 320 |  Loss: (0.0048) | Acc: (99.92%) (41054/41088)\n",
            "Epoch: 137 | Batch_idx: 330 |  Loss: (0.0048) | Acc: (99.92%) (42334/42368)\n",
            "Epoch: 137 | Batch_idx: 340 |  Loss: (0.0048) | Acc: (99.91%) (43610/43648)\n",
            "Epoch: 137 | Batch_idx: 350 |  Loss: (0.0049) | Acc: (99.91%) (44888/44928)\n",
            "Epoch: 137 | Batch_idx: 360 |  Loss: (0.0049) | Acc: (99.91%) (46167/46208)\n",
            "Epoch: 137 | Batch_idx: 370 |  Loss: (0.0049) | Acc: (99.91%) (47446/47488)\n",
            "Epoch: 137 | Batch_idx: 380 |  Loss: (0.0048) | Acc: (99.91%) (48725/48768)\n",
            "Epoch: 137 | Batch_idx: 390 |  Loss: (0.0048) | Acc: (99.91%) (49957/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3557) | Acc: (92.66%) (9266/10000)\n",
            "Epoch: 138 | Batch_idx: 0 |  Loss: (0.0041) | Acc: (100.00%) (128/128)\n",
            "Epoch: 138 | Batch_idx: 10 |  Loss: (0.0060) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 138 | Batch_idx: 20 |  Loss: (0.0070) | Acc: (99.81%) (2683/2688)\n",
            "Epoch: 138 | Batch_idx: 30 |  Loss: (0.0062) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 138 | Batch_idx: 40 |  Loss: (0.0065) | Acc: (99.85%) (5240/5248)\n",
            "Epoch: 138 | Batch_idx: 50 |  Loss: (0.0059) | Acc: (99.86%) (6519/6528)\n",
            "Epoch: 138 | Batch_idx: 60 |  Loss: (0.0060) | Acc: (99.86%) (7797/7808)\n",
            "Epoch: 138 | Batch_idx: 70 |  Loss: (0.0062) | Acc: (99.83%) (9073/9088)\n",
            "Epoch: 138 | Batch_idx: 80 |  Loss: (0.0059) | Acc: (99.85%) (10352/10368)\n",
            "Epoch: 138 | Batch_idx: 90 |  Loss: (0.0057) | Acc: (99.86%) (11632/11648)\n",
            "Epoch: 138 | Batch_idx: 100 |  Loss: (0.0055) | Acc: (99.87%) (12911/12928)\n",
            "Epoch: 138 | Batch_idx: 110 |  Loss: (0.0055) | Acc: (99.86%) (14188/14208)\n",
            "Epoch: 138 | Batch_idx: 120 |  Loss: (0.0053) | Acc: (99.87%) (15468/15488)\n",
            "Epoch: 138 | Batch_idx: 130 |  Loss: (0.0052) | Acc: (99.87%) (16747/16768)\n",
            "Epoch: 138 | Batch_idx: 140 |  Loss: (0.0051) | Acc: (99.88%) (18026/18048)\n",
            "Epoch: 138 | Batch_idx: 150 |  Loss: (0.0050) | Acc: (99.89%) (19306/19328)\n",
            "Epoch: 138 | Batch_idx: 160 |  Loss: (0.0050) | Acc: (99.89%) (20585/20608)\n",
            "Epoch: 138 | Batch_idx: 170 |  Loss: (0.0049) | Acc: (99.89%) (21865/21888)\n",
            "Epoch: 138 | Batch_idx: 180 |  Loss: (0.0049) | Acc: (99.90%) (23144/23168)\n",
            "Epoch: 138 | Batch_idx: 190 |  Loss: (0.0049) | Acc: (99.89%) (24422/24448)\n",
            "Epoch: 138 | Batch_idx: 200 |  Loss: (0.0049) | Acc: (99.90%) (25701/25728)\n",
            "Epoch: 138 | Batch_idx: 210 |  Loss: (0.0051) | Acc: (99.89%) (26977/27008)\n",
            "Epoch: 138 | Batch_idx: 220 |  Loss: (0.0051) | Acc: (99.88%) (28255/28288)\n",
            "Epoch: 138 | Batch_idx: 230 |  Loss: (0.0052) | Acc: (99.88%) (29533/29568)\n",
            "Epoch: 138 | Batch_idx: 240 |  Loss: (0.0051) | Acc: (99.88%) (30812/30848)\n",
            "Epoch: 138 | Batch_idx: 250 |  Loss: (0.0051) | Acc: (99.88%) (32091/32128)\n",
            "Epoch: 138 | Batch_idx: 260 |  Loss: (0.0051) | Acc: (99.89%) (33371/33408)\n",
            "Epoch: 138 | Batch_idx: 270 |  Loss: (0.0051) | Acc: (99.88%) (34648/34688)\n",
            "Epoch: 138 | Batch_idx: 280 |  Loss: (0.0051) | Acc: (99.89%) (35928/35968)\n",
            "Epoch: 138 | Batch_idx: 290 |  Loss: (0.0051) | Acc: (99.89%) (37207/37248)\n",
            "Epoch: 138 | Batch_idx: 300 |  Loss: (0.0050) | Acc: (99.89%) (38486/38528)\n",
            "Epoch: 138 | Batch_idx: 310 |  Loss: (0.0051) | Acc: (99.89%) (39764/39808)\n",
            "Epoch: 138 | Batch_idx: 320 |  Loss: (0.0052) | Acc: (99.89%) (41043/41088)\n",
            "Epoch: 138 | Batch_idx: 330 |  Loss: (0.0051) | Acc: (99.89%) (42323/42368)\n",
            "Epoch: 138 | Batch_idx: 340 |  Loss: (0.0051) | Acc: (99.89%) (43602/43648)\n",
            "Epoch: 138 | Batch_idx: 350 |  Loss: (0.0050) | Acc: (99.90%) (44881/44928)\n",
            "Epoch: 138 | Batch_idx: 360 |  Loss: (0.0050) | Acc: (99.90%) (46161/46208)\n",
            "Epoch: 138 | Batch_idx: 370 |  Loss: (0.0049) | Acc: (99.90%) (47441/47488)\n",
            "Epoch: 138 | Batch_idx: 380 |  Loss: (0.0049) | Acc: (99.90%) (48721/48768)\n",
            "Epoch: 138 | Batch_idx: 390 |  Loss: (0.0049) | Acc: (99.90%) (49951/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3559) | Acc: (92.73%) (9273/10000)\n",
            "Epoch: 139 | Batch_idx: 0 |  Loss: (0.0027) | Acc: (100.00%) (128/128)\n",
            "Epoch: 139 | Batch_idx: 10 |  Loss: (0.0054) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 139 | Batch_idx: 20 |  Loss: (0.0052) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 139 | Batch_idx: 30 |  Loss: (0.0058) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 139 | Batch_idx: 40 |  Loss: (0.0057) | Acc: (99.87%) (5241/5248)\n",
            "Epoch: 139 | Batch_idx: 50 |  Loss: (0.0052) | Acc: (99.89%) (6521/6528)\n",
            "Epoch: 139 | Batch_idx: 60 |  Loss: (0.0057) | Acc: (99.88%) (7799/7808)\n",
            "Epoch: 139 | Batch_idx: 70 |  Loss: (0.0053) | Acc: (99.89%) (9078/9088)\n",
            "Epoch: 139 | Batch_idx: 80 |  Loss: (0.0057) | Acc: (99.88%) (10356/10368)\n",
            "Epoch: 139 | Batch_idx: 90 |  Loss: (0.0057) | Acc: (99.90%) (11636/11648)\n",
            "Epoch: 139 | Batch_idx: 100 |  Loss: (0.0061) | Acc: (99.88%) (12912/12928)\n",
            "Epoch: 139 | Batch_idx: 110 |  Loss: (0.0061) | Acc: (99.88%) (14191/14208)\n",
            "Epoch: 139 | Batch_idx: 120 |  Loss: (0.0059) | Acc: (99.88%) (15470/15488)\n",
            "Epoch: 139 | Batch_idx: 130 |  Loss: (0.0058) | Acc: (99.89%) (16749/16768)\n",
            "Epoch: 139 | Batch_idx: 140 |  Loss: (0.0058) | Acc: (99.89%) (18028/18048)\n",
            "Epoch: 139 | Batch_idx: 150 |  Loss: (0.0057) | Acc: (99.90%) (19308/19328)\n",
            "Epoch: 139 | Batch_idx: 160 |  Loss: (0.0056) | Acc: (99.90%) (20587/20608)\n",
            "Epoch: 139 | Batch_idx: 170 |  Loss: (0.0055) | Acc: (99.90%) (21866/21888)\n",
            "Epoch: 139 | Batch_idx: 180 |  Loss: (0.0054) | Acc: (99.91%) (23146/23168)\n",
            "Epoch: 139 | Batch_idx: 190 |  Loss: (0.0053) | Acc: (99.91%) (24425/24448)\n",
            "Epoch: 139 | Batch_idx: 200 |  Loss: (0.0053) | Acc: (99.91%) (25705/25728)\n",
            "Epoch: 139 | Batch_idx: 210 |  Loss: (0.0051) | Acc: (99.91%) (26985/27008)\n",
            "Epoch: 139 | Batch_idx: 220 |  Loss: (0.0052) | Acc: (99.92%) (28264/28288)\n",
            "Epoch: 139 | Batch_idx: 230 |  Loss: (0.0051) | Acc: (99.92%) (29544/29568)\n",
            "Epoch: 139 | Batch_idx: 240 |  Loss: (0.0051) | Acc: (99.92%) (30822/30848)\n",
            "Epoch: 139 | Batch_idx: 250 |  Loss: (0.0050) | Acc: (99.92%) (32101/32128)\n",
            "Epoch: 139 | Batch_idx: 260 |  Loss: (0.0050) | Acc: (99.92%) (33380/33408)\n",
            "Epoch: 139 | Batch_idx: 270 |  Loss: (0.0050) | Acc: (99.91%) (34658/34688)\n",
            "Epoch: 139 | Batch_idx: 280 |  Loss: (0.0050) | Acc: (99.91%) (35936/35968)\n",
            "Epoch: 139 | Batch_idx: 290 |  Loss: (0.0050) | Acc: (99.91%) (37214/37248)\n",
            "Epoch: 139 | Batch_idx: 300 |  Loss: (0.0050) | Acc: (99.90%) (38491/38528)\n",
            "Epoch: 139 | Batch_idx: 310 |  Loss: (0.0050) | Acc: (99.90%) (39770/39808)\n",
            "Epoch: 139 | Batch_idx: 320 |  Loss: (0.0050) | Acc: (99.91%) (41050/41088)\n",
            "Epoch: 139 | Batch_idx: 330 |  Loss: (0.0051) | Acc: (99.91%) (42328/42368)\n",
            "Epoch: 139 | Batch_idx: 340 |  Loss: (0.0050) | Acc: (99.91%) (43608/43648)\n",
            "Epoch: 139 | Batch_idx: 350 |  Loss: (0.0051) | Acc: (99.91%) (44886/44928)\n",
            "Epoch: 139 | Batch_idx: 360 |  Loss: (0.0050) | Acc: (99.91%) (46166/46208)\n",
            "Epoch: 139 | Batch_idx: 370 |  Loss: (0.0050) | Acc: (99.91%) (47444/47488)\n",
            "Epoch: 139 | Batch_idx: 380 |  Loss: (0.0050) | Acc: (99.91%) (48723/48768)\n",
            "Epoch: 139 | Batch_idx: 390 |  Loss: (0.0051) | Acc: (99.90%) (49952/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3546) | Acc: (92.73%) (9273/10000)\n",
            "Epoch: 140 | Batch_idx: 0 |  Loss: (0.0042) | Acc: (100.00%) (128/128)\n",
            "Epoch: 140 | Batch_idx: 10 |  Loss: (0.0073) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 140 | Batch_idx: 20 |  Loss: (0.0061) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 140 | Batch_idx: 30 |  Loss: (0.0055) | Acc: (99.90%) (3964/3968)\n",
            "Epoch: 140 | Batch_idx: 40 |  Loss: (0.0056) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 140 | Batch_idx: 50 |  Loss: (0.0052) | Acc: (99.91%) (6522/6528)\n",
            "Epoch: 140 | Batch_idx: 60 |  Loss: (0.0053) | Acc: (99.91%) (7801/7808)\n",
            "Epoch: 140 | Batch_idx: 70 |  Loss: (0.0052) | Acc: (99.91%) (9080/9088)\n",
            "Epoch: 140 | Batch_idx: 80 |  Loss: (0.0050) | Acc: (99.91%) (10359/10368)\n",
            "Epoch: 140 | Batch_idx: 90 |  Loss: (0.0050) | Acc: (99.92%) (11639/11648)\n",
            "Epoch: 140 | Batch_idx: 100 |  Loss: (0.0049) | Acc: (99.92%) (12918/12928)\n",
            "Epoch: 140 | Batch_idx: 110 |  Loss: (0.0048) | Acc: (99.92%) (14196/14208)\n",
            "Epoch: 140 | Batch_idx: 120 |  Loss: (0.0049) | Acc: (99.92%) (15475/15488)\n",
            "Epoch: 140 | Batch_idx: 130 |  Loss: (0.0049) | Acc: (99.92%) (16754/16768)\n",
            "Epoch: 140 | Batch_idx: 140 |  Loss: (0.0050) | Acc: (99.91%) (18032/18048)\n",
            "Epoch: 140 | Batch_idx: 150 |  Loss: (0.0050) | Acc: (99.91%) (19310/19328)\n",
            "Epoch: 140 | Batch_idx: 160 |  Loss: (0.0051) | Acc: (99.90%) (20588/20608)\n",
            "Epoch: 140 | Batch_idx: 170 |  Loss: (0.0051) | Acc: (99.90%) (21867/21888)\n",
            "Epoch: 140 | Batch_idx: 180 |  Loss: (0.0051) | Acc: (99.91%) (23146/23168)\n",
            "Epoch: 140 | Batch_idx: 190 |  Loss: (0.0050) | Acc: (99.91%) (24426/24448)\n",
            "Epoch: 140 | Batch_idx: 200 |  Loss: (0.0050) | Acc: (99.91%) (25704/25728)\n",
            "Epoch: 140 | Batch_idx: 210 |  Loss: (0.0049) | Acc: (99.91%) (26984/27008)\n",
            "Epoch: 140 | Batch_idx: 220 |  Loss: (0.0049) | Acc: (99.91%) (28262/28288)\n",
            "Epoch: 140 | Batch_idx: 230 |  Loss: (0.0049) | Acc: (99.91%) (29542/29568)\n",
            "Epoch: 140 | Batch_idx: 240 |  Loss: (0.0048) | Acc: (99.91%) (30820/30848)\n",
            "Epoch: 140 | Batch_idx: 250 |  Loss: (0.0049) | Acc: (99.90%) (32097/32128)\n",
            "Epoch: 140 | Batch_idx: 260 |  Loss: (0.0049) | Acc: (99.91%) (33377/33408)\n",
            "Epoch: 140 | Batch_idx: 270 |  Loss: (0.0049) | Acc: (99.90%) (34655/34688)\n",
            "Epoch: 140 | Batch_idx: 280 |  Loss: (0.0050) | Acc: (99.91%) (35934/35968)\n",
            "Epoch: 140 | Batch_idx: 290 |  Loss: (0.0049) | Acc: (99.91%) (37214/37248)\n",
            "Epoch: 140 | Batch_idx: 300 |  Loss: (0.0049) | Acc: (99.91%) (38494/38528)\n",
            "Epoch: 140 | Batch_idx: 310 |  Loss: (0.0048) | Acc: (99.91%) (39774/39808)\n",
            "Epoch: 140 | Batch_idx: 320 |  Loss: (0.0050) | Acc: (99.91%) (41052/41088)\n",
            "Epoch: 140 | Batch_idx: 330 |  Loss: (0.0050) | Acc: (99.91%) (42331/42368)\n",
            "Epoch: 140 | Batch_idx: 340 |  Loss: (0.0049) | Acc: (99.92%) (43611/43648)\n",
            "Epoch: 140 | Batch_idx: 350 |  Loss: (0.0049) | Acc: (99.92%) (44890/44928)\n",
            "Epoch: 140 | Batch_idx: 360 |  Loss: (0.0049) | Acc: (99.92%) (46170/46208)\n",
            "Epoch: 140 | Batch_idx: 370 |  Loss: (0.0049) | Acc: (99.92%) (47449/47488)\n",
            "Epoch: 140 | Batch_idx: 380 |  Loss: (0.0049) | Acc: (99.92%) (48728/48768)\n",
            "Epoch: 140 | Batch_idx: 390 |  Loss: (0.0049) | Acc: (99.92%) (49960/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3517) | Acc: (92.69%) (9269/10000)\n",
            "Epoch: 141 | Batch_idx: 0 |  Loss: (0.0022) | Acc: (100.00%) (128/128)\n",
            "Epoch: 141 | Batch_idx: 10 |  Loss: (0.0043) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 141 | Batch_idx: 20 |  Loss: (0.0041) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 141 | Batch_idx: 30 |  Loss: (0.0039) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 141 | Batch_idx: 40 |  Loss: (0.0039) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 141 | Batch_idx: 50 |  Loss: (0.0036) | Acc: (99.95%) (6525/6528)\n",
            "Epoch: 141 | Batch_idx: 60 |  Loss: (0.0038) | Acc: (99.95%) (7804/7808)\n",
            "Epoch: 141 | Batch_idx: 70 |  Loss: (0.0041) | Acc: (99.94%) (9083/9088)\n",
            "Epoch: 141 | Batch_idx: 80 |  Loss: (0.0039) | Acc: (99.95%) (10363/10368)\n",
            "Epoch: 141 | Batch_idx: 90 |  Loss: (0.0039) | Acc: (99.95%) (11642/11648)\n",
            "Epoch: 141 | Batch_idx: 100 |  Loss: (0.0038) | Acc: (99.95%) (12922/12928)\n",
            "Epoch: 141 | Batch_idx: 110 |  Loss: (0.0041) | Acc: (99.94%) (14199/14208)\n",
            "Epoch: 141 | Batch_idx: 120 |  Loss: (0.0041) | Acc: (99.94%) (15478/15488)\n",
            "Epoch: 141 | Batch_idx: 130 |  Loss: (0.0040) | Acc: (99.94%) (16758/16768)\n",
            "Epoch: 141 | Batch_idx: 140 |  Loss: (0.0040) | Acc: (99.93%) (18036/18048)\n",
            "Epoch: 141 | Batch_idx: 150 |  Loss: (0.0040) | Acc: (99.94%) (19316/19328)\n",
            "Epoch: 141 | Batch_idx: 160 |  Loss: (0.0039) | Acc: (99.94%) (20595/20608)\n",
            "Epoch: 141 | Batch_idx: 170 |  Loss: (0.0039) | Acc: (99.94%) (21875/21888)\n",
            "Epoch: 141 | Batch_idx: 180 |  Loss: (0.0040) | Acc: (99.94%) (23153/23168)\n",
            "Epoch: 141 | Batch_idx: 190 |  Loss: (0.0041) | Acc: (99.94%) (24433/24448)\n",
            "Epoch: 141 | Batch_idx: 200 |  Loss: (0.0041) | Acc: (99.94%) (25712/25728)\n",
            "Epoch: 141 | Batch_idx: 210 |  Loss: (0.0041) | Acc: (99.94%) (26991/27008)\n",
            "Epoch: 141 | Batch_idx: 220 |  Loss: (0.0040) | Acc: (99.94%) (28271/28288)\n",
            "Epoch: 141 | Batch_idx: 230 |  Loss: (0.0041) | Acc: (99.94%) (29550/29568)\n",
            "Epoch: 141 | Batch_idx: 240 |  Loss: (0.0042) | Acc: (99.94%) (30828/30848)\n",
            "Epoch: 141 | Batch_idx: 250 |  Loss: (0.0041) | Acc: (99.94%) (32108/32128)\n",
            "Epoch: 141 | Batch_idx: 260 |  Loss: (0.0042) | Acc: (99.93%) (33385/33408)\n",
            "Epoch: 141 | Batch_idx: 270 |  Loss: (0.0042) | Acc: (99.93%) (34665/34688)\n",
            "Epoch: 141 | Batch_idx: 280 |  Loss: (0.0043) | Acc: (99.93%) (35943/35968)\n",
            "Epoch: 141 | Batch_idx: 290 |  Loss: (0.0043) | Acc: (99.93%) (37223/37248)\n",
            "Epoch: 141 | Batch_idx: 300 |  Loss: (0.0043) | Acc: (99.94%) (38503/38528)\n",
            "Epoch: 141 | Batch_idx: 310 |  Loss: (0.0042) | Acc: (99.93%) (39781/39808)\n",
            "Epoch: 141 | Batch_idx: 320 |  Loss: (0.0042) | Acc: (99.93%) (41061/41088)\n",
            "Epoch: 141 | Batch_idx: 330 |  Loss: (0.0043) | Acc: (99.93%) (42340/42368)\n",
            "Epoch: 141 | Batch_idx: 340 |  Loss: (0.0044) | Acc: (99.93%) (43618/43648)\n",
            "Epoch: 141 | Batch_idx: 350 |  Loss: (0.0044) | Acc: (99.93%) (44897/44928)\n",
            "Epoch: 141 | Batch_idx: 360 |  Loss: (0.0043) | Acc: (99.93%) (46176/46208)\n",
            "Epoch: 141 | Batch_idx: 370 |  Loss: (0.0044) | Acc: (99.93%) (47455/47488)\n",
            "Epoch: 141 | Batch_idx: 380 |  Loss: (0.0044) | Acc: (99.93%) (48735/48768)\n",
            "Epoch: 141 | Batch_idx: 390 |  Loss: (0.0044) | Acc: (99.93%) (49966/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3549) | Acc: (92.58%) (9258/10000)\n",
            "Epoch: 142 | Batch_idx: 0 |  Loss: (0.0070) | Acc: (100.00%) (128/128)\n",
            "Epoch: 142 | Batch_idx: 10 |  Loss: (0.0040) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 142 | Batch_idx: 20 |  Loss: (0.0038) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 142 | Batch_idx: 30 |  Loss: (0.0034) | Acc: (99.97%) (3967/3968)\n",
            "Epoch: 142 | Batch_idx: 40 |  Loss: (0.0040) | Acc: (99.96%) (5246/5248)\n",
            "Epoch: 142 | Batch_idx: 50 |  Loss: (0.0045) | Acc: (99.92%) (6523/6528)\n",
            "Epoch: 142 | Batch_idx: 60 |  Loss: (0.0044) | Acc: (99.92%) (7802/7808)\n",
            "Epoch: 142 | Batch_idx: 70 |  Loss: (0.0043) | Acc: (99.92%) (9081/9088)\n",
            "Epoch: 142 | Batch_idx: 80 |  Loss: (0.0045) | Acc: (99.91%) (10359/10368)\n",
            "Epoch: 142 | Batch_idx: 90 |  Loss: (0.0043) | Acc: (99.92%) (11639/11648)\n",
            "Epoch: 142 | Batch_idx: 100 |  Loss: (0.0044) | Acc: (99.92%) (12918/12928)\n",
            "Epoch: 142 | Batch_idx: 110 |  Loss: (0.0045) | Acc: (99.92%) (14196/14208)\n",
            "Epoch: 142 | Batch_idx: 120 |  Loss: (0.0045) | Acc: (99.92%) (15475/15488)\n",
            "Epoch: 142 | Batch_idx: 130 |  Loss: (0.0044) | Acc: (99.92%) (16755/16768)\n",
            "Epoch: 142 | Batch_idx: 140 |  Loss: (0.0045) | Acc: (99.93%) (18035/18048)\n",
            "Epoch: 142 | Batch_idx: 150 |  Loss: (0.0046) | Acc: (99.91%) (19311/19328)\n",
            "Epoch: 142 | Batch_idx: 160 |  Loss: (0.0046) | Acc: (99.91%) (20590/20608)\n",
            "Epoch: 142 | Batch_idx: 170 |  Loss: (0.0045) | Acc: (99.92%) (21870/21888)\n",
            "Epoch: 142 | Batch_idx: 180 |  Loss: (0.0046) | Acc: (99.91%) (23148/23168)\n",
            "Epoch: 142 | Batch_idx: 190 |  Loss: (0.0046) | Acc: (99.91%) (24427/24448)\n",
            "Epoch: 142 | Batch_idx: 200 |  Loss: (0.0045) | Acc: (99.92%) (25707/25728)\n",
            "Epoch: 142 | Batch_idx: 210 |  Loss: (0.0045) | Acc: (99.92%) (26987/27008)\n",
            "Epoch: 142 | Batch_idx: 220 |  Loss: (0.0045) | Acc: (99.93%) (28267/28288)\n",
            "Epoch: 142 | Batch_idx: 230 |  Loss: (0.0046) | Acc: (99.93%) (29546/29568)\n",
            "Epoch: 142 | Batch_idx: 240 |  Loss: (0.0046) | Acc: (99.93%) (30825/30848)\n",
            "Epoch: 142 | Batch_idx: 250 |  Loss: (0.0046) | Acc: (99.92%) (32103/32128)\n",
            "Epoch: 142 | Batch_idx: 260 |  Loss: (0.0046) | Acc: (99.92%) (33382/33408)\n",
            "Epoch: 142 | Batch_idx: 270 |  Loss: (0.0046) | Acc: (99.92%) (34661/34688)\n",
            "Epoch: 142 | Batch_idx: 280 |  Loss: (0.0046) | Acc: (99.92%) (35941/35968)\n",
            "Epoch: 142 | Batch_idx: 290 |  Loss: (0.0045) | Acc: (99.93%) (37221/37248)\n",
            "Epoch: 142 | Batch_idx: 300 |  Loss: (0.0045) | Acc: (99.93%) (38500/38528)\n",
            "Epoch: 142 | Batch_idx: 310 |  Loss: (0.0045) | Acc: (99.93%) (39780/39808)\n",
            "Epoch: 142 | Batch_idx: 320 |  Loss: (0.0045) | Acc: (99.93%) (41060/41088)\n",
            "Epoch: 142 | Batch_idx: 330 |  Loss: (0.0045) | Acc: (99.93%) (42338/42368)\n",
            "Epoch: 142 | Batch_idx: 340 |  Loss: (0.0046) | Acc: (99.92%) (43615/43648)\n",
            "Epoch: 142 | Batch_idx: 350 |  Loss: (0.0046) | Acc: (99.92%) (44894/44928)\n",
            "Epoch: 142 | Batch_idx: 360 |  Loss: (0.0046) | Acc: (99.92%) (46173/46208)\n",
            "Epoch: 142 | Batch_idx: 370 |  Loss: (0.0046) | Acc: (99.93%) (47453/47488)\n",
            "Epoch: 142 | Batch_idx: 380 |  Loss: (0.0045) | Acc: (99.93%) (48732/48768)\n",
            "Epoch: 142 | Batch_idx: 390 |  Loss: (0.0045) | Acc: (99.93%) (49963/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3505) | Acc: (92.73%) (9273/10000)\n",
            "Epoch: 143 | Batch_idx: 0 |  Loss: (0.0025) | Acc: (100.00%) (128/128)\n",
            "Epoch: 143 | Batch_idx: 10 |  Loss: (0.0058) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 143 | Batch_idx: 20 |  Loss: (0.0046) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 143 | Batch_idx: 30 |  Loss: (0.0051) | Acc: (99.90%) (3964/3968)\n",
            "Epoch: 143 | Batch_idx: 40 |  Loss: (0.0049) | Acc: (99.92%) (5244/5248)\n",
            "Epoch: 143 | Batch_idx: 50 |  Loss: (0.0050) | Acc: (99.94%) (6524/6528)\n",
            "Epoch: 143 | Batch_idx: 60 |  Loss: (0.0053) | Acc: (99.91%) (7801/7808)\n",
            "Epoch: 143 | Batch_idx: 70 |  Loss: (0.0054) | Acc: (99.90%) (9079/9088)\n",
            "Epoch: 143 | Batch_idx: 80 |  Loss: (0.0051) | Acc: (99.90%) (10358/10368)\n",
            "Epoch: 143 | Batch_idx: 90 |  Loss: (0.0052) | Acc: (99.91%) (11637/11648)\n",
            "Epoch: 143 | Batch_idx: 100 |  Loss: (0.0050) | Acc: (99.91%) (12917/12928)\n",
            "Epoch: 143 | Batch_idx: 110 |  Loss: (0.0049) | Acc: (99.92%) (14196/14208)\n",
            "Epoch: 143 | Batch_idx: 120 |  Loss: (0.0049) | Acc: (99.92%) (15476/15488)\n",
            "Epoch: 143 | Batch_idx: 130 |  Loss: (0.0051) | Acc: (99.90%) (16752/16768)\n",
            "Epoch: 143 | Batch_idx: 140 |  Loss: (0.0051) | Acc: (99.89%) (18029/18048)\n",
            "Epoch: 143 | Batch_idx: 150 |  Loss: (0.0050) | Acc: (99.90%) (19309/19328)\n",
            "Epoch: 143 | Batch_idx: 160 |  Loss: (0.0049) | Acc: (99.91%) (20589/20608)\n",
            "Epoch: 143 | Batch_idx: 170 |  Loss: (0.0049) | Acc: (99.91%) (21868/21888)\n",
            "Epoch: 143 | Batch_idx: 180 |  Loss: (0.0049) | Acc: (99.91%) (23147/23168)\n",
            "Epoch: 143 | Batch_idx: 190 |  Loss: (0.0049) | Acc: (99.91%) (24426/24448)\n",
            "Epoch: 143 | Batch_idx: 200 |  Loss: (0.0048) | Acc: (99.91%) (25706/25728)\n",
            "Epoch: 143 | Batch_idx: 210 |  Loss: (0.0048) | Acc: (99.91%) (26985/27008)\n",
            "Epoch: 143 | Batch_idx: 220 |  Loss: (0.0048) | Acc: (99.91%) (28263/28288)\n",
            "Epoch: 143 | Batch_idx: 230 |  Loss: (0.0050) | Acc: (99.90%) (29539/29568)\n",
            "Epoch: 143 | Batch_idx: 240 |  Loss: (0.0050) | Acc: (99.90%) (30817/30848)\n",
            "Epoch: 143 | Batch_idx: 250 |  Loss: (0.0049) | Acc: (99.90%) (32097/32128)\n",
            "Epoch: 143 | Batch_idx: 260 |  Loss: (0.0050) | Acc: (99.90%) (33374/33408)\n",
            "Epoch: 143 | Batch_idx: 270 |  Loss: (0.0049) | Acc: (99.90%) (34654/34688)\n",
            "Epoch: 143 | Batch_idx: 280 |  Loss: (0.0049) | Acc: (99.90%) (35933/35968)\n",
            "Epoch: 143 | Batch_idx: 290 |  Loss: (0.0049) | Acc: (99.90%) (37212/37248)\n",
            "Epoch: 143 | Batch_idx: 300 |  Loss: (0.0048) | Acc: (99.91%) (38492/38528)\n",
            "Epoch: 143 | Batch_idx: 310 |  Loss: (0.0048) | Acc: (99.91%) (39771/39808)\n",
            "Epoch: 143 | Batch_idx: 320 |  Loss: (0.0048) | Acc: (99.91%) (41051/41088)\n",
            "Epoch: 143 | Batch_idx: 330 |  Loss: (0.0048) | Acc: (99.91%) (42328/42368)\n",
            "Epoch: 143 | Batch_idx: 340 |  Loss: (0.0049) | Acc: (99.91%) (43607/43648)\n",
            "Epoch: 143 | Batch_idx: 350 |  Loss: (0.0049) | Acc: (99.91%) (44887/44928)\n",
            "Epoch: 143 | Batch_idx: 360 |  Loss: (0.0049) | Acc: (99.91%) (46166/46208)\n",
            "Epoch: 143 | Batch_idx: 370 |  Loss: (0.0049) | Acc: (99.91%) (47445/47488)\n",
            "Epoch: 143 | Batch_idx: 380 |  Loss: (0.0049) | Acc: (99.91%) (48725/48768)\n",
            "Epoch: 143 | Batch_idx: 390 |  Loss: (0.0049) | Acc: (99.91%) (49956/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3552) | Acc: (92.69%) (9269/10000)\n",
            "Epoch: 144 | Batch_idx: 0 |  Loss: (0.0088) | Acc: (100.00%) (128/128)\n",
            "Epoch: 144 | Batch_idx: 10 |  Loss: (0.0033) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 144 | Batch_idx: 20 |  Loss: (0.0041) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 144 | Batch_idx: 30 |  Loss: (0.0043) | Acc: (99.95%) (3966/3968)\n",
            "Epoch: 144 | Batch_idx: 40 |  Loss: (0.0041) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 144 | Batch_idx: 50 |  Loss: (0.0044) | Acc: (99.94%) (6524/6528)\n",
            "Epoch: 144 | Batch_idx: 60 |  Loss: (0.0040) | Acc: (99.95%) (7804/7808)\n",
            "Epoch: 144 | Batch_idx: 70 |  Loss: (0.0042) | Acc: (99.94%) (9083/9088)\n",
            "Epoch: 144 | Batch_idx: 80 |  Loss: (0.0042) | Acc: (99.95%) (10363/10368)\n",
            "Epoch: 144 | Batch_idx: 90 |  Loss: (0.0042) | Acc: (99.95%) (11642/11648)\n",
            "Epoch: 144 | Batch_idx: 100 |  Loss: (0.0042) | Acc: (99.94%) (12920/12928)\n",
            "Epoch: 144 | Batch_idx: 110 |  Loss: (0.0041) | Acc: (99.94%) (14199/14208)\n",
            "Epoch: 144 | Batch_idx: 120 |  Loss: (0.0042) | Acc: (99.94%) (15478/15488)\n",
            "Epoch: 144 | Batch_idx: 130 |  Loss: (0.0042) | Acc: (99.93%) (16756/16768)\n",
            "Epoch: 144 | Batch_idx: 140 |  Loss: (0.0041) | Acc: (99.93%) (18036/18048)\n",
            "Epoch: 144 | Batch_idx: 150 |  Loss: (0.0042) | Acc: (99.92%) (19313/19328)\n",
            "Epoch: 144 | Batch_idx: 160 |  Loss: (0.0042) | Acc: (99.92%) (20592/20608)\n",
            "Epoch: 144 | Batch_idx: 170 |  Loss: (0.0042) | Acc: (99.92%) (21871/21888)\n",
            "Epoch: 144 | Batch_idx: 180 |  Loss: (0.0043) | Acc: (99.91%) (23148/23168)\n",
            "Epoch: 144 | Batch_idx: 190 |  Loss: (0.0044) | Acc: (99.91%) (24427/24448)\n",
            "Epoch: 144 | Batch_idx: 200 |  Loss: (0.0044) | Acc: (99.91%) (25705/25728)\n",
            "Epoch: 144 | Batch_idx: 210 |  Loss: (0.0045) | Acc: (99.91%) (26983/27008)\n",
            "Epoch: 144 | Batch_idx: 220 |  Loss: (0.0045) | Acc: (99.91%) (28262/28288)\n",
            "Epoch: 144 | Batch_idx: 230 |  Loss: (0.0045) | Acc: (99.91%) (29542/29568)\n",
            "Epoch: 144 | Batch_idx: 240 |  Loss: (0.0045) | Acc: (99.91%) (30821/30848)\n",
            "Epoch: 144 | Batch_idx: 250 |  Loss: (0.0045) | Acc: (99.92%) (32101/32128)\n",
            "Epoch: 144 | Batch_idx: 260 |  Loss: (0.0045) | Acc: (99.92%) (33381/33408)\n",
            "Epoch: 144 | Batch_idx: 270 |  Loss: (0.0044) | Acc: (99.92%) (34660/34688)\n",
            "Epoch: 144 | Batch_idx: 280 |  Loss: (0.0044) | Acc: (99.92%) (35940/35968)\n",
            "Epoch: 144 | Batch_idx: 290 |  Loss: (0.0044) | Acc: (99.92%) (37219/37248)\n",
            "Epoch: 144 | Batch_idx: 300 |  Loss: (0.0044) | Acc: (99.92%) (38496/38528)\n",
            "Epoch: 144 | Batch_idx: 310 |  Loss: (0.0045) | Acc: (99.92%) (39775/39808)\n",
            "Epoch: 144 | Batch_idx: 320 |  Loss: (0.0045) | Acc: (99.92%) (41054/41088)\n",
            "Epoch: 144 | Batch_idx: 330 |  Loss: (0.0045) | Acc: (99.92%) (42333/42368)\n",
            "Epoch: 144 | Batch_idx: 340 |  Loss: (0.0045) | Acc: (99.92%) (43613/43648)\n",
            "Epoch: 144 | Batch_idx: 350 |  Loss: (0.0045) | Acc: (99.92%) (44893/44928)\n",
            "Epoch: 144 | Batch_idx: 360 |  Loss: (0.0045) | Acc: (99.92%) (46171/46208)\n",
            "Epoch: 144 | Batch_idx: 370 |  Loss: (0.0045) | Acc: (99.92%) (47450/47488)\n",
            "Epoch: 144 | Batch_idx: 380 |  Loss: (0.0046) | Acc: (99.92%) (48728/48768)\n",
            "Epoch: 144 | Batch_idx: 390 |  Loss: (0.0045) | Acc: (99.92%) (49959/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3558) | Acc: (92.68%) (9268/10000)\n",
            "Epoch: 145 | Batch_idx: 0 |  Loss: (0.0040) | Acc: (100.00%) (128/128)\n",
            "Epoch: 145 | Batch_idx: 10 |  Loss: (0.0028) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 145 | Batch_idx: 20 |  Loss: (0.0030) | Acc: (100.00%) (2688/2688)\n",
            "Epoch: 145 | Batch_idx: 30 |  Loss: (0.0033) | Acc: (99.97%) (3967/3968)\n",
            "Epoch: 145 | Batch_idx: 40 |  Loss: (0.0041) | Acc: (99.96%) (5246/5248)\n",
            "Epoch: 145 | Batch_idx: 50 |  Loss: (0.0042) | Acc: (99.94%) (6524/6528)\n",
            "Epoch: 145 | Batch_idx: 60 |  Loss: (0.0044) | Acc: (99.91%) (7801/7808)\n",
            "Epoch: 145 | Batch_idx: 70 |  Loss: (0.0043) | Acc: (99.91%) (9080/9088)\n",
            "Epoch: 145 | Batch_idx: 80 |  Loss: (0.0046) | Acc: (99.90%) (10358/10368)\n",
            "Epoch: 145 | Batch_idx: 90 |  Loss: (0.0047) | Acc: (99.91%) (11637/11648)\n",
            "Epoch: 145 | Batch_idx: 100 |  Loss: (0.0045) | Acc: (99.91%) (12916/12928)\n",
            "Epoch: 145 | Batch_idx: 110 |  Loss: (0.0044) | Acc: (99.92%) (14196/14208)\n",
            "Epoch: 145 | Batch_idx: 120 |  Loss: (0.0046) | Acc: (99.91%) (15474/15488)\n",
            "Epoch: 145 | Batch_idx: 130 |  Loss: (0.0046) | Acc: (99.91%) (16753/16768)\n",
            "Epoch: 145 | Batch_idx: 140 |  Loss: (0.0045) | Acc: (99.92%) (18033/18048)\n",
            "Epoch: 145 | Batch_idx: 150 |  Loss: (0.0045) | Acc: (99.92%) (19312/19328)\n",
            "Epoch: 145 | Batch_idx: 160 |  Loss: (0.0046) | Acc: (99.92%) (20591/20608)\n",
            "Epoch: 145 | Batch_idx: 170 |  Loss: (0.0045) | Acc: (99.91%) (21868/21888)\n",
            "Epoch: 145 | Batch_idx: 180 |  Loss: (0.0044) | Acc: (99.91%) (23148/23168)\n",
            "Epoch: 145 | Batch_idx: 190 |  Loss: (0.0044) | Acc: (99.92%) (24428/24448)\n",
            "Epoch: 145 | Batch_idx: 200 |  Loss: (0.0044) | Acc: (99.92%) (25707/25728)\n",
            "Epoch: 145 | Batch_idx: 210 |  Loss: (0.0043) | Acc: (99.92%) (26986/27008)\n",
            "Epoch: 145 | Batch_idx: 220 |  Loss: (0.0043) | Acc: (99.92%) (28265/28288)\n",
            "Epoch: 145 | Batch_idx: 230 |  Loss: (0.0044) | Acc: (99.92%) (29543/29568)\n",
            "Epoch: 145 | Batch_idx: 240 |  Loss: (0.0043) | Acc: (99.92%) (30823/30848)\n",
            "Epoch: 145 | Batch_idx: 250 |  Loss: (0.0044) | Acc: (99.92%) (32101/32128)\n",
            "Epoch: 145 | Batch_idx: 260 |  Loss: (0.0044) | Acc: (99.92%) (33380/33408)\n",
            "Epoch: 145 | Batch_idx: 270 |  Loss: (0.0043) | Acc: (99.92%) (34659/34688)\n",
            "Epoch: 145 | Batch_idx: 280 |  Loss: (0.0043) | Acc: (99.92%) (35939/35968)\n",
            "Epoch: 145 | Batch_idx: 290 |  Loss: (0.0043) | Acc: (99.92%) (37218/37248)\n",
            "Epoch: 145 | Batch_idx: 300 |  Loss: (0.0044) | Acc: (99.92%) (38496/38528)\n",
            "Epoch: 145 | Batch_idx: 310 |  Loss: (0.0044) | Acc: (99.92%) (39776/39808)\n",
            "Epoch: 145 | Batch_idx: 320 |  Loss: (0.0044) | Acc: (99.92%) (41055/41088)\n",
            "Epoch: 145 | Batch_idx: 330 |  Loss: (0.0044) | Acc: (99.92%) (42334/42368)\n",
            "Epoch: 145 | Batch_idx: 340 |  Loss: (0.0044) | Acc: (99.92%) (43613/43648)\n",
            "Epoch: 145 | Batch_idx: 350 |  Loss: (0.0044) | Acc: (99.92%) (44892/44928)\n",
            "Epoch: 145 | Batch_idx: 360 |  Loss: (0.0044) | Acc: (99.92%) (46169/46208)\n",
            "Epoch: 145 | Batch_idx: 370 |  Loss: (0.0044) | Acc: (99.92%) (47449/47488)\n",
            "Epoch: 145 | Batch_idx: 380 |  Loss: (0.0043) | Acc: (99.92%) (48729/48768)\n",
            "Epoch: 145 | Batch_idx: 390 |  Loss: (0.0043) | Acc: (99.92%) (49961/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3526) | Acc: (92.73%) (9273/10000)\n",
            "Epoch: 146 | Batch_idx: 0 |  Loss: (0.0028) | Acc: (100.00%) (128/128)\n",
            "Epoch: 146 | Batch_idx: 10 |  Loss: (0.0055) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 146 | Batch_idx: 20 |  Loss: (0.0055) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 146 | Batch_idx: 30 |  Loss: (0.0062) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 146 | Batch_idx: 40 |  Loss: (0.0059) | Acc: (99.87%) (5241/5248)\n",
            "Epoch: 146 | Batch_idx: 50 |  Loss: (0.0055) | Acc: (99.88%) (6520/6528)\n",
            "Epoch: 146 | Batch_idx: 60 |  Loss: (0.0056) | Acc: (99.87%) (7798/7808)\n",
            "Epoch: 146 | Batch_idx: 70 |  Loss: (0.0057) | Acc: (99.87%) (9076/9088)\n",
            "Epoch: 146 | Batch_idx: 80 |  Loss: (0.0057) | Acc: (99.87%) (10355/10368)\n",
            "Epoch: 146 | Batch_idx: 90 |  Loss: (0.0056) | Acc: (99.86%) (11632/11648)\n",
            "Epoch: 146 | Batch_idx: 100 |  Loss: (0.0058) | Acc: (99.85%) (12909/12928)\n",
            "Epoch: 146 | Batch_idx: 110 |  Loss: (0.0058) | Acc: (99.85%) (14187/14208)\n",
            "Epoch: 146 | Batch_idx: 120 |  Loss: (0.0056) | Acc: (99.86%) (15467/15488)\n",
            "Epoch: 146 | Batch_idx: 130 |  Loss: (0.0056) | Acc: (99.86%) (16745/16768)\n",
            "Epoch: 146 | Batch_idx: 140 |  Loss: (0.0055) | Acc: (99.87%) (18025/18048)\n",
            "Epoch: 146 | Batch_idx: 150 |  Loss: (0.0054) | Acc: (99.88%) (19305/19328)\n",
            "Epoch: 146 | Batch_idx: 160 |  Loss: (0.0053) | Acc: (99.89%) (20585/20608)\n",
            "Epoch: 146 | Batch_idx: 170 |  Loss: (0.0053) | Acc: (99.89%) (21863/21888)\n",
            "Epoch: 146 | Batch_idx: 180 |  Loss: (0.0054) | Acc: (99.88%) (23141/23168)\n",
            "Epoch: 146 | Batch_idx: 190 |  Loss: (0.0053) | Acc: (99.89%) (24420/24448)\n",
            "Epoch: 146 | Batch_idx: 200 |  Loss: (0.0052) | Acc: (99.89%) (25699/25728)\n",
            "Epoch: 146 | Batch_idx: 210 |  Loss: (0.0052) | Acc: (99.89%) (26978/27008)\n",
            "Epoch: 146 | Batch_idx: 220 |  Loss: (0.0052) | Acc: (99.89%) (28257/28288)\n",
            "Epoch: 146 | Batch_idx: 230 |  Loss: (0.0052) | Acc: (99.89%) (29536/29568)\n",
            "Epoch: 146 | Batch_idx: 240 |  Loss: (0.0052) | Acc: (99.89%) (30814/30848)\n",
            "Epoch: 146 | Batch_idx: 250 |  Loss: (0.0051) | Acc: (99.89%) (32093/32128)\n",
            "Epoch: 146 | Batch_idx: 260 |  Loss: (0.0051) | Acc: (99.89%) (33372/33408)\n",
            "Epoch: 146 | Batch_idx: 270 |  Loss: (0.0051) | Acc: (99.89%) (34650/34688)\n",
            "Epoch: 146 | Batch_idx: 280 |  Loss: (0.0050) | Acc: (99.89%) (35930/35968)\n",
            "Epoch: 146 | Batch_idx: 290 |  Loss: (0.0049) | Acc: (99.90%) (37209/37248)\n",
            "Epoch: 146 | Batch_idx: 300 |  Loss: (0.0049) | Acc: (99.90%) (38488/38528)\n",
            "Epoch: 146 | Batch_idx: 310 |  Loss: (0.0049) | Acc: (99.89%) (39766/39808)\n",
            "Epoch: 146 | Batch_idx: 320 |  Loss: (0.0049) | Acc: (99.90%) (41046/41088)\n",
            "Epoch: 146 | Batch_idx: 330 |  Loss: (0.0048) | Acc: (99.90%) (42326/42368)\n",
            "Epoch: 146 | Batch_idx: 340 |  Loss: (0.0048) | Acc: (99.90%) (43606/43648)\n",
            "Epoch: 146 | Batch_idx: 350 |  Loss: (0.0047) | Acc: (99.91%) (44886/44928)\n",
            "Epoch: 146 | Batch_idx: 360 |  Loss: (0.0048) | Acc: (99.90%) (46163/46208)\n",
            "Epoch: 146 | Batch_idx: 370 |  Loss: (0.0048) | Acc: (99.91%) (47443/47488)\n",
            "Epoch: 146 | Batch_idx: 380 |  Loss: (0.0048) | Acc: (99.90%) (48720/48768)\n",
            "Epoch: 146 | Batch_idx: 390 |  Loss: (0.0048) | Acc: (99.90%) (49951/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3549) | Acc: (92.69%) (9269/10000)\n",
            "Epoch: 147 | Batch_idx: 0 |  Loss: (0.0021) | Acc: (100.00%) (128/128)\n",
            "Epoch: 147 | Batch_idx: 10 |  Loss: (0.0039) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 147 | Batch_idx: 20 |  Loss: (0.0051) | Acc: (99.81%) (2683/2688)\n",
            "Epoch: 147 | Batch_idx: 30 |  Loss: (0.0050) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 147 | Batch_idx: 40 |  Loss: (0.0050) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 147 | Batch_idx: 50 |  Loss: (0.0046) | Acc: (99.91%) (6522/6528)\n",
            "Epoch: 147 | Batch_idx: 60 |  Loss: (0.0046) | Acc: (99.90%) (7800/7808)\n",
            "Epoch: 147 | Batch_idx: 70 |  Loss: (0.0046) | Acc: (99.91%) (9080/9088)\n",
            "Epoch: 147 | Batch_idx: 80 |  Loss: (0.0047) | Acc: (99.91%) (10359/10368)\n",
            "Epoch: 147 | Batch_idx: 90 |  Loss: (0.0044) | Acc: (99.92%) (11639/11648)\n",
            "Epoch: 147 | Batch_idx: 100 |  Loss: (0.0045) | Acc: (99.91%) (12917/12928)\n",
            "Epoch: 147 | Batch_idx: 110 |  Loss: (0.0044) | Acc: (99.92%) (14196/14208)\n",
            "Epoch: 147 | Batch_idx: 120 |  Loss: (0.0043) | Acc: (99.92%) (15476/15488)\n",
            "Epoch: 147 | Batch_idx: 130 |  Loss: (0.0045) | Acc: (99.91%) (16753/16768)\n",
            "Epoch: 147 | Batch_idx: 140 |  Loss: (0.0044) | Acc: (99.91%) (18032/18048)\n",
            "Epoch: 147 | Batch_idx: 150 |  Loss: (0.0045) | Acc: (99.91%) (19310/19328)\n",
            "Epoch: 147 | Batch_idx: 160 |  Loss: (0.0043) | Acc: (99.91%) (20590/20608)\n",
            "Epoch: 147 | Batch_idx: 170 |  Loss: (0.0045) | Acc: (99.91%) (21868/21888)\n",
            "Epoch: 147 | Batch_idx: 180 |  Loss: (0.0045) | Acc: (99.91%) (23147/23168)\n",
            "Epoch: 147 | Batch_idx: 190 |  Loss: (0.0044) | Acc: (99.91%) (24427/24448)\n",
            "Epoch: 147 | Batch_idx: 200 |  Loss: (0.0043) | Acc: (99.91%) (25706/25728)\n",
            "Epoch: 147 | Batch_idx: 210 |  Loss: (0.0043) | Acc: (99.92%) (26986/27008)\n",
            "Epoch: 147 | Batch_idx: 220 |  Loss: (0.0043) | Acc: (99.92%) (28264/28288)\n",
            "Epoch: 147 | Batch_idx: 230 |  Loss: (0.0043) | Acc: (99.92%) (29543/29568)\n",
            "Epoch: 147 | Batch_idx: 240 |  Loss: (0.0043) | Acc: (99.92%) (30822/30848)\n",
            "Epoch: 147 | Batch_idx: 250 |  Loss: (0.0043) | Acc: (99.92%) (32102/32128)\n",
            "Epoch: 147 | Batch_idx: 260 |  Loss: (0.0043) | Acc: (99.92%) (33381/33408)\n",
            "Epoch: 147 | Batch_idx: 270 |  Loss: (0.0043) | Acc: (99.92%) (34661/34688)\n",
            "Epoch: 147 | Batch_idx: 280 |  Loss: (0.0045) | Acc: (99.91%) (35936/35968)\n",
            "Epoch: 147 | Batch_idx: 290 |  Loss: (0.0045) | Acc: (99.91%) (37215/37248)\n",
            "Epoch: 147 | Batch_idx: 300 |  Loss: (0.0044) | Acc: (99.91%) (38495/38528)\n",
            "Epoch: 147 | Batch_idx: 310 |  Loss: (0.0043) | Acc: (99.92%) (39775/39808)\n",
            "Epoch: 147 | Batch_idx: 320 |  Loss: (0.0043) | Acc: (99.92%) (41054/41088)\n",
            "Epoch: 147 | Batch_idx: 330 |  Loss: (0.0043) | Acc: (99.92%) (42333/42368)\n",
            "Epoch: 147 | Batch_idx: 340 |  Loss: (0.0044) | Acc: (99.91%) (43610/43648)\n",
            "Epoch: 147 | Batch_idx: 350 |  Loss: (0.0044) | Acc: (99.91%) (44888/44928)\n",
            "Epoch: 147 | Batch_idx: 360 |  Loss: (0.0044) | Acc: (99.91%) (46168/46208)\n",
            "Epoch: 147 | Batch_idx: 370 |  Loss: (0.0044) | Acc: (99.92%) (47448/47488)\n",
            "Epoch: 147 | Batch_idx: 380 |  Loss: (0.0044) | Acc: (99.92%) (48728/48768)\n",
            "Epoch: 147 | Batch_idx: 390 |  Loss: (0.0046) | Acc: (99.91%) (49956/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3548) | Acc: (92.72%) (9272/10000)\n",
            "Epoch: 148 | Batch_idx: 0 |  Loss: (0.0036) | Acc: (100.00%) (128/128)\n",
            "Epoch: 148 | Batch_idx: 10 |  Loss: (0.0055) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 148 | Batch_idx: 20 |  Loss: (0.0049) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 148 | Batch_idx: 30 |  Loss: (0.0046) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 148 | Batch_idx: 40 |  Loss: (0.0044) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 148 | Batch_idx: 50 |  Loss: (0.0048) | Acc: (99.89%) (6521/6528)\n",
            "Epoch: 148 | Batch_idx: 60 |  Loss: (0.0048) | Acc: (99.90%) (7800/7808)\n",
            "Epoch: 148 | Batch_idx: 70 |  Loss: (0.0048) | Acc: (99.90%) (9079/9088)\n",
            "Epoch: 148 | Batch_idx: 80 |  Loss: (0.0050) | Acc: (99.88%) (10356/10368)\n",
            "Epoch: 148 | Batch_idx: 90 |  Loss: (0.0049) | Acc: (99.89%) (11635/11648)\n",
            "Epoch: 148 | Batch_idx: 100 |  Loss: (0.0050) | Acc: (99.89%) (12914/12928)\n",
            "Epoch: 148 | Batch_idx: 110 |  Loss: (0.0047) | Acc: (99.90%) (14194/14208)\n",
            "Epoch: 148 | Batch_idx: 120 |  Loss: (0.0046) | Acc: (99.90%) (15473/15488)\n",
            "Epoch: 148 | Batch_idx: 130 |  Loss: (0.0046) | Acc: (99.91%) (16753/16768)\n",
            "Epoch: 148 | Batch_idx: 140 |  Loss: (0.0046) | Acc: (99.91%) (18031/18048)\n",
            "Epoch: 148 | Batch_idx: 150 |  Loss: (0.0046) | Acc: (99.91%) (19310/19328)\n",
            "Epoch: 148 | Batch_idx: 160 |  Loss: (0.0048) | Acc: (99.90%) (20588/20608)\n",
            "Epoch: 148 | Batch_idx: 170 |  Loss: (0.0048) | Acc: (99.90%) (21867/21888)\n",
            "Epoch: 148 | Batch_idx: 180 |  Loss: (0.0048) | Acc: (99.91%) (23147/23168)\n",
            "Epoch: 148 | Batch_idx: 190 |  Loss: (0.0048) | Acc: (99.91%) (24427/24448)\n",
            "Epoch: 148 | Batch_idx: 200 |  Loss: (0.0047) | Acc: (99.92%) (25707/25728)\n",
            "Epoch: 148 | Batch_idx: 210 |  Loss: (0.0047) | Acc: (99.92%) (26986/27008)\n",
            "Epoch: 148 | Batch_idx: 220 |  Loss: (0.0047) | Acc: (99.92%) (28265/28288)\n",
            "Epoch: 148 | Batch_idx: 230 |  Loss: (0.0046) | Acc: (99.92%) (29544/29568)\n",
            "Epoch: 148 | Batch_idx: 240 |  Loss: (0.0046) | Acc: (99.92%) (30823/30848)\n",
            "Epoch: 148 | Batch_idx: 250 |  Loss: (0.0046) | Acc: (99.92%) (32103/32128)\n",
            "Epoch: 148 | Batch_idx: 260 |  Loss: (0.0045) | Acc: (99.93%) (33383/33408)\n",
            "Epoch: 148 | Batch_idx: 270 |  Loss: (0.0045) | Acc: (99.92%) (34661/34688)\n",
            "Epoch: 148 | Batch_idx: 280 |  Loss: (0.0045) | Acc: (99.92%) (35939/35968)\n",
            "Epoch: 148 | Batch_idx: 290 |  Loss: (0.0045) | Acc: (99.92%) (37219/37248)\n",
            "Epoch: 148 | Batch_idx: 300 |  Loss: (0.0045) | Acc: (99.92%) (38499/38528)\n",
            "Epoch: 148 | Batch_idx: 310 |  Loss: (0.0045) | Acc: (99.92%) (39778/39808)\n",
            "Epoch: 148 | Batch_idx: 320 |  Loss: (0.0044) | Acc: (99.93%) (41058/41088)\n",
            "Epoch: 148 | Batch_idx: 330 |  Loss: (0.0044) | Acc: (99.93%) (42337/42368)\n",
            "Epoch: 148 | Batch_idx: 340 |  Loss: (0.0044) | Acc: (99.93%) (43616/43648)\n",
            "Epoch: 148 | Batch_idx: 350 |  Loss: (0.0044) | Acc: (99.93%) (44895/44928)\n",
            "Epoch: 148 | Batch_idx: 360 |  Loss: (0.0043) | Acc: (99.93%) (46174/46208)\n",
            "Epoch: 148 | Batch_idx: 370 |  Loss: (0.0043) | Acc: (99.93%) (47453/47488)\n",
            "Epoch: 148 | Batch_idx: 380 |  Loss: (0.0043) | Acc: (99.92%) (48731/48768)\n",
            "Epoch: 148 | Batch_idx: 390 |  Loss: (0.0044) | Acc: (99.92%) (49961/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3615) | Acc: (92.64%) (9264/10000)\n",
            "Epoch: 149 | Batch_idx: 0 |  Loss: (0.0010) | Acc: (100.00%) (128/128)\n",
            "Epoch: 149 | Batch_idx: 10 |  Loss: (0.0029) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 149 | Batch_idx: 20 |  Loss: (0.0042) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 149 | Batch_idx: 30 |  Loss: (0.0045) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 149 | Batch_idx: 40 |  Loss: (0.0044) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 149 | Batch_idx: 50 |  Loss: (0.0042) | Acc: (99.95%) (6525/6528)\n",
            "Epoch: 149 | Batch_idx: 60 |  Loss: (0.0044) | Acc: (99.94%) (7803/7808)\n",
            "Epoch: 149 | Batch_idx: 70 |  Loss: (0.0043) | Acc: (99.93%) (9082/9088)\n",
            "Epoch: 149 | Batch_idx: 80 |  Loss: (0.0043) | Acc: (99.94%) (10362/10368)\n",
            "Epoch: 149 | Batch_idx: 90 |  Loss: (0.0045) | Acc: (99.94%) (11641/11648)\n",
            "Epoch: 149 | Batch_idx: 100 |  Loss: (0.0044) | Acc: (99.95%) (12921/12928)\n",
            "Epoch: 149 | Batch_idx: 110 |  Loss: (0.0043) | Acc: (99.95%) (14201/14208)\n",
            "Epoch: 149 | Batch_idx: 120 |  Loss: (0.0042) | Acc: (99.95%) (15481/15488)\n",
            "Epoch: 149 | Batch_idx: 130 |  Loss: (0.0041) | Acc: (99.96%) (16761/16768)\n",
            "Epoch: 149 | Batch_idx: 140 |  Loss: (0.0040) | Acc: (99.96%) (18041/18048)\n",
            "Epoch: 149 | Batch_idx: 150 |  Loss: (0.0041) | Acc: (99.96%) (19320/19328)\n",
            "Epoch: 149 | Batch_idx: 160 |  Loss: (0.0042) | Acc: (99.96%) (20600/20608)\n",
            "Epoch: 149 | Batch_idx: 170 |  Loss: (0.0041) | Acc: (99.96%) (21880/21888)\n",
            "Epoch: 149 | Batch_idx: 180 |  Loss: (0.0040) | Acc: (99.97%) (23160/23168)\n",
            "Epoch: 149 | Batch_idx: 190 |  Loss: (0.0041) | Acc: (99.96%) (24437/24448)\n",
            "Epoch: 149 | Batch_idx: 200 |  Loss: (0.0041) | Acc: (99.96%) (25717/25728)\n",
            "Epoch: 149 | Batch_idx: 210 |  Loss: (0.0041) | Acc: (99.96%) (26997/27008)\n",
            "Epoch: 149 | Batch_idx: 220 |  Loss: (0.0042) | Acc: (99.95%) (28275/28288)\n",
            "Epoch: 149 | Batch_idx: 230 |  Loss: (0.0042) | Acc: (99.95%) (29553/29568)\n",
            "Epoch: 149 | Batch_idx: 240 |  Loss: (0.0043) | Acc: (99.94%) (30831/30848)\n",
            "Epoch: 149 | Batch_idx: 250 |  Loss: (0.0043) | Acc: (99.94%) (32110/32128)\n",
            "Epoch: 149 | Batch_idx: 260 |  Loss: (0.0043) | Acc: (99.94%) (33388/33408)\n",
            "Epoch: 149 | Batch_idx: 270 |  Loss: (0.0043) | Acc: (99.94%) (34667/34688)\n",
            "Epoch: 149 | Batch_idx: 280 |  Loss: (0.0044) | Acc: (99.94%) (35945/35968)\n",
            "Epoch: 149 | Batch_idx: 290 |  Loss: (0.0044) | Acc: (99.94%) (37225/37248)\n",
            "Epoch: 149 | Batch_idx: 300 |  Loss: (0.0044) | Acc: (99.94%) (38505/38528)\n",
            "Epoch: 149 | Batch_idx: 310 |  Loss: (0.0043) | Acc: (99.94%) (39785/39808)\n",
            "Epoch: 149 | Batch_idx: 320 |  Loss: (0.0043) | Acc: (99.94%) (41064/41088)\n",
            "Epoch: 149 | Batch_idx: 330 |  Loss: (0.0044) | Acc: (99.94%) (42342/42368)\n",
            "Epoch: 149 | Batch_idx: 340 |  Loss: (0.0044) | Acc: (99.94%) (43622/43648)\n",
            "Epoch: 149 | Batch_idx: 350 |  Loss: (0.0043) | Acc: (99.94%) (44902/44928)\n",
            "Epoch: 149 | Batch_idx: 360 |  Loss: (0.0044) | Acc: (99.94%) (46179/46208)\n",
            "Epoch: 149 | Batch_idx: 370 |  Loss: (0.0044) | Acc: (99.93%) (47457/47488)\n",
            "Epoch: 149 | Batch_idx: 380 |  Loss: (0.0044) | Acc: (99.93%) (48736/48768)\n",
            "Epoch: 149 | Batch_idx: 390 |  Loss: (0.0044) | Acc: (99.94%) (49968/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3568) | Acc: (92.54%) (9254/10000)\n",
            "Epoch: 150 | Batch_idx: 0 |  Loss: (0.0250) | Acc: (99.22%) (127/128)\n",
            "Epoch: 150 | Batch_idx: 10 |  Loss: (0.0053) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 150 | Batch_idx: 20 |  Loss: (0.0053) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 150 | Batch_idx: 30 |  Loss: (0.0053) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 150 | Batch_idx: 40 |  Loss: (0.0048) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 150 | Batch_idx: 50 |  Loss: (0.0046) | Acc: (99.95%) (6525/6528)\n",
            "Epoch: 150 | Batch_idx: 60 |  Loss: (0.0045) | Acc: (99.94%) (7803/7808)\n",
            "Epoch: 150 | Batch_idx: 70 |  Loss: (0.0046) | Acc: (99.93%) (9082/9088)\n",
            "Epoch: 150 | Batch_idx: 80 |  Loss: (0.0045) | Acc: (99.93%) (10361/10368)\n",
            "Epoch: 150 | Batch_idx: 90 |  Loss: (0.0047) | Acc: (99.92%) (11639/11648)\n",
            "Epoch: 150 | Batch_idx: 100 |  Loss: (0.0046) | Acc: (99.93%) (12919/12928)\n",
            "Epoch: 150 | Batch_idx: 110 |  Loss: (0.0045) | Acc: (99.93%) (14198/14208)\n",
            "Epoch: 150 | Batch_idx: 120 |  Loss: (0.0045) | Acc: (99.94%) (15478/15488)\n",
            "Epoch: 150 | Batch_idx: 130 |  Loss: (0.0045) | Acc: (99.93%) (16757/16768)\n",
            "Epoch: 150 | Batch_idx: 140 |  Loss: (0.0045) | Acc: (99.94%) (18037/18048)\n",
            "Epoch: 150 | Batch_idx: 150 |  Loss: (0.0044) | Acc: (99.94%) (19317/19328)\n",
            "Epoch: 150 | Batch_idx: 160 |  Loss: (0.0047) | Acc: (99.94%) (20595/20608)\n",
            "Epoch: 150 | Batch_idx: 170 |  Loss: (0.0046) | Acc: (99.94%) (21875/21888)\n",
            "Epoch: 150 | Batch_idx: 180 |  Loss: (0.0045) | Acc: (99.94%) (23155/23168)\n",
            "Epoch: 150 | Batch_idx: 190 |  Loss: (0.0046) | Acc: (99.94%) (24433/24448)\n",
            "Epoch: 150 | Batch_idx: 200 |  Loss: (0.0045) | Acc: (99.94%) (25712/25728)\n",
            "Epoch: 150 | Batch_idx: 210 |  Loss: (0.0045) | Acc: (99.94%) (26991/27008)\n",
            "Epoch: 150 | Batch_idx: 220 |  Loss: (0.0046) | Acc: (99.93%) (28269/28288)\n",
            "Epoch: 150 | Batch_idx: 230 |  Loss: (0.0045) | Acc: (99.93%) (29548/29568)\n",
            "Epoch: 150 | Batch_idx: 240 |  Loss: (0.0045) | Acc: (99.93%) (30827/30848)\n",
            "Epoch: 150 | Batch_idx: 250 |  Loss: (0.0046) | Acc: (99.93%) (32104/32128)\n",
            "Epoch: 150 | Batch_idx: 260 |  Loss: (0.0046) | Acc: (99.93%) (33384/33408)\n",
            "Epoch: 150 | Batch_idx: 270 |  Loss: (0.0045) | Acc: (99.93%) (34664/34688)\n",
            "Epoch: 150 | Batch_idx: 280 |  Loss: (0.0046) | Acc: (99.93%) (35942/35968)\n",
            "Epoch: 150 | Batch_idx: 290 |  Loss: (0.0045) | Acc: (99.93%) (37222/37248)\n",
            "Epoch: 150 | Batch_idx: 300 |  Loss: (0.0045) | Acc: (99.93%) (38502/38528)\n",
            "Epoch: 150 | Batch_idx: 310 |  Loss: (0.0044) | Acc: (99.93%) (39782/39808)\n",
            "Epoch: 150 | Batch_idx: 320 |  Loss: (0.0044) | Acc: (99.94%) (41062/41088)\n",
            "Epoch: 150 | Batch_idx: 330 |  Loss: (0.0043) | Acc: (99.94%) (42342/42368)\n",
            "Epoch: 150 | Batch_idx: 340 |  Loss: (0.0044) | Acc: (99.93%) (43618/43648)\n",
            "Epoch: 150 | Batch_idx: 350 |  Loss: (0.0044) | Acc: (99.93%) (44897/44928)\n",
            "Epoch: 150 | Batch_idx: 360 |  Loss: (0.0043) | Acc: (99.93%) (46177/46208)\n",
            "Epoch: 150 | Batch_idx: 370 |  Loss: (0.0043) | Acc: (99.93%) (47455/47488)\n",
            "Epoch: 150 | Batch_idx: 380 |  Loss: (0.0043) | Acc: (99.93%) (48734/48768)\n",
            "Epoch: 150 | Batch_idx: 390 |  Loss: (0.0043) | Acc: (99.93%) (49966/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3581) | Acc: (92.72%) (9272/10000)\n",
            "Epoch: 151 | Batch_idx: 0 |  Loss: (0.0023) | Acc: (100.00%) (128/128)\n",
            "Epoch: 151 | Batch_idx: 10 |  Loss: (0.0045) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 151 | Batch_idx: 20 |  Loss: (0.0043) | Acc: (100.00%) (2688/2688)\n",
            "Epoch: 151 | Batch_idx: 30 |  Loss: (0.0051) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 151 | Batch_idx: 40 |  Loss: (0.0045) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 151 | Batch_idx: 50 |  Loss: (0.0042) | Acc: (99.95%) (6525/6528)\n",
            "Epoch: 151 | Batch_idx: 60 |  Loss: (0.0045) | Acc: (99.95%) (7804/7808)\n",
            "Epoch: 151 | Batch_idx: 70 |  Loss: (0.0045) | Acc: (99.94%) (9083/9088)\n",
            "Epoch: 151 | Batch_idx: 80 |  Loss: (0.0043) | Acc: (99.95%) (10363/10368)\n",
            "Epoch: 151 | Batch_idx: 90 |  Loss: (0.0043) | Acc: (99.96%) (11643/11648)\n",
            "Epoch: 151 | Batch_idx: 100 |  Loss: (0.0045) | Acc: (99.94%) (12920/12928)\n",
            "Epoch: 151 | Batch_idx: 110 |  Loss: (0.0043) | Acc: (99.94%) (14200/14208)\n",
            "Epoch: 151 | Batch_idx: 120 |  Loss: (0.0043) | Acc: (99.94%) (15479/15488)\n",
            "Epoch: 151 | Batch_idx: 130 |  Loss: (0.0044) | Acc: (99.93%) (16757/16768)\n",
            "Epoch: 151 | Batch_idx: 140 |  Loss: (0.0044) | Acc: (99.94%) (18037/18048)\n",
            "Epoch: 151 | Batch_idx: 150 |  Loss: (0.0045) | Acc: (99.94%) (19316/19328)\n",
            "Epoch: 151 | Batch_idx: 160 |  Loss: (0.0045) | Acc: (99.94%) (20595/20608)\n",
            "Epoch: 151 | Batch_idx: 170 |  Loss: (0.0048) | Acc: (99.92%) (21871/21888)\n",
            "Epoch: 151 | Batch_idx: 180 |  Loss: (0.0048) | Acc: (99.92%) (23149/23168)\n",
            "Epoch: 151 | Batch_idx: 190 |  Loss: (0.0048) | Acc: (99.92%) (24428/24448)\n",
            "Epoch: 151 | Batch_idx: 200 |  Loss: (0.0047) | Acc: (99.92%) (25707/25728)\n",
            "Epoch: 151 | Batch_idx: 210 |  Loss: (0.0047) | Acc: (99.91%) (26985/27008)\n",
            "Epoch: 151 | Batch_idx: 220 |  Loss: (0.0047) | Acc: (99.92%) (28265/28288)\n",
            "Epoch: 151 | Batch_idx: 230 |  Loss: (0.0046) | Acc: (99.92%) (29545/29568)\n",
            "Epoch: 151 | Batch_idx: 240 |  Loss: (0.0046) | Acc: (99.92%) (30824/30848)\n",
            "Epoch: 151 | Batch_idx: 250 |  Loss: (0.0046) | Acc: (99.93%) (32104/32128)\n",
            "Epoch: 151 | Batch_idx: 260 |  Loss: (0.0046) | Acc: (99.92%) (33382/33408)\n",
            "Epoch: 151 | Batch_idx: 270 |  Loss: (0.0045) | Acc: (99.93%) (34662/34688)\n",
            "Epoch: 151 | Batch_idx: 280 |  Loss: (0.0047) | Acc: (99.92%) (35939/35968)\n",
            "Epoch: 151 | Batch_idx: 290 |  Loss: (0.0047) | Acc: (99.92%) (37219/37248)\n",
            "Epoch: 151 | Batch_idx: 300 |  Loss: (0.0047) | Acc: (99.92%) (38497/38528)\n",
            "Epoch: 151 | Batch_idx: 310 |  Loss: (0.0047) | Acc: (99.92%) (39775/39808)\n",
            "Epoch: 151 | Batch_idx: 320 |  Loss: (0.0046) | Acc: (99.92%) (41055/41088)\n",
            "Epoch: 151 | Batch_idx: 330 |  Loss: (0.0046) | Acc: (99.92%) (42335/42368)\n",
            "Epoch: 151 | Batch_idx: 340 |  Loss: (0.0046) | Acc: (99.92%) (43613/43648)\n",
            "Epoch: 151 | Batch_idx: 350 |  Loss: (0.0047) | Acc: (99.92%) (44890/44928)\n",
            "Epoch: 151 | Batch_idx: 360 |  Loss: (0.0046) | Acc: (99.92%) (46170/46208)\n",
            "Epoch: 151 | Batch_idx: 370 |  Loss: (0.0047) | Acc: (99.91%) (47447/47488)\n",
            "Epoch: 151 | Batch_idx: 380 |  Loss: (0.0046) | Acc: (99.91%) (48726/48768)\n",
            "Epoch: 151 | Batch_idx: 390 |  Loss: (0.0046) | Acc: (99.91%) (49957/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3568) | Acc: (92.79%) (9279/10000)\n",
            "Epoch: 152 | Batch_idx: 0 |  Loss: (0.0007) | Acc: (100.00%) (128/128)\n",
            "Epoch: 152 | Batch_idx: 10 |  Loss: (0.0022) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 152 | Batch_idx: 20 |  Loss: (0.0032) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 152 | Batch_idx: 30 |  Loss: (0.0045) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 152 | Batch_idx: 40 |  Loss: (0.0046) | Acc: (99.92%) (5244/5248)\n",
            "Epoch: 152 | Batch_idx: 50 |  Loss: (0.0044) | Acc: (99.92%) (6523/6528)\n",
            "Epoch: 152 | Batch_idx: 60 |  Loss: (0.0040) | Acc: (99.94%) (7803/7808)\n",
            "Epoch: 152 | Batch_idx: 70 |  Loss: (0.0044) | Acc: (99.92%) (9081/9088)\n",
            "Epoch: 152 | Batch_idx: 80 |  Loss: (0.0045) | Acc: (99.92%) (10360/10368)\n",
            "Epoch: 152 | Batch_idx: 90 |  Loss: (0.0043) | Acc: (99.93%) (11640/11648)\n",
            "Epoch: 152 | Batch_idx: 100 |  Loss: (0.0044) | Acc: (99.93%) (12919/12928)\n",
            "Epoch: 152 | Batch_idx: 110 |  Loss: (0.0044) | Acc: (99.93%) (14198/14208)\n",
            "Epoch: 152 | Batch_idx: 120 |  Loss: (0.0045) | Acc: (99.93%) (15477/15488)\n",
            "Epoch: 152 | Batch_idx: 130 |  Loss: (0.0045) | Acc: (99.92%) (16755/16768)\n",
            "Epoch: 152 | Batch_idx: 140 |  Loss: (0.0045) | Acc: (99.92%) (18034/18048)\n",
            "Epoch: 152 | Batch_idx: 150 |  Loss: (0.0045) | Acc: (99.92%) (19313/19328)\n",
            "Epoch: 152 | Batch_idx: 160 |  Loss: (0.0046) | Acc: (99.92%) (20592/20608)\n",
            "Epoch: 152 | Batch_idx: 170 |  Loss: (0.0045) | Acc: (99.92%) (21871/21888)\n",
            "Epoch: 152 | Batch_idx: 180 |  Loss: (0.0045) | Acc: (99.92%) (23150/23168)\n",
            "Epoch: 152 | Batch_idx: 190 |  Loss: (0.0044) | Acc: (99.93%) (24430/24448)\n",
            "Epoch: 152 | Batch_idx: 200 |  Loss: (0.0044) | Acc: (99.93%) (25709/25728)\n",
            "Epoch: 152 | Batch_idx: 210 |  Loss: (0.0045) | Acc: (99.92%) (26987/27008)\n",
            "Epoch: 152 | Batch_idx: 220 |  Loss: (0.0045) | Acc: (99.93%) (28267/28288)\n",
            "Epoch: 152 | Batch_idx: 230 |  Loss: (0.0045) | Acc: (99.92%) (29545/29568)\n",
            "Epoch: 152 | Batch_idx: 240 |  Loss: (0.0045) | Acc: (99.92%) (30822/30848)\n",
            "Epoch: 152 | Batch_idx: 250 |  Loss: (0.0045) | Acc: (99.91%) (32100/32128)\n",
            "Epoch: 152 | Batch_idx: 260 |  Loss: (0.0046) | Acc: (99.91%) (33377/33408)\n",
            "Epoch: 152 | Batch_idx: 270 |  Loss: (0.0046) | Acc: (99.91%) (34656/34688)\n",
            "Epoch: 152 | Batch_idx: 280 |  Loss: (0.0047) | Acc: (99.90%) (35933/35968)\n",
            "Epoch: 152 | Batch_idx: 290 |  Loss: (0.0047) | Acc: (99.90%) (37212/37248)\n",
            "Epoch: 152 | Batch_idx: 300 |  Loss: (0.0047) | Acc: (99.90%) (38490/38528)\n",
            "Epoch: 152 | Batch_idx: 310 |  Loss: (0.0047) | Acc: (99.90%) (39769/39808)\n",
            "Epoch: 152 | Batch_idx: 320 |  Loss: (0.0046) | Acc: (99.90%) (41048/41088)\n",
            "Epoch: 152 | Batch_idx: 330 |  Loss: (0.0047) | Acc: (99.91%) (42328/42368)\n",
            "Epoch: 152 | Batch_idx: 340 |  Loss: (0.0047) | Acc: (99.91%) (43608/43648)\n",
            "Epoch: 152 | Batch_idx: 350 |  Loss: (0.0046) | Acc: (99.91%) (44888/44928)\n",
            "Epoch: 152 | Batch_idx: 360 |  Loss: (0.0046) | Acc: (99.91%) (46168/46208)\n",
            "Epoch: 152 | Batch_idx: 370 |  Loss: (0.0046) | Acc: (99.91%) (47447/47488)\n",
            "Epoch: 152 | Batch_idx: 380 |  Loss: (0.0045) | Acc: (99.92%) (48727/48768)\n",
            "Epoch: 152 | Batch_idx: 390 |  Loss: (0.0046) | Acc: (99.91%) (49957/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3596) | Acc: (92.65%) (9265/10000)\n",
            "Epoch: 153 | Batch_idx: 0 |  Loss: (0.0029) | Acc: (100.00%) (128/128)\n",
            "Epoch: 153 | Batch_idx: 10 |  Loss: (0.0039) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 153 | Batch_idx: 20 |  Loss: (0.0059) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 153 | Batch_idx: 30 |  Loss: (0.0051) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 153 | Batch_idx: 40 |  Loss: (0.0049) | Acc: (99.92%) (5244/5248)\n",
            "Epoch: 153 | Batch_idx: 50 |  Loss: (0.0045) | Acc: (99.94%) (6524/6528)\n",
            "Epoch: 153 | Batch_idx: 60 |  Loss: (0.0045) | Acc: (99.94%) (7803/7808)\n",
            "Epoch: 153 | Batch_idx: 70 |  Loss: (0.0045) | Acc: (99.93%) (9082/9088)\n",
            "Epoch: 153 | Batch_idx: 80 |  Loss: (0.0044) | Acc: (99.94%) (10362/10368)\n",
            "Epoch: 153 | Batch_idx: 90 |  Loss: (0.0042) | Acc: (99.95%) (11642/11648)\n",
            "Epoch: 153 | Batch_idx: 100 |  Loss: (0.0040) | Acc: (99.95%) (12922/12928)\n",
            "Epoch: 153 | Batch_idx: 110 |  Loss: (0.0041) | Acc: (99.94%) (14199/14208)\n",
            "Epoch: 153 | Batch_idx: 120 |  Loss: (0.0041) | Acc: (99.94%) (15478/15488)\n",
            "Epoch: 153 | Batch_idx: 130 |  Loss: (0.0040) | Acc: (99.94%) (16758/16768)\n",
            "Epoch: 153 | Batch_idx: 140 |  Loss: (0.0040) | Acc: (99.94%) (18037/18048)\n",
            "Epoch: 153 | Batch_idx: 150 |  Loss: (0.0040) | Acc: (99.94%) (19316/19328)\n",
            "Epoch: 153 | Batch_idx: 160 |  Loss: (0.0040) | Acc: (99.94%) (20595/20608)\n",
            "Epoch: 153 | Batch_idx: 170 |  Loss: (0.0040) | Acc: (99.94%) (21875/21888)\n",
            "Epoch: 153 | Batch_idx: 180 |  Loss: (0.0040) | Acc: (99.94%) (23155/23168)\n",
            "Epoch: 153 | Batch_idx: 190 |  Loss: (0.0039) | Acc: (99.94%) (24434/24448)\n",
            "Epoch: 153 | Batch_idx: 200 |  Loss: (0.0040) | Acc: (99.94%) (25713/25728)\n",
            "Epoch: 153 | Batch_idx: 210 |  Loss: (0.0040) | Acc: (99.94%) (26992/27008)\n",
            "Epoch: 153 | Batch_idx: 220 |  Loss: (0.0040) | Acc: (99.94%) (28270/28288)\n",
            "Epoch: 153 | Batch_idx: 230 |  Loss: (0.0041) | Acc: (99.93%) (29547/29568)\n",
            "Epoch: 153 | Batch_idx: 240 |  Loss: (0.0041) | Acc: (99.93%) (30826/30848)\n",
            "Epoch: 153 | Batch_idx: 250 |  Loss: (0.0040) | Acc: (99.93%) (32106/32128)\n",
            "Epoch: 153 | Batch_idx: 260 |  Loss: (0.0041) | Acc: (99.93%) (33385/33408)\n",
            "Epoch: 153 | Batch_idx: 270 |  Loss: (0.0041) | Acc: (99.93%) (34665/34688)\n",
            "Epoch: 153 | Batch_idx: 280 |  Loss: (0.0041) | Acc: (99.93%) (35943/35968)\n",
            "Epoch: 153 | Batch_idx: 290 |  Loss: (0.0041) | Acc: (99.93%) (37222/37248)\n",
            "Epoch: 153 | Batch_idx: 300 |  Loss: (0.0041) | Acc: (99.93%) (38501/38528)\n",
            "Epoch: 153 | Batch_idx: 310 |  Loss: (0.0041) | Acc: (99.93%) (39780/39808)\n",
            "Epoch: 153 | Batch_idx: 320 |  Loss: (0.0041) | Acc: (99.93%) (41059/41088)\n",
            "Epoch: 153 | Batch_idx: 330 |  Loss: (0.0042) | Acc: (99.93%) (42338/42368)\n",
            "Epoch: 153 | Batch_idx: 340 |  Loss: (0.0041) | Acc: (99.93%) (43618/43648)\n",
            "Epoch: 153 | Batch_idx: 350 |  Loss: (0.0041) | Acc: (99.93%) (44898/44928)\n",
            "Epoch: 153 | Batch_idx: 360 |  Loss: (0.0041) | Acc: (99.93%) (46177/46208)\n",
            "Epoch: 153 | Batch_idx: 370 |  Loss: (0.0041) | Acc: (99.93%) (47456/47488)\n",
            "Epoch: 153 | Batch_idx: 380 |  Loss: (0.0041) | Acc: (99.93%) (48736/48768)\n",
            "Epoch: 153 | Batch_idx: 390 |  Loss: (0.0042) | Acc: (99.93%) (49965/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3585) | Acc: (92.64%) (9264/10000)\n",
            "Epoch: 154 | Batch_idx: 0 |  Loss: (0.0012) | Acc: (100.00%) (128/128)\n",
            "Epoch: 154 | Batch_idx: 10 |  Loss: (0.0026) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 154 | Batch_idx: 20 |  Loss: (0.0033) | Acc: (100.00%) (2688/2688)\n",
            "Epoch: 154 | Batch_idx: 30 |  Loss: (0.0033) | Acc: (100.00%) (3968/3968)\n",
            "Epoch: 154 | Batch_idx: 40 |  Loss: (0.0041) | Acc: (99.96%) (5246/5248)\n",
            "Epoch: 154 | Batch_idx: 50 |  Loss: (0.0039) | Acc: (99.97%) (6526/6528)\n",
            "Epoch: 154 | Batch_idx: 60 |  Loss: (0.0036) | Acc: (99.97%) (7806/7808)\n",
            "Epoch: 154 | Batch_idx: 70 |  Loss: (0.0038) | Acc: (99.96%) (9084/9088)\n",
            "Epoch: 154 | Batch_idx: 80 |  Loss: (0.0039) | Acc: (99.96%) (10364/10368)\n",
            "Epoch: 154 | Batch_idx: 90 |  Loss: (0.0039) | Acc: (99.97%) (11644/11648)\n",
            "Epoch: 154 | Batch_idx: 100 |  Loss: (0.0039) | Acc: (99.96%) (12923/12928)\n",
            "Epoch: 154 | Batch_idx: 110 |  Loss: (0.0038) | Acc: (99.96%) (14202/14208)\n",
            "Epoch: 154 | Batch_idx: 120 |  Loss: (0.0039) | Acc: (99.96%) (15482/15488)\n",
            "Epoch: 154 | Batch_idx: 130 |  Loss: (0.0039) | Acc: (99.95%) (16760/16768)\n",
            "Epoch: 154 | Batch_idx: 140 |  Loss: (0.0039) | Acc: (99.96%) (18040/18048)\n",
            "Epoch: 154 | Batch_idx: 150 |  Loss: (0.0038) | Acc: (99.96%) (19320/19328)\n",
            "Epoch: 154 | Batch_idx: 160 |  Loss: (0.0040) | Acc: (99.96%) (20599/20608)\n",
            "Epoch: 154 | Batch_idx: 170 |  Loss: (0.0039) | Acc: (99.96%) (21879/21888)\n",
            "Epoch: 154 | Batch_idx: 180 |  Loss: (0.0039) | Acc: (99.96%) (23159/23168)\n",
            "Epoch: 154 | Batch_idx: 190 |  Loss: (0.0040) | Acc: (99.96%) (24437/24448)\n",
            "Epoch: 154 | Batch_idx: 200 |  Loss: (0.0039) | Acc: (99.96%) (25717/25728)\n",
            "Epoch: 154 | Batch_idx: 210 |  Loss: (0.0040) | Acc: (99.95%) (26995/27008)\n",
            "Epoch: 154 | Batch_idx: 220 |  Loss: (0.0040) | Acc: (99.95%) (28275/28288)\n",
            "Epoch: 154 | Batch_idx: 230 |  Loss: (0.0040) | Acc: (99.95%) (29554/29568)\n",
            "Epoch: 154 | Batch_idx: 240 |  Loss: (0.0040) | Acc: (99.95%) (30833/30848)\n",
            "Epoch: 154 | Batch_idx: 250 |  Loss: (0.0040) | Acc: (99.95%) (32111/32128)\n",
            "Epoch: 154 | Batch_idx: 260 |  Loss: (0.0040) | Acc: (99.95%) (33390/33408)\n",
            "Epoch: 154 | Batch_idx: 270 |  Loss: (0.0040) | Acc: (99.94%) (34668/34688)\n",
            "Epoch: 154 | Batch_idx: 280 |  Loss: (0.0039) | Acc: (99.94%) (35948/35968)\n",
            "Epoch: 154 | Batch_idx: 290 |  Loss: (0.0039) | Acc: (99.95%) (37228/37248)\n",
            "Epoch: 154 | Batch_idx: 300 |  Loss: (0.0039) | Acc: (99.94%) (38506/38528)\n",
            "Epoch: 154 | Batch_idx: 310 |  Loss: (0.0039) | Acc: (99.94%) (39785/39808)\n",
            "Epoch: 154 | Batch_idx: 320 |  Loss: (0.0039) | Acc: (99.94%) (41064/41088)\n",
            "Epoch: 154 | Batch_idx: 330 |  Loss: (0.0039) | Acc: (99.94%) (42344/42368)\n",
            "Epoch: 154 | Batch_idx: 340 |  Loss: (0.0038) | Acc: (99.95%) (43624/43648)\n",
            "Epoch: 154 | Batch_idx: 350 |  Loss: (0.0038) | Acc: (99.95%) (44904/44928)\n",
            "Epoch: 154 | Batch_idx: 360 |  Loss: (0.0038) | Acc: (99.94%) (46182/46208)\n",
            "Epoch: 154 | Batch_idx: 370 |  Loss: (0.0039) | Acc: (99.95%) (47462/47488)\n",
            "Epoch: 154 | Batch_idx: 380 |  Loss: (0.0038) | Acc: (99.94%) (48741/48768)\n",
            "Epoch: 154 | Batch_idx: 390 |  Loss: (0.0039) | Acc: (99.94%) (49972/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3557) | Acc: (92.60%) (9260/10000)\n",
            "Epoch: 155 | Batch_idx: 0 |  Loss: (0.0173) | Acc: (99.22%) (127/128)\n",
            "Epoch: 155 | Batch_idx: 10 |  Loss: (0.0068) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 155 | Batch_idx: 20 |  Loss: (0.0051) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 155 | Batch_idx: 30 |  Loss: (0.0049) | Acc: (99.90%) (3964/3968)\n",
            "Epoch: 155 | Batch_idx: 40 |  Loss: (0.0044) | Acc: (99.92%) (5244/5248)\n",
            "Epoch: 155 | Batch_idx: 50 |  Loss: (0.0047) | Acc: (99.91%) (6522/6528)\n",
            "Epoch: 155 | Batch_idx: 60 |  Loss: (0.0045) | Acc: (99.91%) (7801/7808)\n",
            "Epoch: 155 | Batch_idx: 70 |  Loss: (0.0043) | Acc: (99.92%) (9081/9088)\n",
            "Epoch: 155 | Batch_idx: 80 |  Loss: (0.0042) | Acc: (99.92%) (10360/10368)\n",
            "Epoch: 155 | Batch_idx: 90 |  Loss: (0.0042) | Acc: (99.91%) (11638/11648)\n",
            "Epoch: 155 | Batch_idx: 100 |  Loss: (0.0043) | Acc: (99.91%) (12917/12928)\n",
            "Epoch: 155 | Batch_idx: 110 |  Loss: (0.0042) | Acc: (99.92%) (14197/14208)\n",
            "Epoch: 155 | Batch_idx: 120 |  Loss: (0.0042) | Acc: (99.92%) (15476/15488)\n",
            "Epoch: 155 | Batch_idx: 130 |  Loss: (0.0042) | Acc: (99.92%) (16755/16768)\n",
            "Epoch: 155 | Batch_idx: 140 |  Loss: (0.0043) | Acc: (99.92%) (18033/18048)\n",
            "Epoch: 155 | Batch_idx: 150 |  Loss: (0.0042) | Acc: (99.92%) (19313/19328)\n",
            "Epoch: 155 | Batch_idx: 160 |  Loss: (0.0045) | Acc: (99.92%) (20591/20608)\n",
            "Epoch: 155 | Batch_idx: 170 |  Loss: (0.0045) | Acc: (99.92%) (21870/21888)\n",
            "Epoch: 155 | Batch_idx: 180 |  Loss: (0.0044) | Acc: (99.92%) (23150/23168)\n",
            "Epoch: 155 | Batch_idx: 190 |  Loss: (0.0044) | Acc: (99.92%) (24429/24448)\n",
            "Epoch: 155 | Batch_idx: 200 |  Loss: (0.0043) | Acc: (99.92%) (25708/25728)\n",
            "Epoch: 155 | Batch_idx: 210 |  Loss: (0.0043) | Acc: (99.92%) (26987/27008)\n",
            "Epoch: 155 | Batch_idx: 220 |  Loss: (0.0044) | Acc: (99.92%) (28264/28288)\n",
            "Epoch: 155 | Batch_idx: 230 |  Loss: (0.0043) | Acc: (99.92%) (29544/29568)\n",
            "Epoch: 155 | Batch_idx: 240 |  Loss: (0.0044) | Acc: (99.91%) (30821/30848)\n",
            "Epoch: 155 | Batch_idx: 250 |  Loss: (0.0043) | Acc: (99.92%) (32101/32128)\n",
            "Epoch: 155 | Batch_idx: 260 |  Loss: (0.0044) | Acc: (99.91%) (33378/33408)\n",
            "Epoch: 155 | Batch_idx: 270 |  Loss: (0.0045) | Acc: (99.90%) (34652/34688)\n",
            "Epoch: 155 | Batch_idx: 280 |  Loss: (0.0044) | Acc: (99.90%) (35931/35968)\n",
            "Epoch: 155 | Batch_idx: 290 |  Loss: (0.0044) | Acc: (99.90%) (37211/37248)\n",
            "Epoch: 155 | Batch_idx: 300 |  Loss: (0.0044) | Acc: (99.90%) (38491/38528)\n",
            "Epoch: 155 | Batch_idx: 310 |  Loss: (0.0044) | Acc: (99.90%) (39769/39808)\n",
            "Epoch: 155 | Batch_idx: 320 |  Loss: (0.0044) | Acc: (99.91%) (41049/41088)\n",
            "Epoch: 155 | Batch_idx: 330 |  Loss: (0.0044) | Acc: (99.91%) (42328/42368)\n",
            "Epoch: 155 | Batch_idx: 340 |  Loss: (0.0044) | Acc: (99.91%) (43608/43648)\n",
            "Epoch: 155 | Batch_idx: 350 |  Loss: (0.0044) | Acc: (99.90%) (44885/44928)\n",
            "Epoch: 155 | Batch_idx: 360 |  Loss: (0.0044) | Acc: (99.91%) (46165/46208)\n",
            "Epoch: 155 | Batch_idx: 370 |  Loss: (0.0044) | Acc: (99.91%) (47444/47488)\n",
            "Epoch: 155 | Batch_idx: 380 |  Loss: (0.0044) | Acc: (99.91%) (48722/48768)\n",
            "Epoch: 155 | Batch_idx: 390 |  Loss: (0.0044) | Acc: (99.91%) (49954/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3581) | Acc: (92.63%) (9263/10000)\n",
            "Epoch: 156 | Batch_idx: 0 |  Loss: (0.0115) | Acc: (99.22%) (127/128)\n",
            "Epoch: 156 | Batch_idx: 10 |  Loss: (0.0031) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 156 | Batch_idx: 20 |  Loss: (0.0033) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 156 | Batch_idx: 30 |  Loss: (0.0036) | Acc: (99.95%) (3966/3968)\n",
            "Epoch: 156 | Batch_idx: 40 |  Loss: (0.0036) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 156 | Batch_idx: 50 |  Loss: (0.0038) | Acc: (99.94%) (6524/6528)\n",
            "Epoch: 156 | Batch_idx: 60 |  Loss: (0.0042) | Acc: (99.92%) (7802/7808)\n",
            "Epoch: 156 | Batch_idx: 70 |  Loss: (0.0040) | Acc: (99.93%) (9082/9088)\n",
            "Epoch: 156 | Batch_idx: 80 |  Loss: (0.0043) | Acc: (99.92%) (10360/10368)\n",
            "Epoch: 156 | Batch_idx: 90 |  Loss: (0.0042) | Acc: (99.93%) (11640/11648)\n",
            "Epoch: 156 | Batch_idx: 100 |  Loss: (0.0040) | Acc: (99.94%) (12920/12928)\n",
            "Epoch: 156 | Batch_idx: 110 |  Loss: (0.0040) | Acc: (99.94%) (14200/14208)\n",
            "Epoch: 156 | Batch_idx: 120 |  Loss: (0.0039) | Acc: (99.95%) (15480/15488)\n",
            "Epoch: 156 | Batch_idx: 130 |  Loss: (0.0039) | Acc: (99.95%) (16759/16768)\n",
            "Epoch: 156 | Batch_idx: 140 |  Loss: (0.0040) | Acc: (99.94%) (18037/18048)\n",
            "Epoch: 156 | Batch_idx: 150 |  Loss: (0.0040) | Acc: (99.94%) (19317/19328)\n",
            "Epoch: 156 | Batch_idx: 160 |  Loss: (0.0042) | Acc: (99.93%) (20594/20608)\n",
            "Epoch: 156 | Batch_idx: 170 |  Loss: (0.0041) | Acc: (99.93%) (21873/21888)\n",
            "Epoch: 156 | Batch_idx: 180 |  Loss: (0.0041) | Acc: (99.93%) (23152/23168)\n",
            "Epoch: 156 | Batch_idx: 190 |  Loss: (0.0040) | Acc: (99.93%) (24432/24448)\n",
            "Epoch: 156 | Batch_idx: 200 |  Loss: (0.0039) | Acc: (99.94%) (25712/25728)\n",
            "Epoch: 156 | Batch_idx: 210 |  Loss: (0.0040) | Acc: (99.94%) (26991/27008)\n",
            "Epoch: 156 | Batch_idx: 220 |  Loss: (0.0040) | Acc: (99.93%) (28269/28288)\n",
            "Epoch: 156 | Batch_idx: 230 |  Loss: (0.0041) | Acc: (99.93%) (29547/29568)\n",
            "Epoch: 156 | Batch_idx: 240 |  Loss: (0.0041) | Acc: (99.93%) (30826/30848)\n",
            "Epoch: 156 | Batch_idx: 250 |  Loss: (0.0041) | Acc: (99.93%) (32106/32128)\n",
            "Epoch: 156 | Batch_idx: 260 |  Loss: (0.0040) | Acc: (99.93%) (33386/33408)\n",
            "Epoch: 156 | Batch_idx: 270 |  Loss: (0.0040) | Acc: (99.93%) (34665/34688)\n",
            "Epoch: 156 | Batch_idx: 280 |  Loss: (0.0040) | Acc: (99.93%) (35944/35968)\n",
            "Epoch: 156 | Batch_idx: 290 |  Loss: (0.0040) | Acc: (99.94%) (37224/37248)\n",
            "Epoch: 156 | Batch_idx: 300 |  Loss: (0.0041) | Acc: (99.93%) (38502/38528)\n",
            "Epoch: 156 | Batch_idx: 310 |  Loss: (0.0041) | Acc: (99.93%) (39781/39808)\n",
            "Epoch: 156 | Batch_idx: 320 |  Loss: (0.0041) | Acc: (99.93%) (41060/41088)\n",
            "Epoch: 156 | Batch_idx: 330 |  Loss: (0.0041) | Acc: (99.93%) (42340/42368)\n",
            "Epoch: 156 | Batch_idx: 340 |  Loss: (0.0041) | Acc: (99.94%) (43620/43648)\n",
            "Epoch: 156 | Batch_idx: 350 |  Loss: (0.0041) | Acc: (99.93%) (44898/44928)\n",
            "Epoch: 156 | Batch_idx: 360 |  Loss: (0.0041) | Acc: (99.94%) (46178/46208)\n",
            "Epoch: 156 | Batch_idx: 370 |  Loss: (0.0041) | Acc: (99.94%) (47458/47488)\n",
            "Epoch: 156 | Batch_idx: 380 |  Loss: (0.0040) | Acc: (99.94%) (48737/48768)\n",
            "Epoch: 156 | Batch_idx: 390 |  Loss: (0.0041) | Acc: (99.94%) (49968/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3578) | Acc: (92.70%) (9270/10000)\n",
            "Epoch: 157 | Batch_idx: 0 |  Loss: (0.0024) | Acc: (100.00%) (128/128)\n",
            "Epoch: 157 | Batch_idx: 10 |  Loss: (0.0029) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 157 | Batch_idx: 20 |  Loss: (0.0030) | Acc: (100.00%) (2688/2688)\n",
            "Epoch: 157 | Batch_idx: 30 |  Loss: (0.0032) | Acc: (100.00%) (3968/3968)\n",
            "Epoch: 157 | Batch_idx: 40 |  Loss: (0.0031) | Acc: (100.00%) (5248/5248)\n",
            "Epoch: 157 | Batch_idx: 50 |  Loss: (0.0038) | Acc: (99.95%) (6525/6528)\n",
            "Epoch: 157 | Batch_idx: 60 |  Loss: (0.0038) | Acc: (99.95%) (7804/7808)\n",
            "Epoch: 157 | Batch_idx: 70 |  Loss: (0.0037) | Acc: (99.96%) (9084/9088)\n",
            "Epoch: 157 | Batch_idx: 80 |  Loss: (0.0036) | Acc: (99.96%) (10364/10368)\n",
            "Epoch: 157 | Batch_idx: 90 |  Loss: (0.0037) | Acc: (99.96%) (11643/11648)\n",
            "Epoch: 157 | Batch_idx: 100 |  Loss: (0.0038) | Acc: (99.95%) (12921/12928)\n",
            "Epoch: 157 | Batch_idx: 110 |  Loss: (0.0037) | Acc: (99.95%) (14201/14208)\n",
            "Epoch: 157 | Batch_idx: 120 |  Loss: (0.0038) | Acc: (99.95%) (15480/15488)\n",
            "Epoch: 157 | Batch_idx: 130 |  Loss: (0.0038) | Acc: (99.95%) (16760/16768)\n",
            "Epoch: 157 | Batch_idx: 140 |  Loss: (0.0037) | Acc: (99.95%) (18039/18048)\n",
            "Epoch: 157 | Batch_idx: 150 |  Loss: (0.0038) | Acc: (99.94%) (19317/19328)\n",
            "Epoch: 157 | Batch_idx: 160 |  Loss: (0.0037) | Acc: (99.95%) (20597/20608)\n",
            "Epoch: 157 | Batch_idx: 170 |  Loss: (0.0039) | Acc: (99.95%) (21876/21888)\n",
            "Epoch: 157 | Batch_idx: 180 |  Loss: (0.0039) | Acc: (99.94%) (23155/23168)\n",
            "Epoch: 157 | Batch_idx: 190 |  Loss: (0.0039) | Acc: (99.94%) (24434/24448)\n",
            "Epoch: 157 | Batch_idx: 200 |  Loss: (0.0040) | Acc: (99.93%) (25710/25728)\n",
            "Epoch: 157 | Batch_idx: 210 |  Loss: (0.0040) | Acc: (99.93%) (26989/27008)\n",
            "Epoch: 157 | Batch_idx: 220 |  Loss: (0.0039) | Acc: (99.93%) (28268/28288)\n",
            "Epoch: 157 | Batch_idx: 230 |  Loss: (0.0040) | Acc: (99.93%) (29546/29568)\n",
            "Epoch: 157 | Batch_idx: 240 |  Loss: (0.0039) | Acc: (99.93%) (30826/30848)\n",
            "Epoch: 157 | Batch_idx: 250 |  Loss: (0.0040) | Acc: (99.93%) (32105/32128)\n",
            "Epoch: 157 | Batch_idx: 260 |  Loss: (0.0040) | Acc: (99.93%) (33383/33408)\n",
            "Epoch: 157 | Batch_idx: 270 |  Loss: (0.0039) | Acc: (99.93%) (34663/34688)\n",
            "Epoch: 157 | Batch_idx: 280 |  Loss: (0.0040) | Acc: (99.92%) (35941/35968)\n",
            "Epoch: 157 | Batch_idx: 290 |  Loss: (0.0040) | Acc: (99.92%) (37220/37248)\n",
            "Epoch: 157 | Batch_idx: 300 |  Loss: (0.0040) | Acc: (99.92%) (38498/38528)\n",
            "Epoch: 157 | Batch_idx: 310 |  Loss: (0.0040) | Acc: (99.92%) (39778/39808)\n",
            "Epoch: 157 | Batch_idx: 320 |  Loss: (0.0040) | Acc: (99.92%) (41056/41088)\n",
            "Epoch: 157 | Batch_idx: 330 |  Loss: (0.0040) | Acc: (99.92%) (42336/42368)\n",
            "Epoch: 157 | Batch_idx: 340 |  Loss: (0.0040) | Acc: (99.92%) (43614/43648)\n",
            "Epoch: 157 | Batch_idx: 350 |  Loss: (0.0040) | Acc: (99.92%) (44892/44928)\n",
            "Epoch: 157 | Batch_idx: 360 |  Loss: (0.0040) | Acc: (99.92%) (46172/46208)\n",
            "Epoch: 157 | Batch_idx: 370 |  Loss: (0.0040) | Acc: (99.92%) (47450/47488)\n",
            "Epoch: 157 | Batch_idx: 380 |  Loss: (0.0040) | Acc: (99.92%) (48729/48768)\n",
            "Epoch: 157 | Batch_idx: 390 |  Loss: (0.0040) | Acc: (99.92%) (49960/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3615) | Acc: (92.61%) (9261/10000)\n",
            "Epoch: 158 | Batch_idx: 0 |  Loss: (0.0035) | Acc: (100.00%) (128/128)\n",
            "Epoch: 158 | Batch_idx: 10 |  Loss: (0.0033) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 158 | Batch_idx: 20 |  Loss: (0.0028) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 158 | Batch_idx: 30 |  Loss: (0.0028) | Acc: (99.97%) (3967/3968)\n",
            "Epoch: 158 | Batch_idx: 40 |  Loss: (0.0029) | Acc: (99.96%) (5246/5248)\n",
            "Epoch: 158 | Batch_idx: 50 |  Loss: (0.0031) | Acc: (99.95%) (6525/6528)\n",
            "Epoch: 158 | Batch_idx: 60 |  Loss: (0.0032) | Acc: (99.96%) (7805/7808)\n",
            "Epoch: 158 | Batch_idx: 70 |  Loss: (0.0036) | Acc: (99.96%) (9084/9088)\n",
            "Epoch: 158 | Batch_idx: 80 |  Loss: (0.0036) | Acc: (99.93%) (10361/10368)\n",
            "Epoch: 158 | Batch_idx: 90 |  Loss: (0.0036) | Acc: (99.93%) (11640/11648)\n",
            "Epoch: 158 | Batch_idx: 100 |  Loss: (0.0035) | Acc: (99.94%) (12920/12928)\n",
            "Epoch: 158 | Batch_idx: 110 |  Loss: (0.0035) | Acc: (99.94%) (14200/14208)\n",
            "Epoch: 158 | Batch_idx: 120 |  Loss: (0.0035) | Acc: (99.94%) (15479/15488)\n",
            "Epoch: 158 | Batch_idx: 130 |  Loss: (0.0037) | Acc: (99.94%) (16758/16768)\n",
            "Epoch: 158 | Batch_idx: 140 |  Loss: (0.0037) | Acc: (99.94%) (18037/18048)\n",
            "Epoch: 158 | Batch_idx: 150 |  Loss: (0.0038) | Acc: (99.94%) (19316/19328)\n",
            "Epoch: 158 | Batch_idx: 160 |  Loss: (0.0039) | Acc: (99.94%) (20595/20608)\n",
            "Epoch: 158 | Batch_idx: 170 |  Loss: (0.0040) | Acc: (99.93%) (21873/21888)\n",
            "Epoch: 158 | Batch_idx: 180 |  Loss: (0.0039) | Acc: (99.93%) (23152/23168)\n",
            "Epoch: 158 | Batch_idx: 190 |  Loss: (0.0040) | Acc: (99.93%) (24430/24448)\n",
            "Epoch: 158 | Batch_idx: 200 |  Loss: (0.0039) | Acc: (99.93%) (25710/25728)\n",
            "Epoch: 158 | Batch_idx: 210 |  Loss: (0.0039) | Acc: (99.93%) (26990/27008)\n",
            "Epoch: 158 | Batch_idx: 220 |  Loss: (0.0039) | Acc: (99.94%) (28270/28288)\n",
            "Epoch: 158 | Batch_idx: 230 |  Loss: (0.0038) | Acc: (99.94%) (29550/29568)\n",
            "Epoch: 158 | Batch_idx: 240 |  Loss: (0.0038) | Acc: (99.94%) (30829/30848)\n",
            "Epoch: 158 | Batch_idx: 250 |  Loss: (0.0038) | Acc: (99.94%) (32109/32128)\n",
            "Epoch: 158 | Batch_idx: 260 |  Loss: (0.0039) | Acc: (99.94%) (33388/33408)\n",
            "Epoch: 158 | Batch_idx: 270 |  Loss: (0.0039) | Acc: (99.94%) (34668/34688)\n",
            "Epoch: 158 | Batch_idx: 280 |  Loss: (0.0039) | Acc: (99.94%) (35946/35968)\n",
            "Epoch: 158 | Batch_idx: 290 |  Loss: (0.0039) | Acc: (99.94%) (37225/37248)\n",
            "Epoch: 158 | Batch_idx: 300 |  Loss: (0.0041) | Acc: (99.93%) (38501/38528)\n",
            "Epoch: 158 | Batch_idx: 310 |  Loss: (0.0041) | Acc: (99.93%) (39781/39808)\n",
            "Epoch: 158 | Batch_idx: 320 |  Loss: (0.0041) | Acc: (99.93%) (41061/41088)\n",
            "Epoch: 158 | Batch_idx: 330 |  Loss: (0.0041) | Acc: (99.93%) (42340/42368)\n",
            "Epoch: 158 | Batch_idx: 340 |  Loss: (0.0041) | Acc: (99.93%) (43619/43648)\n",
            "Epoch: 158 | Batch_idx: 350 |  Loss: (0.0041) | Acc: (99.93%) (44898/44928)\n",
            "Epoch: 158 | Batch_idx: 360 |  Loss: (0.0040) | Acc: (99.93%) (46177/46208)\n",
            "Epoch: 158 | Batch_idx: 370 |  Loss: (0.0041) | Acc: (99.93%) (47455/47488)\n",
            "Epoch: 158 | Batch_idx: 380 |  Loss: (0.0040) | Acc: (99.93%) (48735/48768)\n",
            "Epoch: 158 | Batch_idx: 390 |  Loss: (0.0041) | Acc: (99.93%) (49966/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3639) | Acc: (92.53%) (9253/10000)\n",
            "Epoch: 159 | Batch_idx: 0 |  Loss: (0.0018) | Acc: (100.00%) (128/128)\n",
            "Epoch: 159 | Batch_idx: 10 |  Loss: (0.0023) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 159 | Batch_idx: 20 |  Loss: (0.0031) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 159 | Batch_idx: 30 |  Loss: (0.0036) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 159 | Batch_idx: 40 |  Loss: (0.0035) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 159 | Batch_idx: 50 |  Loss: (0.0034) | Acc: (99.94%) (6524/6528)\n",
            "Epoch: 159 | Batch_idx: 60 |  Loss: (0.0034) | Acc: (99.95%) (7804/7808)\n",
            "Epoch: 159 | Batch_idx: 70 |  Loss: (0.0036) | Acc: (99.92%) (9081/9088)\n",
            "Epoch: 159 | Batch_idx: 80 |  Loss: (0.0036) | Acc: (99.93%) (10361/10368)\n",
            "Epoch: 159 | Batch_idx: 90 |  Loss: (0.0039) | Acc: (99.91%) (11638/11648)\n",
            "Epoch: 159 | Batch_idx: 100 |  Loss: (0.0040) | Acc: (99.91%) (12916/12928)\n",
            "Epoch: 159 | Batch_idx: 110 |  Loss: (0.0040) | Acc: (99.92%) (14196/14208)\n",
            "Epoch: 159 | Batch_idx: 120 |  Loss: (0.0040) | Acc: (99.92%) (15476/15488)\n",
            "Epoch: 159 | Batch_idx: 130 |  Loss: (0.0038) | Acc: (99.93%) (16756/16768)\n",
            "Epoch: 159 | Batch_idx: 140 |  Loss: (0.0038) | Acc: (99.93%) (18036/18048)\n",
            "Epoch: 159 | Batch_idx: 150 |  Loss: (0.0037) | Acc: (99.94%) (19316/19328)\n",
            "Epoch: 159 | Batch_idx: 160 |  Loss: (0.0036) | Acc: (99.94%) (20596/20608)\n",
            "Epoch: 159 | Batch_idx: 170 |  Loss: (0.0036) | Acc: (99.95%) (21876/21888)\n",
            "Epoch: 159 | Batch_idx: 180 |  Loss: (0.0036) | Acc: (99.94%) (23155/23168)\n",
            "Epoch: 159 | Batch_idx: 190 |  Loss: (0.0036) | Acc: (99.94%) (24434/24448)\n",
            "Epoch: 159 | Batch_idx: 200 |  Loss: (0.0037) | Acc: (99.94%) (25713/25728)\n",
            "Epoch: 159 | Batch_idx: 210 |  Loss: (0.0037) | Acc: (99.94%) (26991/27008)\n",
            "Epoch: 159 | Batch_idx: 220 |  Loss: (0.0037) | Acc: (99.94%) (28271/28288)\n",
            "Epoch: 159 | Batch_idx: 230 |  Loss: (0.0037) | Acc: (99.94%) (29550/29568)\n",
            "Epoch: 159 | Batch_idx: 240 |  Loss: (0.0038) | Acc: (99.94%) (30829/30848)\n",
            "Epoch: 159 | Batch_idx: 250 |  Loss: (0.0038) | Acc: (99.94%) (32108/32128)\n",
            "Epoch: 159 | Batch_idx: 260 |  Loss: (0.0037) | Acc: (99.94%) (33388/33408)\n",
            "Epoch: 159 | Batch_idx: 270 |  Loss: (0.0037) | Acc: (99.94%) (34668/34688)\n",
            "Epoch: 159 | Batch_idx: 280 |  Loss: (0.0037) | Acc: (99.94%) (35948/35968)\n",
            "Epoch: 159 | Batch_idx: 290 |  Loss: (0.0037) | Acc: (99.95%) (37228/37248)\n",
            "Epoch: 159 | Batch_idx: 300 |  Loss: (0.0037) | Acc: (99.95%) (38508/38528)\n",
            "Epoch: 159 | Batch_idx: 310 |  Loss: (0.0037) | Acc: (99.95%) (39787/39808)\n",
            "Epoch: 159 | Batch_idx: 320 |  Loss: (0.0038) | Acc: (99.94%) (41065/41088)\n",
            "Epoch: 159 | Batch_idx: 330 |  Loss: (0.0038) | Acc: (99.95%) (42345/42368)\n",
            "Epoch: 159 | Batch_idx: 340 |  Loss: (0.0038) | Acc: (99.95%) (43624/43648)\n",
            "Epoch: 159 | Batch_idx: 350 |  Loss: (0.0038) | Acc: (99.94%) (44902/44928)\n",
            "Epoch: 159 | Batch_idx: 360 |  Loss: (0.0038) | Acc: (99.94%) (46181/46208)\n",
            "Epoch: 159 | Batch_idx: 370 |  Loss: (0.0038) | Acc: (99.94%) (47460/47488)\n",
            "Epoch: 159 | Batch_idx: 380 |  Loss: (0.0038) | Acc: (99.94%) (48740/48768)\n",
            "Epoch: 159 | Batch_idx: 390 |  Loss: (0.0038) | Acc: (99.94%) (49971/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3617) | Acc: (92.53%) (9253/10000)\n",
            "Epoch: 160 | Batch_idx: 0 |  Loss: (0.0095) | Acc: (99.22%) (127/128)\n",
            "Epoch: 160 | Batch_idx: 10 |  Loss: (0.0027) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 160 | Batch_idx: 20 |  Loss: (0.0025) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 160 | Batch_idx: 30 |  Loss: (0.0026) | Acc: (99.97%) (3967/3968)\n",
            "Epoch: 160 | Batch_idx: 40 |  Loss: (0.0030) | Acc: (99.96%) (5246/5248)\n",
            "Epoch: 160 | Batch_idx: 50 |  Loss: (0.0031) | Acc: (99.95%) (6525/6528)\n",
            "Epoch: 160 | Batch_idx: 60 |  Loss: (0.0032) | Acc: (99.95%) (7804/7808)\n",
            "Epoch: 160 | Batch_idx: 70 |  Loss: (0.0033) | Acc: (99.94%) (9083/9088)\n",
            "Epoch: 160 | Batch_idx: 80 |  Loss: (0.0034) | Acc: (99.94%) (10362/10368)\n",
            "Epoch: 160 | Batch_idx: 90 |  Loss: (0.0033) | Acc: (99.95%) (11642/11648)\n",
            "Epoch: 160 | Batch_idx: 100 |  Loss: (0.0032) | Acc: (99.95%) (12922/12928)\n",
            "Epoch: 160 | Batch_idx: 110 |  Loss: (0.0035) | Acc: (99.95%) (14201/14208)\n",
            "Epoch: 160 | Batch_idx: 120 |  Loss: (0.0035) | Acc: (99.95%) (15481/15488)\n",
            "Epoch: 160 | Batch_idx: 130 |  Loss: (0.0035) | Acc: (99.95%) (16760/16768)\n",
            "Epoch: 160 | Batch_idx: 140 |  Loss: (0.0035) | Acc: (99.96%) (18040/18048)\n",
            "Epoch: 160 | Batch_idx: 150 |  Loss: (0.0035) | Acc: (99.95%) (19319/19328)\n",
            "Epoch: 160 | Batch_idx: 160 |  Loss: (0.0037) | Acc: (99.94%) (20596/20608)\n",
            "Epoch: 160 | Batch_idx: 170 |  Loss: (0.0037) | Acc: (99.94%) (21875/21888)\n",
            "Epoch: 160 | Batch_idx: 180 |  Loss: (0.0038) | Acc: (99.94%) (23153/23168)\n",
            "Epoch: 160 | Batch_idx: 190 |  Loss: (0.0038) | Acc: (99.94%) (24433/24448)\n",
            "Epoch: 160 | Batch_idx: 200 |  Loss: (0.0038) | Acc: (99.93%) (25711/25728)\n",
            "Epoch: 160 | Batch_idx: 210 |  Loss: (0.0038) | Acc: (99.93%) (26989/27008)\n",
            "Epoch: 160 | Batch_idx: 220 |  Loss: (0.0038) | Acc: (99.93%) (28269/28288)\n",
            "Epoch: 160 | Batch_idx: 230 |  Loss: (0.0038) | Acc: (99.94%) (29549/29568)\n",
            "Epoch: 160 | Batch_idx: 240 |  Loss: (0.0037) | Acc: (99.94%) (30829/30848)\n",
            "Epoch: 160 | Batch_idx: 250 |  Loss: (0.0037) | Acc: (99.94%) (32109/32128)\n",
            "Epoch: 160 | Batch_idx: 260 |  Loss: (0.0037) | Acc: (99.94%) (33389/33408)\n",
            "Epoch: 160 | Batch_idx: 270 |  Loss: (0.0037) | Acc: (99.94%) (34668/34688)\n",
            "Epoch: 160 | Batch_idx: 280 |  Loss: (0.0037) | Acc: (99.94%) (35946/35968)\n",
            "Epoch: 160 | Batch_idx: 290 |  Loss: (0.0037) | Acc: (99.94%) (37226/37248)\n",
            "Epoch: 160 | Batch_idx: 300 |  Loss: (0.0037) | Acc: (99.94%) (38505/38528)\n",
            "Epoch: 160 | Batch_idx: 310 |  Loss: (0.0037) | Acc: (99.94%) (39784/39808)\n",
            "Epoch: 160 | Batch_idx: 320 |  Loss: (0.0037) | Acc: (99.94%) (41063/41088)\n",
            "Epoch: 160 | Batch_idx: 330 |  Loss: (0.0038) | Acc: (99.94%) (42341/42368)\n",
            "Epoch: 160 | Batch_idx: 340 |  Loss: (0.0038) | Acc: (99.94%) (43621/43648)\n",
            "Epoch: 160 | Batch_idx: 350 |  Loss: (0.0038) | Acc: (99.94%) (44901/44928)\n",
            "Epoch: 160 | Batch_idx: 360 |  Loss: (0.0038) | Acc: (99.94%) (46181/46208)\n",
            "Epoch: 160 | Batch_idx: 370 |  Loss: (0.0038) | Acc: (99.94%) (47459/47488)\n",
            "Epoch: 160 | Batch_idx: 380 |  Loss: (0.0038) | Acc: (99.94%) (48739/48768)\n",
            "Epoch: 160 | Batch_idx: 390 |  Loss: (0.0038) | Acc: (99.94%) (49969/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3644) | Acc: (92.57%) (9257/10000)\n",
            "Epoch: 161 | Batch_idx: 0 |  Loss: (0.0278) | Acc: (99.22%) (127/128)\n",
            "Epoch: 161 | Batch_idx: 10 |  Loss: (0.0052) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 161 | Batch_idx: 20 |  Loss: (0.0048) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 161 | Batch_idx: 30 |  Loss: (0.0044) | Acc: (99.95%) (3966/3968)\n",
            "Epoch: 161 | Batch_idx: 40 |  Loss: (0.0048) | Acc: (99.92%) (5244/5248)\n",
            "Epoch: 161 | Batch_idx: 50 |  Loss: (0.0047) | Acc: (99.92%) (6523/6528)\n",
            "Epoch: 161 | Batch_idx: 60 |  Loss: (0.0045) | Acc: (99.92%) (7802/7808)\n",
            "Epoch: 161 | Batch_idx: 70 |  Loss: (0.0042) | Acc: (99.93%) (9082/9088)\n",
            "Epoch: 161 | Batch_idx: 80 |  Loss: (0.0041) | Acc: (99.93%) (10361/10368)\n",
            "Epoch: 161 | Batch_idx: 90 |  Loss: (0.0041) | Acc: (99.93%) (11640/11648)\n",
            "Epoch: 161 | Batch_idx: 100 |  Loss: (0.0040) | Acc: (99.94%) (12920/12928)\n",
            "Epoch: 161 | Batch_idx: 110 |  Loss: (0.0039) | Acc: (99.94%) (14200/14208)\n",
            "Epoch: 161 | Batch_idx: 120 |  Loss: (0.0040) | Acc: (99.93%) (15477/15488)\n",
            "Epoch: 161 | Batch_idx: 130 |  Loss: (0.0042) | Acc: (99.93%) (16756/16768)\n",
            "Epoch: 161 | Batch_idx: 140 |  Loss: (0.0041) | Acc: (99.93%) (18035/18048)\n",
            "Epoch: 161 | Batch_idx: 150 |  Loss: (0.0042) | Acc: (99.93%) (19314/19328)\n",
            "Epoch: 161 | Batch_idx: 160 |  Loss: (0.0044) | Acc: (99.92%) (20591/20608)\n",
            "Epoch: 161 | Batch_idx: 170 |  Loss: (0.0043) | Acc: (99.92%) (21870/21888)\n",
            "Epoch: 161 | Batch_idx: 180 |  Loss: (0.0043) | Acc: (99.92%) (23149/23168)\n",
            "Epoch: 161 | Batch_idx: 190 |  Loss: (0.0042) | Acc: (99.92%) (24429/24448)\n",
            "Epoch: 161 | Batch_idx: 200 |  Loss: (0.0041) | Acc: (99.93%) (25709/25728)\n",
            "Epoch: 161 | Batch_idx: 210 |  Loss: (0.0041) | Acc: (99.93%) (26989/27008)\n",
            "Epoch: 161 | Batch_idx: 220 |  Loss: (0.0042) | Acc: (99.93%) (28267/28288)\n",
            "Epoch: 161 | Batch_idx: 230 |  Loss: (0.0042) | Acc: (99.93%) (29546/29568)\n",
            "Epoch: 161 | Batch_idx: 240 |  Loss: (0.0042) | Acc: (99.93%) (30825/30848)\n",
            "Epoch: 161 | Batch_idx: 250 |  Loss: (0.0042) | Acc: (99.92%) (32102/32128)\n",
            "Epoch: 161 | Batch_idx: 260 |  Loss: (0.0043) | Acc: (99.92%) (33380/33408)\n",
            "Epoch: 161 | Batch_idx: 270 |  Loss: (0.0043) | Acc: (99.91%) (34658/34688)\n",
            "Epoch: 161 | Batch_idx: 280 |  Loss: (0.0042) | Acc: (99.91%) (35937/35968)\n",
            "Epoch: 161 | Batch_idx: 290 |  Loss: (0.0043) | Acc: (99.91%) (37216/37248)\n",
            "Epoch: 161 | Batch_idx: 300 |  Loss: (0.0042) | Acc: (99.92%) (38496/38528)\n",
            "Epoch: 161 | Batch_idx: 310 |  Loss: (0.0042) | Acc: (99.92%) (39776/39808)\n",
            "Epoch: 161 | Batch_idx: 320 |  Loss: (0.0042) | Acc: (99.92%) (41055/41088)\n",
            "Epoch: 161 | Batch_idx: 330 |  Loss: (0.0042) | Acc: (99.92%) (42335/42368)\n",
            "Epoch: 161 | Batch_idx: 340 |  Loss: (0.0041) | Acc: (99.92%) (43615/43648)\n",
            "Epoch: 161 | Batch_idx: 350 |  Loss: (0.0041) | Acc: (99.93%) (44895/44928)\n",
            "Epoch: 161 | Batch_idx: 360 |  Loss: (0.0041) | Acc: (99.92%) (46173/46208)\n",
            "Epoch: 161 | Batch_idx: 370 |  Loss: (0.0041) | Acc: (99.92%) (47452/47488)\n",
            "Epoch: 161 | Batch_idx: 380 |  Loss: (0.0041) | Acc: (99.93%) (48732/48768)\n",
            "Epoch: 161 | Batch_idx: 390 |  Loss: (0.0041) | Acc: (99.93%) (49963/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3643) | Acc: (92.41%) (9241/10000)\n",
            "Epoch: 162 | Batch_idx: 0 |  Loss: (0.0022) | Acc: (100.00%) (128/128)\n",
            "Epoch: 162 | Batch_idx: 10 |  Loss: (0.0034) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 162 | Batch_idx: 20 |  Loss: (0.0033) | Acc: (100.00%) (2688/2688)\n",
            "Epoch: 162 | Batch_idx: 30 |  Loss: (0.0036) | Acc: (99.97%) (3967/3968)\n",
            "Epoch: 162 | Batch_idx: 40 |  Loss: (0.0039) | Acc: (99.96%) (5246/5248)\n",
            "Epoch: 162 | Batch_idx: 50 |  Loss: (0.0045) | Acc: (99.94%) (6524/6528)\n",
            "Epoch: 162 | Batch_idx: 60 |  Loss: (0.0044) | Acc: (99.95%) (7804/7808)\n",
            "Epoch: 162 | Batch_idx: 70 |  Loss: (0.0042) | Acc: (99.96%) (9084/9088)\n",
            "Epoch: 162 | Batch_idx: 80 |  Loss: (0.0041) | Acc: (99.96%) (10364/10368)\n",
            "Epoch: 162 | Batch_idx: 90 |  Loss: (0.0043) | Acc: (99.95%) (11642/11648)\n",
            "Epoch: 162 | Batch_idx: 100 |  Loss: (0.0041) | Acc: (99.95%) (12922/12928)\n",
            "Epoch: 162 | Batch_idx: 110 |  Loss: (0.0041) | Acc: (99.96%) (14202/14208)\n",
            "Epoch: 162 | Batch_idx: 120 |  Loss: (0.0041) | Acc: (99.95%) (15481/15488)\n",
            "Epoch: 162 | Batch_idx: 130 |  Loss: (0.0042) | Acc: (99.95%) (16760/16768)\n",
            "Epoch: 162 | Batch_idx: 140 |  Loss: (0.0043) | Acc: (99.94%) (18038/18048)\n",
            "Epoch: 162 | Batch_idx: 150 |  Loss: (0.0042) | Acc: (99.95%) (19318/19328)\n",
            "Epoch: 162 | Batch_idx: 160 |  Loss: (0.0042) | Acc: (99.95%) (20597/20608)\n",
            "Epoch: 162 | Batch_idx: 170 |  Loss: (0.0041) | Acc: (99.95%) (21876/21888)\n",
            "Epoch: 162 | Batch_idx: 180 |  Loss: (0.0041) | Acc: (99.95%) (23156/23168)\n",
            "Epoch: 162 | Batch_idx: 190 |  Loss: (0.0040) | Acc: (99.95%) (24435/24448)\n",
            "Epoch: 162 | Batch_idx: 200 |  Loss: (0.0040) | Acc: (99.95%) (25715/25728)\n",
            "Epoch: 162 | Batch_idx: 210 |  Loss: (0.0039) | Acc: (99.95%) (26994/27008)\n",
            "Epoch: 162 | Batch_idx: 220 |  Loss: (0.0039) | Acc: (99.95%) (28274/28288)\n",
            "Epoch: 162 | Batch_idx: 230 |  Loss: (0.0039) | Acc: (99.95%) (29553/29568)\n",
            "Epoch: 162 | Batch_idx: 240 |  Loss: (0.0039) | Acc: (99.95%) (30833/30848)\n",
            "Epoch: 162 | Batch_idx: 250 |  Loss: (0.0040) | Acc: (99.94%) (32110/32128)\n",
            "Epoch: 162 | Batch_idx: 260 |  Loss: (0.0040) | Acc: (99.95%) (33390/33408)\n",
            "Epoch: 162 | Batch_idx: 270 |  Loss: (0.0041) | Acc: (99.94%) (34668/34688)\n",
            "Epoch: 162 | Batch_idx: 280 |  Loss: (0.0041) | Acc: (99.94%) (35948/35968)\n",
            "Epoch: 162 | Batch_idx: 290 |  Loss: (0.0041) | Acc: (99.94%) (37227/37248)\n",
            "Epoch: 162 | Batch_idx: 300 |  Loss: (0.0041) | Acc: (99.94%) (38506/38528)\n",
            "Epoch: 162 | Batch_idx: 310 |  Loss: (0.0041) | Acc: (99.94%) (39785/39808)\n",
            "Epoch: 162 | Batch_idx: 320 |  Loss: (0.0040) | Acc: (99.94%) (41065/41088)\n",
            "Epoch: 162 | Batch_idx: 330 |  Loss: (0.0041) | Acc: (99.94%) (42343/42368)\n",
            "Epoch: 162 | Batch_idx: 340 |  Loss: (0.0040) | Acc: (99.94%) (43623/43648)\n",
            "Epoch: 162 | Batch_idx: 350 |  Loss: (0.0040) | Acc: (99.94%) (44902/44928)\n",
            "Epoch: 162 | Batch_idx: 360 |  Loss: (0.0040) | Acc: (99.94%) (46181/46208)\n",
            "Epoch: 162 | Batch_idx: 370 |  Loss: (0.0040) | Acc: (99.94%) (47461/47488)\n",
            "Epoch: 162 | Batch_idx: 380 |  Loss: (0.0040) | Acc: (99.94%) (48741/48768)\n",
            "Epoch: 162 | Batch_idx: 390 |  Loss: (0.0039) | Acc: (99.95%) (49973/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3626) | Acc: (92.54%) (9254/10000)\n",
            "Epoch: 163 | Batch_idx: 0 |  Loss: (0.0032) | Acc: (100.00%) (128/128)\n",
            "Epoch: 163 | Batch_idx: 10 |  Loss: (0.0032) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 163 | Batch_idx: 20 |  Loss: (0.0042) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 163 | Batch_idx: 30 |  Loss: (0.0045) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 163 | Batch_idx: 40 |  Loss: (0.0041) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 163 | Batch_idx: 50 |  Loss: (0.0041) | Acc: (99.94%) (6524/6528)\n",
            "Epoch: 163 | Batch_idx: 60 |  Loss: (0.0040) | Acc: (99.95%) (7804/7808)\n",
            "Epoch: 163 | Batch_idx: 70 |  Loss: (0.0038) | Acc: (99.96%) (9084/9088)\n",
            "Epoch: 163 | Batch_idx: 80 |  Loss: (0.0038) | Acc: (99.95%) (10363/10368)\n",
            "Epoch: 163 | Batch_idx: 90 |  Loss: (0.0039) | Acc: (99.95%) (11642/11648)\n",
            "Epoch: 163 | Batch_idx: 100 |  Loss: (0.0038) | Acc: (99.95%) (12922/12928)\n",
            "Epoch: 163 | Batch_idx: 110 |  Loss: (0.0036) | Acc: (99.96%) (14202/14208)\n",
            "Epoch: 163 | Batch_idx: 120 |  Loss: (0.0036) | Acc: (99.96%) (15482/15488)\n",
            "Epoch: 163 | Batch_idx: 130 |  Loss: (0.0036) | Acc: (99.96%) (16761/16768)\n",
            "Epoch: 163 | Batch_idx: 140 |  Loss: (0.0036) | Acc: (99.96%) (18041/18048)\n",
            "Epoch: 163 | Batch_idx: 150 |  Loss: (0.0038) | Acc: (99.95%) (19318/19328)\n",
            "Epoch: 163 | Batch_idx: 160 |  Loss: (0.0037) | Acc: (99.95%) (20598/20608)\n",
            "Epoch: 163 | Batch_idx: 170 |  Loss: (0.0037) | Acc: (99.95%) (21877/21888)\n",
            "Epoch: 163 | Batch_idx: 180 |  Loss: (0.0037) | Acc: (99.95%) (23156/23168)\n",
            "Epoch: 163 | Batch_idx: 190 |  Loss: (0.0038) | Acc: (99.94%) (24434/24448)\n",
            "Epoch: 163 | Batch_idx: 200 |  Loss: (0.0037) | Acc: (99.94%) (25713/25728)\n",
            "Epoch: 163 | Batch_idx: 210 |  Loss: (0.0039) | Acc: (99.93%) (26990/27008)\n",
            "Epoch: 163 | Batch_idx: 220 |  Loss: (0.0039) | Acc: (99.93%) (28269/28288)\n",
            "Epoch: 163 | Batch_idx: 230 |  Loss: (0.0039) | Acc: (99.94%) (29549/29568)\n",
            "Epoch: 163 | Batch_idx: 240 |  Loss: (0.0039) | Acc: (99.94%) (30829/30848)\n",
            "Epoch: 163 | Batch_idx: 250 |  Loss: (0.0039) | Acc: (99.94%) (32108/32128)\n",
            "Epoch: 163 | Batch_idx: 260 |  Loss: (0.0038) | Acc: (99.93%) (33386/33408)\n",
            "Epoch: 163 | Batch_idx: 270 |  Loss: (0.0038) | Acc: (99.94%) (34666/34688)\n",
            "Epoch: 163 | Batch_idx: 280 |  Loss: (0.0038) | Acc: (99.94%) (35946/35968)\n",
            "Epoch: 163 | Batch_idx: 290 |  Loss: (0.0038) | Acc: (99.94%) (37226/37248)\n",
            "Epoch: 163 | Batch_idx: 300 |  Loss: (0.0038) | Acc: (99.94%) (38505/38528)\n",
            "Epoch: 163 | Batch_idx: 310 |  Loss: (0.0037) | Acc: (99.94%) (39785/39808)\n",
            "Epoch: 163 | Batch_idx: 320 |  Loss: (0.0038) | Acc: (99.94%) (41062/41088)\n",
            "Epoch: 163 | Batch_idx: 330 |  Loss: (0.0039) | Acc: (99.93%) (42340/42368)\n",
            "Epoch: 163 | Batch_idx: 340 |  Loss: (0.0039) | Acc: (99.94%) (43620/43648)\n",
            "Epoch: 163 | Batch_idx: 350 |  Loss: (0.0038) | Acc: (99.94%) (44900/44928)\n",
            "Epoch: 163 | Batch_idx: 360 |  Loss: (0.0038) | Acc: (99.94%) (46180/46208)\n",
            "Epoch: 163 | Batch_idx: 370 |  Loss: (0.0038) | Acc: (99.94%) (47458/47488)\n",
            "Epoch: 163 | Batch_idx: 380 |  Loss: (0.0038) | Acc: (99.94%) (48738/48768)\n",
            "Epoch: 163 | Batch_idx: 390 |  Loss: (0.0038) | Acc: (99.94%) (49970/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3614) | Acc: (92.55%) (9255/10000)\n",
            "Epoch: 164 | Batch_idx: 0 |  Loss: (0.0044) | Acc: (100.00%) (128/128)\n",
            "Epoch: 164 | Batch_idx: 10 |  Loss: (0.0028) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 164 | Batch_idx: 20 |  Loss: (0.0025) | Acc: (100.00%) (2688/2688)\n",
            "Epoch: 164 | Batch_idx: 30 |  Loss: (0.0032) | Acc: (99.95%) (3966/3968)\n",
            "Epoch: 164 | Batch_idx: 40 |  Loss: (0.0039) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 164 | Batch_idx: 50 |  Loss: (0.0039) | Acc: (99.94%) (6524/6528)\n",
            "Epoch: 164 | Batch_idx: 60 |  Loss: (0.0040) | Acc: (99.94%) (7803/7808)\n",
            "Epoch: 164 | Batch_idx: 70 |  Loss: (0.0038) | Acc: (99.94%) (9083/9088)\n",
            "Epoch: 164 | Batch_idx: 80 |  Loss: (0.0036) | Acc: (99.95%) (10363/10368)\n",
            "Epoch: 164 | Batch_idx: 90 |  Loss: (0.0040) | Acc: (99.94%) (11641/11648)\n",
            "Epoch: 164 | Batch_idx: 100 |  Loss: (0.0040) | Acc: (99.95%) (12921/12928)\n",
            "Epoch: 164 | Batch_idx: 110 |  Loss: (0.0039) | Acc: (99.95%) (14201/14208)\n",
            "Epoch: 164 | Batch_idx: 120 |  Loss: (0.0040) | Acc: (99.94%) (15479/15488)\n",
            "Epoch: 164 | Batch_idx: 130 |  Loss: (0.0041) | Acc: (99.95%) (16759/16768)\n",
            "Epoch: 164 | Batch_idx: 140 |  Loss: (0.0042) | Acc: (99.94%) (18037/18048)\n",
            "Epoch: 164 | Batch_idx: 150 |  Loss: (0.0042) | Acc: (99.94%) (19317/19328)\n",
            "Epoch: 164 | Batch_idx: 160 |  Loss: (0.0041) | Acc: (99.95%) (20597/20608)\n",
            "Epoch: 164 | Batch_idx: 170 |  Loss: (0.0042) | Acc: (99.95%) (21876/21888)\n",
            "Epoch: 164 | Batch_idx: 180 |  Loss: (0.0042) | Acc: (99.94%) (23155/23168)\n",
            "Epoch: 164 | Batch_idx: 190 |  Loss: (0.0043) | Acc: (99.93%) (24432/24448)\n",
            "Epoch: 164 | Batch_idx: 200 |  Loss: (0.0042) | Acc: (99.93%) (25711/25728)\n",
            "Epoch: 164 | Batch_idx: 210 |  Loss: (0.0041) | Acc: (99.94%) (26991/27008)\n",
            "Epoch: 164 | Batch_idx: 220 |  Loss: (0.0042) | Acc: (99.93%) (28269/28288)\n",
            "Epoch: 164 | Batch_idx: 230 |  Loss: (0.0042) | Acc: (99.93%) (29548/29568)\n",
            "Epoch: 164 | Batch_idx: 240 |  Loss: (0.0043) | Acc: (99.93%) (30825/30848)\n",
            "Epoch: 164 | Batch_idx: 250 |  Loss: (0.0043) | Acc: (99.93%) (32104/32128)\n",
            "Epoch: 164 | Batch_idx: 260 |  Loss: (0.0043) | Acc: (99.93%) (33384/33408)\n",
            "Epoch: 164 | Batch_idx: 270 |  Loss: (0.0043) | Acc: (99.93%) (34662/34688)\n",
            "Epoch: 164 | Batch_idx: 280 |  Loss: (0.0043) | Acc: (99.93%) (35942/35968)\n",
            "Epoch: 164 | Batch_idx: 290 |  Loss: (0.0043) | Acc: (99.93%) (37221/37248)\n",
            "Epoch: 164 | Batch_idx: 300 |  Loss: (0.0043) | Acc: (99.93%) (38501/38528)\n",
            "Epoch: 164 | Batch_idx: 310 |  Loss: (0.0043) | Acc: (99.93%) (39780/39808)\n",
            "Epoch: 164 | Batch_idx: 320 |  Loss: (0.0043) | Acc: (99.93%) (41059/41088)\n",
            "Epoch: 164 | Batch_idx: 330 |  Loss: (0.0043) | Acc: (99.93%) (42339/42368)\n",
            "Epoch: 164 | Batch_idx: 340 |  Loss: (0.0043) | Acc: (99.93%) (43616/43648)\n",
            "Epoch: 164 | Batch_idx: 350 |  Loss: (0.0043) | Acc: (99.93%) (44896/44928)\n",
            "Epoch: 164 | Batch_idx: 360 |  Loss: (0.0043) | Acc: (99.93%) (46176/46208)\n",
            "Epoch: 164 | Batch_idx: 370 |  Loss: (0.0042) | Acc: (99.93%) (47456/47488)\n",
            "Epoch: 164 | Batch_idx: 380 |  Loss: (0.0042) | Acc: (99.93%) (48735/48768)\n",
            "Epoch: 164 | Batch_idx: 390 |  Loss: (0.0042) | Acc: (99.93%) (49965/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3617) | Acc: (92.61%) (9261/10000)\n",
            "2 hours 43 mins 11 secs for training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYhVQcpSr2J0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8_I0MHilCl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}